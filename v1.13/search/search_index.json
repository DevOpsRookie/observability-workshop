{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"","title":"Home"},{"location":"module-support/cleanup/","text":"Post Workshop Clean Up \u00b6 Multipass Once you have finished with this Workshop exit from the AWS/EC2 instance to get back to your system command prompt. Enter the following to delete the Multipass instance, replace [YOUR_INITIALS] with the ones you used in Smart Agent module: multipass delete --purge [ YOUR_INITIALS ] -k3s AWS/EC2 Once you have finished with this Workshop exit from the AWS/EC2 instance to get back to your system command prompt. We will use Terraform to destroy the instance with the parameters you used in Smart Agent module: cd ~/workshop/ec2 terraform destroy Enter Instance Count , Provide the desired region and Select instance type required . When prompted type yes to confirm you want to destroy, this will take a while to complete. aws_instance.app-dev-instance[0]: Destroying... [id=i-088560a5f6e2bbdbb] aws_instance.app-dev-instance[0]: Still destroying... [id=i-088560a5f6e2bbdbb, 10s elapsed] aws_instance.app-dev-instance[0]: Still destroying... [id=i-088560a5f6e2bbdbb, 20s elapsed] aws_instance.app-dev-instance[0]: Still destroying... [id=i-088560a5f6e2bbdbb, 30s elapsed] aws_instance.app-dev-instance[0]: Still destroying... [id=i-088560a5f6e2bbdbb, 40s elapsed] aws_instance.app-dev-instance[0]: Still destroying... [id=i-088560a5f6e2bbdbb, 50s elapsed] aws_instance.app-dev-instance[0]: Destruction complete after 56s aws_security_group.instance: Destroying... [id=sg-0d6841fbeef022a9f] aws_security_group.instance: Destruction complete after 2s","title":"<b>Post Workshop Clean Up</b>"},{"location":"module-support/cleanup/#post-workshop-clean-up","text":"Multipass Once you have finished with this Workshop exit from the AWS/EC2 instance to get back to your system command prompt. Enter the following to delete the Multipass instance, replace [YOUR_INITIALS] with the ones you used in Smart Agent module: multipass delete --purge [ YOUR_INITIALS ] -k3s AWS/EC2 Once you have finished with this Workshop exit from the AWS/EC2 instance to get back to your system command prompt. We will use Terraform to destroy the instance with the parameters you used in Smart Agent module: cd ~/workshop/ec2 terraform destroy Enter Instance Count , Provide the desired region and Select instance type required . When prompted type yes to confirm you want to destroy, this will take a while to complete. aws_instance.app-dev-instance[0]: Destroying... [id=i-088560a5f6e2bbdbb] aws_instance.app-dev-instance[0]: Still destroying... [id=i-088560a5f6e2bbdbb, 10s elapsed] aws_instance.app-dev-instance[0]: Still destroying... [id=i-088560a5f6e2bbdbb, 20s elapsed] aws_instance.app-dev-instance[0]: Still destroying... [id=i-088560a5f6e2bbdbb, 30s elapsed] aws_instance.app-dev-instance[0]: Still destroying... [id=i-088560a5f6e2bbdbb, 40s elapsed] aws_instance.app-dev-instance[0]: Still destroying... [id=i-088560a5f6e2bbdbb, 50s elapsed] aws_instance.app-dev-instance[0]: Destruction complete after 56s aws_security_group.instance: Destroying... [id=sg-0d6841fbeef022a9f] aws_security_group.instance: Destruction complete after 2s","title":"Post Workshop Clean Up"},{"location":"module-support/hotrod-eks/","text":"Deploying Hot R.O.D. in AWS/EKS \u00b6 Enabling \u00b5APM An Organization needs to be pre-provisioned as a \u00b5APM entitlement is required for the purposes of this module. Please contact someone from SignalFx to get a trial instance with \u00b5APM enabled if you don\u2019t have one already. To check if you have an Organization with \u00b5APM enabled, just login to SignalFx and check that you have the \u00b5APM tab on the top navbar next to Dashboards. 1. Launch the Multipass instance \u00b6 If you have not already completed the Smart Agent Preparation , then please do so, otherwise jump to Step #2 2. Create environment variables \u00b6 Create the following environment variables for SignalFx and AWS to use in the proceeding steps: SignalFx export ACCESS_TOKEN=[ACCESS_TOKEN] export REALM=[REALM e.g. us1] export INITIALS=[YOUR_INITIALS e.g. RWC] export VERSION=[VERSION e.g. 5.1.2] AWS export AWS_ACCESS_KEY_ID=[AWS Access Key] export AWS_SECRET_ACCESS_KEY=[AWS Secret Access Key] export AWS_DEFAULT_REGION=[e.g. us-east-1] export AWS_DEFAULT_OUTPUT=json export EKS_CLUSTER_NAME=$INITIALS-APP-DEV You can check for the latest SignalFx Smart Agent release on Github . 3. Configure AWS CLI for your account \u00b6 Use the AWS CLI to configure access to your AWS environment. The environment variables configured above mean you can just hit enter on each of the prompts to accept the values: Input aws configure Output AWS Access Key ID [****************TVAQ]: AWS Secret Access Key [****************MkB4]: Default region name [us-east-1]: Default output format [json]: 4. Create a cluster running Amazon Elastic Kubernetes Service (EKS) \u00b6 Input eksctl create cluster \\ --name $EKS_CLUSTER_NAME \\ --region $AWS_DEFAULT_REGION \\ --node-type t3.medium \\ --nodes-min 3 \\ --nodes-max 7 \\ --version=1.15 Output [\u2139] eksctl version 0.16.0 [\u2139] using region us-east-1 [\u2139] setting availability zones to [us-east-1a us-east-1f] [\u2139] subnets for us-east-1a - public:192.168.0.0/19 private:192.168.64.0/19 [\u2139] subnets for us-east-1f - public:192.168.32.0/19 private:192.168.96.0/19 [\u2139] nodegroup \"ng-371a784a\" will use \"ami-0e5bb2367e692b807\" [AmazonLinux2/1.15] [\u2139] using Kubernetes version 1.15 [\u2139] creating EKS cluster \"EKS-APP-DEV\" in \"us-east-1\" region with un-managed nodes [\u2139] will create 2 separate CloudFormation stacks for cluster itself and the initial nodegroup [\u2139] if you encounter any issues, check CloudFormation console or try 'eksctl utils describe-stacks --region=us-east-1 --cluster=EKS-APP-DEV' [\u2139] CloudWatch logging will not be enabled for cluster \"EKS-APP-DEV\" in \"us-east-1\" [\u2139] you can enable it with 'eksctl utils update-cluster-logging --region=us-east-1 --cluster=EKS-APP-DEV' [\u2139] Kubernetes API endpoint access will use default of {publicAccess=true, privateAccess=false} for cluster \"EKS-APP-DEV\" in \"us-east-1\" [\u2139] 2 sequential tasks: { create cluster control plane \"EKS-APP-DEV\", create nodegroup \"ng-371a784a\" } [\u2139] building cluster stack \"eksctl-EKS-APP-DEV-cluster\" [\u2139] deploying stack \"eksctl-EKS-APP-DEV-cluster\" [\u2139] building nodegroup stack \"eksctl-EKS-APP-DEV-nodegroup-ng-371a784a\" [\u2139] deploying stack \"eksctl-EKS-APP-DEV-nodegroup-ng-371a784a\" [\u2714] all EKS cluster resources for \"EKS-APP-DEV\" have been created [!] unable to write kubeconfig , please retry with 'eksctl utils write-kubeconfig -n EKS-APP-DEV': unable to modify kubeconfig /home/ubuntu/.kube/config: open /etc/rancher/k3s/k3s.yaml.lock: permission denied [\u2139] adding identity \"arn:aws:iam::327192335161:role/eksctl-EKS-APP-DEV-nodegroup-ng-3-NodeInstanceRole-2RMH7RBODD62\" to auth ConfigMap [\u2139] nodegroup \"ng-371a784a\" has 0 node(s) [\u2139] waiting for at least 3 node(s) to become ready in \"ng-371a784a\" [\u2139] nodegroup \"ng-371a784a\" has 3 node(s) [\u2139] node \"ip-192-168-35-104.ec2.internal\" is ready [\u2139] node \"ip-192-168-52-88.ec2.internal\" is ready [\u2139] node \"ip-192-168-8-236.ec2.internal\" is ready [\u2714] EKS cluster \"EKS-APP-DEV\" in \"us-east-1\" region is ready This may take some time (10-15 minutes). Ensure you see your cluster active in AWS EKS console before proceeding. Note You can ignore the error about unable to write kubeconfig as we address this below. Once complete update your kubeconfig to allow kubectl access to the cluster: Input sudo eksctl utils write-kubeconfig -n $EKS_CLUSTER_NAME 5. Deploy SignalFx SmartAgent to your EKS Cluster \u00b6 Add the SignalFx Helm chart repository to Helm: Input helm repo add signalfx https://dl.signalfx.com/helm-repo Output \"signalfx\" has been added to your repositories Ensure the latest state of the SignalFx Helm repository: Input helm repo update Output Hang tight while we grab the latest from your chart repositories... ...Successfully got an update from the \"signalfx\" chart repository Install the Smart Agent Helm chart with the following commands: Input sed -i -e 's/\\[INITIALS\\]/'\"$INITIALS\"'/' ~/workshop/k3s/values.yaml helm install \\ --set signalFxAccessToken=$ACCESS_TOKEN \\ --set clusterName=$EKS_CLUSTER_NAME \\ --set signalFxRealm=$REALM \\ --set agentVersion=$VERSION \\ --set kubeletAPI.url=https://localhost:10250 \\ --set traceEndpointUrl=https://ingest.$REALM.signalfx.com/v2/trace \\ signalfx-agent signalfx/signalfx-agent \\ -f workshop/k3s/values.yaml Output NAME: signalfx-agent LAST DEPLOYED: Mon Apr 13 14:23:19 2020 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: The SignalFx agent is being deployed in your Kubernetes cluster. You should see metrics flowing once the agent image is downloaded and started (this may take a few minutes since it has to download the agent container image). Assuming you are logged into SignalFx in your browser, visit https://app.us0.signalfx.com/#/navigator/kubernetes%20pods/kubernetes%20pods to see all of the pods in your cluster. Validate cluster looks healthy in SignalFx Kubernetes Navigator dashboard 6. Deploy Hot R.O.D. Application to EKS \u00b6 Input kubectl apply -f ~/workshop/apm/hotrod/k8s/deployment.yaml To ensure the Hot R.O.D. application is running see examples below: Input kubectl get pods Output NAME READY STATUS RESTARTS AGE hotrod-7564774bf5-vjpfw 1/1 Running 0 47h signalfx-agent-jmq4f 1/1 Running 0 138m signalfx-agent-nk8p9 1/1 Running 0 138m signalfx-agent-q5tzh 1/1 Running 0 138m You then need find the IP address assigned to the Hot R.O.D. service: Input kubectl get svc Output NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE hotrod LoadBalancer 10.100.188.249 af26ce80ef2e14c9292ae5b4bc0d2dd0-1826890352.us-east-2.elb.amazonaws.com 8080:32521/TCP 47h kubernetes ClusterIP 10.100.0.1 <none> 443/TCP 3d1h Create an environment variable for the IP address and port that the Hot R.O.D. application is exposed on: Input HOTROD_ENDPOINT=$(kubectl get svc hotrod -n default -o jsonpath='{.spec.clusterIP}:{.spec.ports[0].port}') You can view / exercise Hot R.O.D. yourself in a browser by opening the EXTERNAL-IP:PORT as shown above e.g. Example URL https://af26ce80ef2e14c9292ae5b4bc0d2dd0-1826890352.us-east-2.elb.amazonaws.com:8080 7. Generate some traffic to the application using Apache Benchmark \u00b6 Input ab -n100 -c10 \"http:// $HOTROD_ENDPOINT /dispatch?customer=392&nonse=0.17041229755366172\" Create some errors with an invalid customer number Input ab -n100 -c10 \"http:// $HOTROD_ENDPOINT /dispatch?customer=391&nonse=0.17041229755366172\" You should now be able to exercise SignalFx APM dashboards. 8. Cleaning up \u00b6 To delete entire EKS cluster: Input eksctl delete cluster $EKS_CLUSTER_NAME Output [\u2139] eksctl version 0.16.0 [\u2139] using region us-east-1 [\u2139] deleting EKS cluster \"RWC-APP-DEV\" [\u2139] deleted 0 Fargate profile(s) [\u2139] cleaning up LoadBalancer services [\u2139] 2 sequential tasks: { delete nodegroup \"ng-371a784a\", delete cluster control plane \"EKS-APP-DEV\" [async] } [\u2139] will delete stack \"eksctl-EKS-APP-DEV-nodegroup-ng-371a784a\" [\u2139] waiting for stack \"eksctl-EKS-APP-DEV-nodegroup-ng-371a784a\" to get deleted [\u2139] will delete stack \"eksctl-EKS-APP-DEV-cluster\" [\u2714] all cluster resources were deleted Or to delete individual components: Input kubectl delete deploy/hotrod svc/hotrod helm delete signalfx-agent To switch back to using the local K3s cluster: Input sudo kubectl config use-context default","title":"Deploying Hot R.O.D. in EKS"},{"location":"module-support/hotrod-eks/#deploying-hot-rod-in-awseks","text":"Enabling \u00b5APM An Organization needs to be pre-provisioned as a \u00b5APM entitlement is required for the purposes of this module. Please contact someone from SignalFx to get a trial instance with \u00b5APM enabled if you don\u2019t have one already. To check if you have an Organization with \u00b5APM enabled, just login to SignalFx and check that you have the \u00b5APM tab on the top navbar next to Dashboards.","title":"Deploying Hot R.O.D. in AWS/EKS"},{"location":"module-support/hotrod-eks/#1-launch-the-multipass-instance","text":"If you have not already completed the Smart Agent Preparation , then please do so, otherwise jump to Step #2","title":"1. Launch the Multipass instance"},{"location":"module-support/hotrod-eks/#2-create-environment-variables","text":"Create the following environment variables for SignalFx and AWS to use in the proceeding steps: SignalFx export ACCESS_TOKEN=[ACCESS_TOKEN] export REALM=[REALM e.g. us1] export INITIALS=[YOUR_INITIALS e.g. RWC] export VERSION=[VERSION e.g. 5.1.2] AWS export AWS_ACCESS_KEY_ID=[AWS Access Key] export AWS_SECRET_ACCESS_KEY=[AWS Secret Access Key] export AWS_DEFAULT_REGION=[e.g. us-east-1] export AWS_DEFAULT_OUTPUT=json export EKS_CLUSTER_NAME=$INITIALS-APP-DEV You can check for the latest SignalFx Smart Agent release on Github .","title":"2. Create environment variables"},{"location":"module-support/hotrod-eks/#3-configure-aws-cli-for-your-account","text":"Use the AWS CLI to configure access to your AWS environment. The environment variables configured above mean you can just hit enter on each of the prompts to accept the values: Input aws configure Output AWS Access Key ID [****************TVAQ]: AWS Secret Access Key [****************MkB4]: Default region name [us-east-1]: Default output format [json]:","title":"3. Configure AWS CLI for your account"},{"location":"module-support/hotrod-eks/#4-create-a-cluster-running-amazon-elastic-kubernetes-service-eks","text":"Input eksctl create cluster \\ --name $EKS_CLUSTER_NAME \\ --region $AWS_DEFAULT_REGION \\ --node-type t3.medium \\ --nodes-min 3 \\ --nodes-max 7 \\ --version=1.15 Output [\u2139] eksctl version 0.16.0 [\u2139] using region us-east-1 [\u2139] setting availability zones to [us-east-1a us-east-1f] [\u2139] subnets for us-east-1a - public:192.168.0.0/19 private:192.168.64.0/19 [\u2139] subnets for us-east-1f - public:192.168.32.0/19 private:192.168.96.0/19 [\u2139] nodegroup \"ng-371a784a\" will use \"ami-0e5bb2367e692b807\" [AmazonLinux2/1.15] [\u2139] using Kubernetes version 1.15 [\u2139] creating EKS cluster \"EKS-APP-DEV\" in \"us-east-1\" region with un-managed nodes [\u2139] will create 2 separate CloudFormation stacks for cluster itself and the initial nodegroup [\u2139] if you encounter any issues, check CloudFormation console or try 'eksctl utils describe-stacks --region=us-east-1 --cluster=EKS-APP-DEV' [\u2139] CloudWatch logging will not be enabled for cluster \"EKS-APP-DEV\" in \"us-east-1\" [\u2139] you can enable it with 'eksctl utils update-cluster-logging --region=us-east-1 --cluster=EKS-APP-DEV' [\u2139] Kubernetes API endpoint access will use default of {publicAccess=true, privateAccess=false} for cluster \"EKS-APP-DEV\" in \"us-east-1\" [\u2139] 2 sequential tasks: { create cluster control plane \"EKS-APP-DEV\", create nodegroup \"ng-371a784a\" } [\u2139] building cluster stack \"eksctl-EKS-APP-DEV-cluster\" [\u2139] deploying stack \"eksctl-EKS-APP-DEV-cluster\" [\u2139] building nodegroup stack \"eksctl-EKS-APP-DEV-nodegroup-ng-371a784a\" [\u2139] deploying stack \"eksctl-EKS-APP-DEV-nodegroup-ng-371a784a\" [\u2714] all EKS cluster resources for \"EKS-APP-DEV\" have been created [!] unable to write kubeconfig , please retry with 'eksctl utils write-kubeconfig -n EKS-APP-DEV': unable to modify kubeconfig /home/ubuntu/.kube/config: open /etc/rancher/k3s/k3s.yaml.lock: permission denied [\u2139] adding identity \"arn:aws:iam::327192335161:role/eksctl-EKS-APP-DEV-nodegroup-ng-3-NodeInstanceRole-2RMH7RBODD62\" to auth ConfigMap [\u2139] nodegroup \"ng-371a784a\" has 0 node(s) [\u2139] waiting for at least 3 node(s) to become ready in \"ng-371a784a\" [\u2139] nodegroup \"ng-371a784a\" has 3 node(s) [\u2139] node \"ip-192-168-35-104.ec2.internal\" is ready [\u2139] node \"ip-192-168-52-88.ec2.internal\" is ready [\u2139] node \"ip-192-168-8-236.ec2.internal\" is ready [\u2714] EKS cluster \"EKS-APP-DEV\" in \"us-east-1\" region is ready This may take some time (10-15 minutes). Ensure you see your cluster active in AWS EKS console before proceeding. Note You can ignore the error about unable to write kubeconfig as we address this below. Once complete update your kubeconfig to allow kubectl access to the cluster: Input sudo eksctl utils write-kubeconfig -n $EKS_CLUSTER_NAME","title":"4. Create a cluster running Amazon Elastic Kubernetes Service (EKS)"},{"location":"module-support/hotrod-eks/#5-deploy-signalfx-smartagent-to-your-eks-cluster","text":"Add the SignalFx Helm chart repository to Helm: Input helm repo add signalfx https://dl.signalfx.com/helm-repo Output \"signalfx\" has been added to your repositories Ensure the latest state of the SignalFx Helm repository: Input helm repo update Output Hang tight while we grab the latest from your chart repositories... ...Successfully got an update from the \"signalfx\" chart repository Install the Smart Agent Helm chart with the following commands: Input sed -i -e 's/\\[INITIALS\\]/'\"$INITIALS\"'/' ~/workshop/k3s/values.yaml helm install \\ --set signalFxAccessToken=$ACCESS_TOKEN \\ --set clusterName=$EKS_CLUSTER_NAME \\ --set signalFxRealm=$REALM \\ --set agentVersion=$VERSION \\ --set kubeletAPI.url=https://localhost:10250 \\ --set traceEndpointUrl=https://ingest.$REALM.signalfx.com/v2/trace \\ signalfx-agent signalfx/signalfx-agent \\ -f workshop/k3s/values.yaml Output NAME: signalfx-agent LAST DEPLOYED: Mon Apr 13 14:23:19 2020 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: The SignalFx agent is being deployed in your Kubernetes cluster. You should see metrics flowing once the agent image is downloaded and started (this may take a few minutes since it has to download the agent container image). Assuming you are logged into SignalFx in your browser, visit https://app.us0.signalfx.com/#/navigator/kubernetes%20pods/kubernetes%20pods to see all of the pods in your cluster. Validate cluster looks healthy in SignalFx Kubernetes Navigator dashboard","title":"5. Deploy SignalFx SmartAgent to your EKS Cluster"},{"location":"module-support/hotrod-eks/#6-deploy-hot-rod-application-to-eks","text":"Input kubectl apply -f ~/workshop/apm/hotrod/k8s/deployment.yaml To ensure the Hot R.O.D. application is running see examples below: Input kubectl get pods Output NAME READY STATUS RESTARTS AGE hotrod-7564774bf5-vjpfw 1/1 Running 0 47h signalfx-agent-jmq4f 1/1 Running 0 138m signalfx-agent-nk8p9 1/1 Running 0 138m signalfx-agent-q5tzh 1/1 Running 0 138m You then need find the IP address assigned to the Hot R.O.D. service: Input kubectl get svc Output NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE hotrod LoadBalancer 10.100.188.249 af26ce80ef2e14c9292ae5b4bc0d2dd0-1826890352.us-east-2.elb.amazonaws.com 8080:32521/TCP 47h kubernetes ClusterIP 10.100.0.1 <none> 443/TCP 3d1h Create an environment variable for the IP address and port that the Hot R.O.D. application is exposed on: Input HOTROD_ENDPOINT=$(kubectl get svc hotrod -n default -o jsonpath='{.spec.clusterIP}:{.spec.ports[0].port}') You can view / exercise Hot R.O.D. yourself in a browser by opening the EXTERNAL-IP:PORT as shown above e.g. Example URL https://af26ce80ef2e14c9292ae5b4bc0d2dd0-1826890352.us-east-2.elb.amazonaws.com:8080","title":"6. Deploy Hot R.O.D. Application to EKS"},{"location":"module-support/hotrod-eks/#7-generate-some-traffic-to-the-application-using-apache-benchmark","text":"Input ab -n100 -c10 \"http:// $HOTROD_ENDPOINT /dispatch?customer=392&nonse=0.17041229755366172\" Create some errors with an invalid customer number Input ab -n100 -c10 \"http:// $HOTROD_ENDPOINT /dispatch?customer=391&nonse=0.17041229755366172\" You should now be able to exercise SignalFx APM dashboards.","title":"7. Generate some traffic to the application using Apache Benchmark"},{"location":"module-support/hotrod-eks/#8-cleaning-up","text":"To delete entire EKS cluster: Input eksctl delete cluster $EKS_CLUSTER_NAME Output [\u2139] eksctl version 0.16.0 [\u2139] using region us-east-1 [\u2139] deleting EKS cluster \"RWC-APP-DEV\" [\u2139] deleted 0 Fargate profile(s) [\u2139] cleaning up LoadBalancer services [\u2139] 2 sequential tasks: { delete nodegroup \"ng-371a784a\", delete cluster control plane \"EKS-APP-DEV\" [async] } [\u2139] will delete stack \"eksctl-EKS-APP-DEV-nodegroup-ng-371a784a\" [\u2139] waiting for stack \"eksctl-EKS-APP-DEV-nodegroup-ng-371a784a\" to get deleted [\u2139] will delete stack \"eksctl-EKS-APP-DEV-cluster\" [\u2714] all cluster resources were deleted Or to delete individual components: Input kubectl delete deploy/hotrod svc/hotrod helm delete signalfx-agent To switch back to using the local K3s cluster: Input sudo kubectl config use-context default","title":"8. Cleaning up"},{"location":"module-support/vm/","text":"Lab Summary \u00b6 Deploy SignalFx Smart Agent via install script on a VM Confirm the Smart Agent is working and sending data Use multipass to create a vanilla Ubuntu VM and shell into it. You can also use a Linux-based VM with your cloud provider of choice. Replace [INITIALS] with your actual initials. Input multipass launch [ INITIALS ] -vm multipass shell [ INITIALs ] -vm 1. Deploy SignalFx Smart Agent via install script on a VM \u00b6 You will need to obtain your Access Token from the SignalFx UI. You can find your Access Token by clicking on your profile icon on the top right of the SignalFx UI. Then select Organization Settings \u2192 Access Tokens . Expand the Default token, then click on Show Token to expose your token. Later in the lab you can come back here and click the Copy button which will copy it to your clipboard so you can paste it when you need to provide an access token in the lab. You will also need to obtain the name of the Realm for your SignalFx account. Click on the profile icon again, but this time select 'My Profile'. The Ream can be found in the middle of the page within the Organizations section. In this example it is us1 . SignalFx maintains a shell script to install on supported distributions. Copy the script below and replace $REALM and $ACCESS_TOKEN with the values found in previous screen: Input curl -sSL https://dl.signalfx.com/signalfx-agent.sh > /tmp/signalfx-agent.sh sudo sh /tmp/signalfx-agent.sh --realm $REALM -- $ACCESS_TOKEN Once the installation is complete check the status of the agent. Input signalfx-agent status Output SignalFx Agent version: 5.1.2 Agent uptime: 4s Observers active: host Active Monitors: 9 Configured Monitors: 9 Discovered Endpoint Count: 16 Bad Monitor Config: None Global Dimensions: {host: as-k3s} GlobalSpanTags: map[] Datapoints sent (last minute): 0 Datapoints failed (last minute): 0 Datapoints overwritten (total): 0 Events Sent (last minute): 0 Trace Spans Sent (last minute): 0 Trace Spans overwritten (total): 0 Additional status commands: signalfx-agent status config - show resolved config in use by agent signalfx-agent status endpoints - show discovered endpoints signalfx-agent status monitors - show active monitors signalfx-agent status all - show everything Important Make a note of the value displayed for host in the Global Dimensions section of the output, as you need this later! 2. Confirm the Smart Agent is working and sending data \u00b6 To see the Metrics that the Smart Agent is sending to SignalFx, please goto the SignalFX UI, and select Infrastructure \u2192 Hosts to see the lists of hosts. Here you see a list of the Nodes that have an Smart Agent installed and are reporting into SignalFx. Make sure you see your Multipass or AWS/EC2 instance in the list of hosts. (The hostname from the previous section) You can also set a filter for just your instance by selecting the host: attribute, followed by picking the name of your host from the drop down list. Click on the link to your host from the list, this wil take you to the overview page of your host. Make sure you have the SYSTEM METRIC tab selected. Here you can see various charts that relate to the health of your host, like CPU & Memory Used%, Disk I/O and many more. You can also see the list of services running on your host by selecting the PROCESSES tab. Take a moment to explore the various charts and the Processes list.","title":"Deploy Smart Agent on a VM"},{"location":"module-support/vm/#lab-summary","text":"Deploy SignalFx Smart Agent via install script on a VM Confirm the Smart Agent is working and sending data Use multipass to create a vanilla Ubuntu VM and shell into it. You can also use a Linux-based VM with your cloud provider of choice. Replace [INITIALS] with your actual initials. Input multipass launch [ INITIALS ] -vm multipass shell [ INITIALs ] -vm","title":"Lab Summary"},{"location":"module-support/vm/#1-deploy-signalfx-smart-agent-via-install-script-on-a-vm","text":"You will need to obtain your Access Token from the SignalFx UI. You can find your Access Token by clicking on your profile icon on the top right of the SignalFx UI. Then select Organization Settings \u2192 Access Tokens . Expand the Default token, then click on Show Token to expose your token. Later in the lab you can come back here and click the Copy button which will copy it to your clipboard so you can paste it when you need to provide an access token in the lab. You will also need to obtain the name of the Realm for your SignalFx account. Click on the profile icon again, but this time select 'My Profile'. The Ream can be found in the middle of the page within the Organizations section. In this example it is us1 . SignalFx maintains a shell script to install on supported distributions. Copy the script below and replace $REALM and $ACCESS_TOKEN with the values found in previous screen: Input curl -sSL https://dl.signalfx.com/signalfx-agent.sh > /tmp/signalfx-agent.sh sudo sh /tmp/signalfx-agent.sh --realm $REALM -- $ACCESS_TOKEN Once the installation is complete check the status of the agent. Input signalfx-agent status Output SignalFx Agent version: 5.1.2 Agent uptime: 4s Observers active: host Active Monitors: 9 Configured Monitors: 9 Discovered Endpoint Count: 16 Bad Monitor Config: None Global Dimensions: {host: as-k3s} GlobalSpanTags: map[] Datapoints sent (last minute): 0 Datapoints failed (last minute): 0 Datapoints overwritten (total): 0 Events Sent (last minute): 0 Trace Spans Sent (last minute): 0 Trace Spans overwritten (total): 0 Additional status commands: signalfx-agent status config - show resolved config in use by agent signalfx-agent status endpoints - show discovered endpoints signalfx-agent status monitors - show active monitors signalfx-agent status all - show everything Important Make a note of the value displayed for host in the Global Dimensions section of the output, as you need this later!","title":"1. Deploy SignalFx Smart Agent via install script on a VM"},{"location":"module-support/vm/#2-confirm-the-smart-agent-is-working-and-sending-data","text":"To see the Metrics that the Smart Agent is sending to SignalFx, please goto the SignalFX UI, and select Infrastructure \u2192 Hosts to see the lists of hosts. Here you see a list of the Nodes that have an Smart Agent installed and are reporting into SignalFx. Make sure you see your Multipass or AWS/EC2 instance in the list of hosts. (The hostname from the previous section) You can also set a filter for just your instance by selecting the host: attribute, followed by picking the name of your host from the drop down list. Click on the link to your host from the list, this wil take you to the overview page of your host. Make sure you have the SYSTEM METRIC tab selected. Here you can see various charts that relate to the health of your host, like CPU & Memory Used%, Disk I/O and many more. You can also see the list of services running on your host by selecting the PROCESSES tab. Take a moment to explore the various charts and the Processes list.","title":"2. Confirm the Smart Agent is working and sending data"},{"location":"module1/adding-charts/","text":"Adding charts to dashboards \u00b6 Let's now save our chart. Click on Save as... and enter a name for your chart; use your initials like [YOUR INITIALS] Latency Chart and click OK . In the next window, find your email address in the list and select it, then click OK . You will immediately be transported to the dashboard created under your selected group (make sure the group name on the top left is your email address). Last but not least, change the dashboard's name, by clicking the ... icon on the top right and selecting Rename . Enter a new name for your dashboard and click on Done . Congratulations! You have created your first chart and dashboard!","title":"Adding charts"},{"location":"module1/adding-charts/#adding-charts-to-dashboards","text":"Let's now save our chart. Click on Save as... and enter a name for your chart; use your initials like [YOUR INITIALS] Latency Chart and click OK . In the next window, find your email address in the list and select it, then click OK . You will immediately be transported to the dashboard created under your selected group (make sure the group name on the top left is your email address). Last but not least, change the dashboard's name, by clicking the ... icon on the top right and selecting Rename . Enter a new name for your dashboard and click on Done . Congratulations! You have created your first chart and dashboard!","title":"Adding charts to dashboards"},{"location":"module1/editing/","text":"Editing charts \u00b6 1. Edit Histogram Chart \u00b6 Click on the three dots ... on the Latency histogram chart in the Sample Data dashboard and then on Open (or you can click on the name of the chart which here is Latency histogram ). You will see the plot options, current plot and signal (metric) for the Latency histogram chart. Click on the different chart type icons to explore each of the visualizations. Notice their name while you click on or swipe over them. See how the chart changes. Note You can use different ways to visualize your metrics - you choose which chart type fits best for the visualization you want to have. For more info on the different chart types see Choosing a chart type . Click on the Line chart type and you will see the line plot. In the PLOT EDITOR tab under Signal you see the metric demo.trans.latency we are currently plotting. 2. Creating a new chart \u00b6 Let's now create a new chart and save it in a new dashboard! Click on the plus icon (top right of the UI) and from the drop down, click on Chart . You will now see a chart template like the following. Let's enter a metric to plot. We are going to use the metric demo.trans.latency . In the PLOT EDITOR tab under Signal enter demo.trans.latency . You will instantly see a number of Line plots, like below. The number 18 ts indicates that we are plotting 18 metric time series in the chart. Click on the DATA TABLE tab. You see now 18 rows, each representing a metics time series with a number of columns. If you swipe over the plot horizontally you will see the metrics in these columns at different times. In the demo_datacenter column you see that there are two data centers, Paris and Tokyo , for which we are getting metrics.","title":"Editing Charts"},{"location":"module1/editing/#editing-charts","text":"","title":"Editing charts"},{"location":"module1/editing/#1-edit-histogram-chart","text":"Click on the three dots ... on the Latency histogram chart in the Sample Data dashboard and then on Open (or you can click on the name of the chart which here is Latency histogram ). You will see the plot options, current plot and signal (metric) for the Latency histogram chart. Click on the different chart type icons to explore each of the visualizations. Notice their name while you click on or swipe over them. See how the chart changes. Note You can use different ways to visualize your metrics - you choose which chart type fits best for the visualization you want to have. For more info on the different chart types see Choosing a chart type . Click on the Line chart type and you will see the line plot. In the PLOT EDITOR tab under Signal you see the metric demo.trans.latency we are currently plotting.","title":"1. Edit Histogram Chart"},{"location":"module1/editing/#2-creating-a-new-chart","text":"Let's now create a new chart and save it in a new dashboard! Click on the plus icon (top right of the UI) and from the drop down, click on Chart . You will now see a chart template like the following. Let's enter a metric to plot. We are going to use the metric demo.trans.latency . In the PLOT EDITOR tab under Signal enter demo.trans.latency . You will instantly see a number of Line plots, like below. The number 18 ts indicates that we are plotting 18 metric time series in the chart. Click on the DATA TABLE tab. You see now 18 rows, each representing a metics time series with a number of columns. If you swipe over the plot horizontally you will see the metrics in these columns at different times. In the demo_datacenter column you see that there are two data centers, Paris and Tokyo , for which we are getting metrics.","title":"2. Creating a new chart"},{"location":"module1/filtering/","text":"Using Filters \u00b6 1. Filtering and Analytics \u00b6 Let's now select the Paris datacenter to do some analytics - for that we will use a filter. Let's go back to the PLOT EDITOR tab and click on Add filter , wait until it automatically populates, choose demo_datacenter , and then Paris . In the F(x) column, add the analytic function Percentile:Aggregation , and leave the value to 95 (click outside to confirm). For info on the Percentile function and the other functions see Analytics reference . 2. Using Timeshift analytical function \u00b6 Let's now compare with older metrics. Click on ... and then on Clone in the dropdown to clone Signal A . You will see a new row identical to A , called B , both visible and plotted. For Signal B , in the F(x) column add the analytic function Timeshift and enter 7d (7 days = 1 week), and click outside to confirm. Click on the cog on the far right, and choose a Plot Color e.g. pink, to change color for the plot of B . Click on Close . Next, click into the field next to Time on the Override bar and choose Past Day from the dropdown. We now see plots for Signal A (the last day) as a blue plot, and 7 days ago in pink. In order to make this clearer we can click on the Area chart icon to change the visualization. We now have a better view of our two plots!","title":"Using filters"},{"location":"module1/filtering/#using-filters","text":"","title":"Using Filters"},{"location":"module1/filtering/#1-filtering-and-analytics","text":"Let's now select the Paris datacenter to do some analytics - for that we will use a filter. Let's go back to the PLOT EDITOR tab and click on Add filter , wait until it automatically populates, choose demo_datacenter , and then Paris . In the F(x) column, add the analytic function Percentile:Aggregation , and leave the value to 95 (click outside to confirm). For info on the Percentile function and the other functions see Analytics reference .","title":"1. Filtering and Analytics"},{"location":"module1/filtering/#2-using-timeshift-analytical-function","text":"Let's now compare with older metrics. Click on ... and then on Clone in the dropdown to clone Signal A . You will see a new row identical to A , called B , both visible and plotted. For Signal B , in the F(x) column add the analytic function Timeshift and enter 7d (7 days = 1 week), and click outside to confirm. Click on the cog on the far right, and choose a Plot Color e.g. pink, to change color for the plot of B . Click on Close . Next, click into the field next to Time on the Override bar and choose Past Day from the dropdown. We now see plots for Signal A (the last day) as a blue plot, and 7 days ago in pink. In order to make this clearer we can click on the Area chart icon to change the visualization. We now have a better view of our two plots!","title":"2. Using Timeshift analytical function"},{"location":"module1/formulas/","text":"Using Formulas \u00b6 1. Plotting differences \u00b6 Let's now plot the difference of all metric values for a day with 7 days in between. Click on Enter Formula then enter A-B (A minus B) and hide (deselect) all Signals using the eye, except C . We now see only the difference of all metric values of A and B being plotted. We see that we have some negative values on the plot because a metric value of B has some times larger value than the metric value of A at that time. Click on DATA TABLE and in that view swipe horizontally along the X axis to see the metric values at different times. 2. Using Absolute Value \u00b6 Click on PLOT EDITOR to get back to the Plot Editor view. Let's apply another function to get the values of C to positive values. Note By doing so we will see the difference between the metric values for a period of 24 hours with 7 days between. This difference can be used to see an alarming trend if we consider last week to be a baseline (the bigger the number - the more we deviate from the baseline) - but mainly we do this for you to get a bit more training on using analytical functions! In the PLOT EDITOR for C , under F(x) , click on Add Analytics and choose Absolute Value . You will see the C plot now having only positive values.","title":"Using formulas"},{"location":"module1/formulas/#using-formulas","text":"","title":"Using Formulas"},{"location":"module1/formulas/#1-plotting-differences","text":"Let's now plot the difference of all metric values for a day with 7 days in between. Click on Enter Formula then enter A-B (A minus B) and hide (deselect) all Signals using the eye, except C . We now see only the difference of all metric values of A and B being plotted. We see that we have some negative values on the plot because a metric value of B has some times larger value than the metric value of A at that time. Click on DATA TABLE and in that view swipe horizontally along the X axis to see the metric values at different times.","title":"1. Plotting differences"},{"location":"module1/formulas/#2-using-absolute-value","text":"Click on PLOT EDITOR to get back to the Plot Editor view. Let's apply another function to get the values of C to positive values. Note By doing so we will see the difference between the metric values for a period of 24 hours with 7 days between. This difference can be used to see an alarming trend if we consider last week to be a baseline (the bigger the number - the more we deviate from the baseline) - but mainly we do this for you to get a bit more training on using analytical functions! In the PLOT EDITOR for C , under F(x) , click on Add Analytics and choose Absolute Value . You will see the C plot now having only positive values.","title":"2. Using Absolute Value"},{"location":"module1/intro/","text":"Working with Dashboards, Charts and Metrics \u00b6 Introduction to the SignalFx Dashboards and charts Editing and creating charts Filtering and analytical functions Using formulas Introduction to SignalFlow 1. Introduction to the SignalFx UI \u00b6 Logon to the SignalFx organization you have been invited to. Hover over DASHBOARDS in the top menu, and then click on All Dashboards . A number of prebuilt dashboards are provided for you in your default view. If you are already receiving metrics through a Cloud API integration or the Smart Agent you will see relevant dashboards for these services in SignalFx. Among the dashboards you will see a Dashboard group called Sample Data . This group exists by default in all SignalFx accounts. Let's take a closer look at it. 2. Inspecting the Sample Data \u00b6 In this dashboard view expand the Sample Data dashboard group by clicking on it, and then click on the Intro to SignalFx dashboard. You will see a selection of sample charts. To learn more about charts you can click on the other sample dashboards ( PART 1 , PART 2 and PART 3 ). Let's take a look at the Sample charts. Click on the SAMPLE CHARTS dashboard name. In the Sample Charts dashboard you can see a selection of charts that show a sample of the various styles, colors and formats you can apply to your charts in the dashboards.","title":"Introduction"},{"location":"module1/intro/#working-with-dashboards-charts-and-metrics","text":"Introduction to the SignalFx Dashboards and charts Editing and creating charts Filtering and analytical functions Using formulas Introduction to SignalFlow","title":"Working with Dashboards, Charts and Metrics"},{"location":"module1/intro/#1-introduction-to-the-signalfx-ui","text":"Logon to the SignalFx organization you have been invited to. Hover over DASHBOARDS in the top menu, and then click on All Dashboards . A number of prebuilt dashboards are provided for you in your default view. If you are already receiving metrics through a Cloud API integration or the Smart Agent you will see relevant dashboards for these services in SignalFx. Among the dashboards you will see a Dashboard group called Sample Data . This group exists by default in all SignalFx accounts. Let's take a closer look at it.","title":"1. Introduction to the SignalFx UI"},{"location":"module1/intro/#2-inspecting-the-sample-data","text":"In this dashboard view expand the Sample Data dashboard group by clicking on it, and then click on the Intro to SignalFx dashboard. You will see a selection of sample charts. To learn more about charts you can click on the other sample dashboards ( PART 1 , PART 2 and PART 3 ). Let's take a look at the Sample charts. Click on the SAMPLE CHARTS dashboard name. In the Sample Charts dashboard you can see a selection of charts that show a sample of the various styles, colors and formats you can apply to your charts in the dashboards.","title":"2. Inspecting the Sample Data"},{"location":"module1/overlay/","text":"Using Overlays \u00b6 Let's overlay metrics and events to our initial plot to see if there is any correlation with high latency. To discover and add new metrics to the chart from the ones that are being sent to SignalFx already, click on Browse on the bottom of the screen. In the METRICS sidebar on the right, enter demo and click on the search icon to search. Observe that the Find Metrics option is pre-selected. The metrics search is showing 3 metrics with demo in the name. Select demo.trans.count and click on the Add Plot green button. Click on the blue eye icon next to C to hide that Signal, and on the greyed eye icon for Signal A to show it. On plot D , apply the Percentile:Aggregation function and set to 95 . Enter -1h in the Time frame for the entire chart. We see that there is a correlation between latency and number of transactions. Note Likewise we could check Find Events and find events like deployment events etc. to correlate with. Click on the the greater than sign icon to collapse the METRICS sidebar.","title":"Using overlays"},{"location":"module1/overlay/#using-overlays","text":"Let's overlay metrics and events to our initial plot to see if there is any correlation with high latency. To discover and add new metrics to the chart from the ones that are being sent to SignalFx already, click on Browse on the bottom of the screen. In the METRICS sidebar on the right, enter demo and click on the search icon to search. Observe that the Find Metrics option is pre-selected. The metrics search is showing 3 metrics with demo in the name. Select demo.trans.count and click on the Add Plot green button. Click on the blue eye icon next to C to hide that Signal, and on the greyed eye icon for Signal A to show it. On plot D , apply the Percentile:Aggregation function and set to 95 . Enter -1h in the Time frame for the entire chart. We see that there is a correlation between latency and number of transactions. Note Likewise we could check Find Events and find events like deployment events etc. to correlate with. Click on the the greater than sign icon to collapse the METRICS sidebar.","title":"Using Overlays"},{"location":"module1/signalflow/","text":"SignalFlow \u00b6 Let's take a look at SignalFlow - the analytics language of SignalFx that can be used to setup monitoring as code. Click on View SignalFlow . You will see the SignalFlow code that composes the chart we were working on. SignalFlow A = data ( 'demo.trans.latency' , filter = filter ( 'demo_datacenter' , 'Paris' )) . percentile ( pct = 95 ) . publish ( label = 'A' ) B = data ( 'demo.trans.latency' , filter = filter ( 'demo_datacenter' , 'Paris' )) . percentile ( pct = 95 ) . timeshift ( '1w' ) . publish ( label = 'B' , enable = False ) C = ( A - B ) . abs () . publish ( label = 'C' , enable = False ) D = data ( 'demo.trans.count' ) . percentile ( pct = 95 ) . publish ( label = 'D' ) SignalFlow is the analytics language of SignalFx. Among other benefits, it can be used to setup monitoring as code. For more info on SignalFlow see Getting started with SignalFlow . Click on View Builder to go back to the Chart Builder UI.","title":"SignalFlow"},{"location":"module1/signalflow/#signalflow","text":"Let's take a look at SignalFlow - the analytics language of SignalFx that can be used to setup monitoring as code. Click on View SignalFlow . You will see the SignalFlow code that composes the chart we were working on. SignalFlow A = data ( 'demo.trans.latency' , filter = filter ( 'demo_datacenter' , 'Paris' )) . percentile ( pct = 95 ) . publish ( label = 'A' ) B = data ( 'demo.trans.latency' , filter = filter ( 'demo_datacenter' , 'Paris' )) . percentile ( pct = 95 ) . timeshift ( '1w' ) . publish ( label = 'B' , enable = False ) C = ( A - B ) . abs () . publish ( label = 'C' , enable = False ) D = data ( 'demo.trans.count' ) . percentile ( pct = 95 ) . publish ( label = 'D' ) SignalFlow is the analytics language of SignalFx. Among other benefits, it can be used to setup monitoring as code. For more info on SignalFlow see Getting started with SignalFlow . Click on View Builder to go back to the Chart Builder UI.","title":"SignalFlow"},{"location":"module2/detectors/","text":"Working with Detectors - Lab Summary \u00b6 Create a Detector from one of your charts Setting Alert conditions Running a pre-flight check Working with muting rules 1. Create a detector from one of your charts \u00b6 In DASHBOARDS click on your dashboard group (the one with your email address) and then on the dashboard name where the chart you created in the previous lab resides or search for your previously created dashboard's name, and click on that dashboard's name in the results. We are now going to create a new detector from this chart. Once you see the chart, click on the bell icon on your chart and then on New Detector From Chart . In the text field next to Detector Name , ADD YOUR INITIALS before the proposed detector name. Naming the detector It's important that you add your initials in front of the proposed detector name. It should be something like this: LI's Latency Chart Detector . Click on Create Alert Rule . In the Detector window, inside Alert signal , the Signal we will alert on is marked with a (blue) bell in the Alert on column. The bell indicates which Signal is being used to generate the alert. Click on Proceed to Alert Condition . 2. Setting Alert condition \u00b6 In Alert condition , click on Static Threshold and then on Proceed to Alert Settings . In Alert Settings , enter the value 290 in the Threshold field. In the same window change Time on top right to past day ( -1d ). 3. Alert pre-flight check \u00b6 SignalFx will now perform a pre-flight check after 5 seconds. See the Estimated alert count . Based on the current alert settings, the amount of alerts we would\u2019ve received in 1 day would have been approx. 18 . About pre-flight checks Once you set an alert condition, SignalFx shows how many alerts you would get based on the current settings, and in the timeframe set on the upper right corner - in this case, the past day. Immediately, the platform will start analyzing the signals with the current settings, and perform something we call a Pre-flight Check. This enables you to test the alert conditions using the historical data in the platform, to ensure the settings are logical and will not inadvertently generate an alert storm, removing the guess work from configuring alerts in a simple but very powerful way, only available using SignalFx. To read more about detector previewing, please visit this link Setting up detectors . 4. Configuring the alert message \u00b6 In Alert Setting click on Proceed to Alert Message . In Alert message , under Severity choose Major . Click on Proceed to Alert Recipients . Click on Add Recipient and then on your email address displayed as the first option. Notification Services That's the same as entering that email address OR you can enter another email address by clicking on E-mail... . That's just one example of the many Notification Services SignalFx has available. You can check this out by going to the INTEGRATIONS tab of the top menu, and see Notification Services . 5. Activating the alert \u00b6 Click on Proceed to Alert Activation . In Activate... click on Activate Alert Rule . If you want to get alerts quicker you can click back on Alert Settings and lower the value from 290 to say 280 . If you change the Time to -1h you can see how many alerts you might get with the threshold you have chosen based on the metics from the last 1 hour. Hover over ALERTS in the top menu and then click on Detectors . You will see you detector listed here. Congratulations ! You have created your first detector and activated it!","title":"Working with Detectors"},{"location":"module2/detectors/#working-with-detectors-lab-summary","text":"Create a Detector from one of your charts Setting Alert conditions Running a pre-flight check Working with muting rules","title":"Working with Detectors - Lab Summary"},{"location":"module2/detectors/#1-create-a-detector-from-one-of-your-charts","text":"In DASHBOARDS click on your dashboard group (the one with your email address) and then on the dashboard name where the chart you created in the previous lab resides or search for your previously created dashboard's name, and click on that dashboard's name in the results. We are now going to create a new detector from this chart. Once you see the chart, click on the bell icon on your chart and then on New Detector From Chart . In the text field next to Detector Name , ADD YOUR INITIALS before the proposed detector name. Naming the detector It's important that you add your initials in front of the proposed detector name. It should be something like this: LI's Latency Chart Detector . Click on Create Alert Rule . In the Detector window, inside Alert signal , the Signal we will alert on is marked with a (blue) bell in the Alert on column. The bell indicates which Signal is being used to generate the alert. Click on Proceed to Alert Condition .","title":"1. Create a detector from one of your charts"},{"location":"module2/detectors/#2-setting-alert-condition","text":"In Alert condition , click on Static Threshold and then on Proceed to Alert Settings . In Alert Settings , enter the value 290 in the Threshold field. In the same window change Time on top right to past day ( -1d ).","title":"2. Setting Alert condition"},{"location":"module2/detectors/#3-alert-pre-flight-check","text":"SignalFx will now perform a pre-flight check after 5 seconds. See the Estimated alert count . Based on the current alert settings, the amount of alerts we would\u2019ve received in 1 day would have been approx. 18 . About pre-flight checks Once you set an alert condition, SignalFx shows how many alerts you would get based on the current settings, and in the timeframe set on the upper right corner - in this case, the past day. Immediately, the platform will start analyzing the signals with the current settings, and perform something we call a Pre-flight Check. This enables you to test the alert conditions using the historical data in the platform, to ensure the settings are logical and will not inadvertently generate an alert storm, removing the guess work from configuring alerts in a simple but very powerful way, only available using SignalFx. To read more about detector previewing, please visit this link Setting up detectors .","title":"3. Alert pre-flight check"},{"location":"module2/detectors/#4-configuring-the-alert-message","text":"In Alert Setting click on Proceed to Alert Message . In Alert message , under Severity choose Major . Click on Proceed to Alert Recipients . Click on Add Recipient and then on your email address displayed as the first option. Notification Services That's the same as entering that email address OR you can enter another email address by clicking on E-mail... . That's just one example of the many Notification Services SignalFx has available. You can check this out by going to the INTEGRATIONS tab of the top menu, and see Notification Services .","title":"4. Configuring the alert message"},{"location":"module2/detectors/#5-activating-the-alert","text":"Click on Proceed to Alert Activation . In Activate... click on Activate Alert Rule . If you want to get alerts quicker you can click back on Alert Settings and lower the value from 290 to say 280 . If you change the Time to -1h you can see how many alerts you might get with the threshold you have chosen based on the metics from the last 1 hour. Hover over ALERTS in the top menu and then click on Detectors . You will see you detector listed here. Congratulations ! You have created your first detector and activated it!","title":"5. Activating the alert"},{"location":"module2/muting/","text":"Working with Muting Rules - Lab Summary \u00b6 Learn how to configure how to mute Alerts 1. Learn how to configure muting your alerts \u00b6 There will be times when you might want to mute certain notifications. For example, if you want to schedule downtime for maintenance on a server or set of servers, or if you are testing new code or settings etc. For that you can use muting rules in SignalFx. Let's create one! Hover over ALERTS in the menu and from the drop down click on Detectors . You will see a list of active detectors. If you created an detector in Working with Detectors you can click on the three dots ... on the far right for that detector; if not, do that for another detector. From the drop-down click on Create Muting Rule... . In the Muting Rule window check Mute Indefinitely and enter a reason. Note This will mute the nofications permanently until you come back here and un-check this box or resume notifications for this detector. Click Next and in the new modal window confirm the muting rule setup. Click on Mute Indefinitely button to confirm. You won't be receiving any email notifications from you detector until you resume notifications again. Let's now see how to do that! 2. Resuming notifications \u00b6 To Resume notifications, hover over ALERTS in the top menu and click on Muting Rules . You will see the name of the detector you muted notifications for under Detector . Click on the thee dots ... on the far right. Click on Resume Notifications . Click on Resume to confirm and resume notifications for this detector. Congratulations! You have now resumed your alert notifications!","title":"Working with Muting Rules"},{"location":"module2/muting/#working-with-muting-rules-lab-summary","text":"Learn how to configure how to mute Alerts","title":"Working with Muting Rules - Lab Summary"},{"location":"module2/muting/#1-learn-how-to-configure-muting-your-alerts","text":"There will be times when you might want to mute certain notifications. For example, if you want to schedule downtime for maintenance on a server or set of servers, or if you are testing new code or settings etc. For that you can use muting rules in SignalFx. Let's create one! Hover over ALERTS in the menu and from the drop down click on Detectors . You will see a list of active detectors. If you created an detector in Working with Detectors you can click on the three dots ... on the far right for that detector; if not, do that for another detector. From the drop-down click on Create Muting Rule... . In the Muting Rule window check Mute Indefinitely and enter a reason. Note This will mute the nofications permanently until you come back here and un-check this box or resume notifications for this detector. Click Next and in the new modal window confirm the muting rule setup. Click on Mute Indefinitely button to confirm. You won't be receiving any email notifications from you detector until you resume notifications again. Let's now see how to do that!","title":"1. Learn how to configure muting your alerts"},{"location":"module2/muting/#2-resuming-notifications","text":"To Resume notifications, hover over ALERTS in the top menu and click on Muting Rules . You will see the name of the detector you muted notifications for under Detector . Click on the thee dots ... on the far right. Click on Resume Notifications . Click on Resume to confirm and resume notifications for this detector. Congratulations! You have now resumed your alert notifications!","title":"2. Resuming notifications"},{"location":"module3/service_bureau/","text":"Service Bureau - Lab Summary \u00b6 How to keep track of the usage of SignalFx in your organization Learn how to keep track of spend by exploring the Billing and Usage interface Creating Teams Adding notification rules to Teams Controlling Team usage 1. Understanding SignalFx engagement \u00b6 To fully understand SignalFx engagement inside your organization, click on the Settings icon on the top right of the SignalFx UI. It may also look like this From the drop down, select the Organizations Settings \u2192 Organization Overview , this will provide you with the following dashboard that shows you how your SignalFx organization is being used: On the left hand menu (not shown in the above screenshot) you will see a list of members, and in the centre, various charts that show you the number of users, teams, charts, dashboards, and dashboard groups created, as well as various growth trends. The screenshot is taken from an demonstration organization, the Workshop organization you're looking at may have less data to work with as this is cleared down after each workshop. Take a minute to explore the various charts in the Organization Overview of this Workshop instance. 2. Usage and Billing \u00b6 If you want to see what your usage is against your contract you can select the Organizations Settings \u2192 Billing and Usage from your profile icon top right of the SignalFx UI. Or the faster way is to select the Billing and Usage item from the left hand pane. This screen may take a few seconds to load whilst it calculates and pulls in the usage. 3. Understanding usage \u00b6 You will see a screen similar like the one below that will give you an overview of the current usage, the average usage and your entitlement per category : Hosts, Containers, Custom Metrics and High Resolution Metrics. For more information about about these categories please refer to Billing and Usage information 4. Examine usage in detail \u00b6 The top chart shows you the current subscription levels per category (shown by the red arrows at the top in the screenshot below). Also, your current usage of the four catagories is displayed (shown at the red lines at the bottom of the chart). In this example you can see that there are 18 Hosts, 0 Containers and 1038 Custom Metrics and 0 High Resolution Metrics. In the bottom chart, you can see the usage per category for the current period (shown in the drop-down box on the top right of the chart). The blue line marked Average Usage indicates what SignalFx will use to calculate your average usage for the current billing period. Info As you can see from the screenshot, SignalFx does not use High Watermark or P95% for cost calculation but the actual average hourly usage, allowing you to do performance testing or Blue/Green style deployments etc. without the risk of overage charges. To get a feel for the options you can change the metric displayed by selecting the different options from the Usage Metric drop down on the left, or change the the Billing Period with the drop down on the right. Please take a minute to explore the different time periods & categories and their views. Finally, the pane on the right shows you information about your Subscription.","title":"Billing and Usage"},{"location":"module3/service_bureau/#service-bureau-lab-summary","text":"How to keep track of the usage of SignalFx in your organization Learn how to keep track of spend by exploring the Billing and Usage interface Creating Teams Adding notification rules to Teams Controlling Team usage","title":"Service Bureau - Lab Summary"},{"location":"module3/service_bureau/#1-understanding-signalfx-engagement","text":"To fully understand SignalFx engagement inside your organization, click on the Settings icon on the top right of the SignalFx UI. It may also look like this From the drop down, select the Organizations Settings \u2192 Organization Overview , this will provide you with the following dashboard that shows you how your SignalFx organization is being used: On the left hand menu (not shown in the above screenshot) you will see a list of members, and in the centre, various charts that show you the number of users, teams, charts, dashboards, and dashboard groups created, as well as various growth trends. The screenshot is taken from an demonstration organization, the Workshop organization you're looking at may have less data to work with as this is cleared down after each workshop. Take a minute to explore the various charts in the Organization Overview of this Workshop instance.","title":"1. Understanding SignalFx engagement"},{"location":"module3/service_bureau/#2-usage-and-billing","text":"If you want to see what your usage is against your contract you can select the Organizations Settings \u2192 Billing and Usage from your profile icon top right of the SignalFx UI. Or the faster way is to select the Billing and Usage item from the left hand pane. This screen may take a few seconds to load whilst it calculates and pulls in the usage.","title":"2. Usage and Billing"},{"location":"module3/service_bureau/#3-understanding-usage","text":"You will see a screen similar like the one below that will give you an overview of the current usage, the average usage and your entitlement per category : Hosts, Containers, Custom Metrics and High Resolution Metrics. For more information about about these categories please refer to Billing and Usage information","title":"3. Understanding usage"},{"location":"module3/service_bureau/#4-examine-usage-in-detail","text":"The top chart shows you the current subscription levels per category (shown by the red arrows at the top in the screenshot below). Also, your current usage of the four catagories is displayed (shown at the red lines at the bottom of the chart). In this example you can see that there are 18 Hosts, 0 Containers and 1038 Custom Metrics and 0 High Resolution Metrics. In the bottom chart, you can see the usage per category for the current period (shown in the drop-down box on the top right of the chart). The blue line marked Average Usage indicates what SignalFx will use to calculate your average usage for the current billing period. Info As you can see from the screenshot, SignalFx does not use High Watermark or P95% for cost calculation but the actual average hourly usage, allowing you to do performance testing or Blue/Green style deployments etc. without the risk of overage charges. To get a feel for the options you can change the metric displayed by selecting the different options from the Usage Metric drop down on the left, or change the the Billing Period with the drop down on the right. Please take a minute to explore the different time periods & categories and their views. Finally, the pane on the right shows you information about your Subscription.","title":"4. Examine usage in detail"},{"location":"module3/teams/","text":"Teams - Lab Summary \u00b6 Introduction to Teams Create a Team and add members to Team Discover how you can restrict usage for Teams by creating separate access tokens and set limits. 1. Introduction to Teams \u00b6 To make sure that users see the dashboards and alerts that are relevant to them when using SignalFX, most organizations will use SignalFx's Teams feature to assign a member to one or more Teams. Ideally, this matches work related roles, for example, members of a Dev-Ops or Product Management group would be assigned to the corresponding Teams in SignalFx. When a user logs into SignalFx, they can choose which Team Dashboard will be their home page and they will typically select the page for their primary role. In the example below, the user is a member of the Development, Operations and Product Management Teams, and is currently viewing the Dashboard for the Operations Team. This Dashboard has specific Dashboard Groups for NGINX, Infra and K8s assigned but any Dashboard Group can be linked to a Teams Dashboard. They can use the menu along the top left to quickly navigate between their allocated teams, or they can use the ALL TEAMS dropdown on the right to select specific Team Dashboards, as well as quickly accessing ALL DASHBOARDS using the adjacent link. Alerts can be linked to specific Teams so the Team can monitor only the Alerts they are interested in, and in the above example they currently have 1 active Critical Alert. The Description for the Team Dashboard can be customized and can include links to team specific resources (using Markdown). 2. Creating a new Team \u00b6 To work with to SignalFx's Team UI click on the Settings icon on the top right of the SignalFx UI. It may also look like this . Select the Organizations Settings \u2192 Teams tab, or select the Teams tab from the left pane. When the Team UI is selected you will be presented with the list of current Teams. To add a new Team click on the green button. This will present you with the Create New Team dialog. Create your own team by naming it [YOUR-INITIALS]-Team and add yourself by searching for your name and selecting the Add link next to your name. This should result in a dialog similar to the one below: You can remove selected users by pressing Remove or the small x . Make sure you have your group created with your initials and with yourself added as a member, then click Done . This will bring you back to the Teams list that will now show your Team and the one's created by others. Note The Teams(s) you are a member of have a grey Member icon in front of it. If no members are assigned to your Team, you should see a blue Add Members link instead of the member count, clicking on that link will get you to the Edit Team dialog where you can add yourself. This is the same dialog you get when pressing the 3 dots ... at the end of the line with your Team and selecting Edit Team The ... menu gives you the option to Edit, Join, Leave or Delete a Team (leave and join will depend on if you are currently a member). 3. Adding Notification Rules \u00b6 You can set up specific Notification rules per team, click on the NOTIFICATION POLICY tab, this will open the notification edit menu. By default the system offers you the ability to set up a general notification rule for your team. Note The Email all team members option means all members of this Team will receive an email with the Alert information, regardless of the alert type. 3.1 Adding recipients \u00b6 You can add other recipients, by clicking . These recipients do not need to be SignalFx users. However if you click on the link Configure separate notification tiers for different severity alerts you can configure every alert level independently. Different alert rules for the different alert levels can be configured, as shown in the above image. Critical and Major are using Splunk's VictorOps Incident Management solution. For the Minor alerts we send it to the Teams Slack channel and for Warning and Info we send an email. 3.2 Notification Integrations \u00b6 In addition to sending alert notifications via email, you can configure SignalFx to send alert notifications to the services shown below. Take a moment to create some notification rules for you Team. 4. Controlling a Team's usage \u00b6 If you wish to control the consumption of Hosts, Containers, Custom Metrics and High Resolution Metrics, you can create multiple Access Tokens and allocate them to different parts of your organization. Assuming you are still within the Organization Overview section, simply select the Access Tokens tab from the left pane. However to get to this section from anywhere click on the settings icon at the top right top of the page and select Organizations Settings \u2192 Access tokens The Access Tokens Interface provides an overview of your Allotments in the form of a list of Access Tokens that have been generated. Every Organization will have a Default token generated when they are first setup, but there will typically be multiple Tokens configured. Each Token is unique and can be assigned limits for the amount of Hosts, Containers, Custom Metrics and High Resolution Metrics it can consume. The Usage Status Column quickly shows if a token is above or below its assigned limits. 4.1 Creating a new token \u00b6 Let create a new token by clicking on the button. This will provide you with the Name Your Access Token dialog. Enter the new name of the new Token by using your Initials e.g. PH-Token After you press Ok, you will be taken back to the Access Token UI, here your new token should be present, among the ones created by others. If you have made an error in your naming, want to disable/enable a token or set a Token limit, click on the 3 ... menu button behind a token limit to open the manage token menu. If you made a typo you can use the Rename Token option to correct the name of your token. 4.2 Disabling a token \u00b6 If you need to make sure a token cannot be used to send Metrics in you can Disable a token. Click on the Disable button to Disable the token, this means the token cannot be used for sending in data to SignalFX. The line with Your Token should become greyed out to indicate that is has been Disabled as you can see in the screenshot below. Go ahead and click on the 3 ... menu button to Disable and Enable your token. 4.3 Manage token usage limits \u00b6 Now Lets start limiting usage by clicking on Manage Token Limit in the 3 ... menu. This will show the Manage Token Limit Dialog: In this Dialog you can set the limits per category. Please go ahead and specify the limits as shown above for each usage metric. For our lab use your own email address, and double check that you have the correct numbers in your dialog box as shown above. Token limits are used to trigger an alert that notify one or more recipients when the usage has been above 90% of the limit for 5 minutes. To specify the recipients, click Add Recipient, then select the recipient or notification method you want to use. (Specifying recipients is optional but highly recommended.) The severity for token alerts is always Critical. Click on Update to save your Access Tokens limits and The Alert Settings. Note When a token is at or above its limit in a usage category, new metrics for that usage category will not be stored and processed by SignalFx. This will make sure you there will be no unexpected cost due to a team sending in data without restriction. Note If you wish to get alerts before you hit 90%, you can create additional detectors using whatever values you want. These detectors could target the Teams consuming the specific Access Tokens so they can take action before the admins need to get involved. In your company you would distribute these new Access Tokens to various teams, controlling how much information/data they can send to SignalFx. This will allow you to fine tune the way you consume your SignalFx allotment and stop expensive surprises from happening. Congratulations! You have now have completed the Service Bureau module.","title":"Teams"},{"location":"module3/teams/#teams-lab-summary","text":"Introduction to Teams Create a Team and add members to Team Discover how you can restrict usage for Teams by creating separate access tokens and set limits.","title":"Teams - Lab Summary"},{"location":"module3/teams/#1-introduction-to-teams","text":"To make sure that users see the dashboards and alerts that are relevant to them when using SignalFX, most organizations will use SignalFx's Teams feature to assign a member to one or more Teams. Ideally, this matches work related roles, for example, members of a Dev-Ops or Product Management group would be assigned to the corresponding Teams in SignalFx. When a user logs into SignalFx, they can choose which Team Dashboard will be their home page and they will typically select the page for their primary role. In the example below, the user is a member of the Development, Operations and Product Management Teams, and is currently viewing the Dashboard for the Operations Team. This Dashboard has specific Dashboard Groups for NGINX, Infra and K8s assigned but any Dashboard Group can be linked to a Teams Dashboard. They can use the menu along the top left to quickly navigate between their allocated teams, or they can use the ALL TEAMS dropdown on the right to select specific Team Dashboards, as well as quickly accessing ALL DASHBOARDS using the adjacent link. Alerts can be linked to specific Teams so the Team can monitor only the Alerts they are interested in, and in the above example they currently have 1 active Critical Alert. The Description for the Team Dashboard can be customized and can include links to team specific resources (using Markdown).","title":"1. Introduction to Teams"},{"location":"module3/teams/#2-creating-a-new-team","text":"To work with to SignalFx's Team UI click on the Settings icon on the top right of the SignalFx UI. It may also look like this . Select the Organizations Settings \u2192 Teams tab, or select the Teams tab from the left pane. When the Team UI is selected you will be presented with the list of current Teams. To add a new Team click on the green button. This will present you with the Create New Team dialog. Create your own team by naming it [YOUR-INITIALS]-Team and add yourself by searching for your name and selecting the Add link next to your name. This should result in a dialog similar to the one below: You can remove selected users by pressing Remove or the small x . Make sure you have your group created with your initials and with yourself added as a member, then click Done . This will bring you back to the Teams list that will now show your Team and the one's created by others. Note The Teams(s) you are a member of have a grey Member icon in front of it. If no members are assigned to your Team, you should see a blue Add Members link instead of the member count, clicking on that link will get you to the Edit Team dialog where you can add yourself. This is the same dialog you get when pressing the 3 dots ... at the end of the line with your Team and selecting Edit Team The ... menu gives you the option to Edit, Join, Leave or Delete a Team (leave and join will depend on if you are currently a member).","title":"2. Creating a new Team"},{"location":"module3/teams/#3-adding-notification-rules","text":"You can set up specific Notification rules per team, click on the NOTIFICATION POLICY tab, this will open the notification edit menu. By default the system offers you the ability to set up a general notification rule for your team. Note The Email all team members option means all members of this Team will receive an email with the Alert information, regardless of the alert type.","title":"3. Adding Notification Rules"},{"location":"module3/teams/#31-adding-recipients","text":"You can add other recipients, by clicking . These recipients do not need to be SignalFx users. However if you click on the link Configure separate notification tiers for different severity alerts you can configure every alert level independently. Different alert rules for the different alert levels can be configured, as shown in the above image. Critical and Major are using Splunk's VictorOps Incident Management solution. For the Minor alerts we send it to the Teams Slack channel and for Warning and Info we send an email.","title":"3.1 Adding recipients"},{"location":"module3/teams/#32-notification-integrations","text":"In addition to sending alert notifications via email, you can configure SignalFx to send alert notifications to the services shown below. Take a moment to create some notification rules for you Team.","title":"3.2 Notification Integrations"},{"location":"module3/teams/#4-controlling-a-teams-usage","text":"If you wish to control the consumption of Hosts, Containers, Custom Metrics and High Resolution Metrics, you can create multiple Access Tokens and allocate them to different parts of your organization. Assuming you are still within the Organization Overview section, simply select the Access Tokens tab from the left pane. However to get to this section from anywhere click on the settings icon at the top right top of the page and select Organizations Settings \u2192 Access tokens The Access Tokens Interface provides an overview of your Allotments in the form of a list of Access Tokens that have been generated. Every Organization will have a Default token generated when they are first setup, but there will typically be multiple Tokens configured. Each Token is unique and can be assigned limits for the amount of Hosts, Containers, Custom Metrics and High Resolution Metrics it can consume. The Usage Status Column quickly shows if a token is above or below its assigned limits.","title":"4. Controlling a Team's usage"},{"location":"module3/teams/#41-creating-a-new-token","text":"Let create a new token by clicking on the button. This will provide you with the Name Your Access Token dialog. Enter the new name of the new Token by using your Initials e.g. PH-Token After you press Ok, you will be taken back to the Access Token UI, here your new token should be present, among the ones created by others. If you have made an error in your naming, want to disable/enable a token or set a Token limit, click on the 3 ... menu button behind a token limit to open the manage token menu. If you made a typo you can use the Rename Token option to correct the name of your token.","title":"4.1 Creating a new token"},{"location":"module3/teams/#42-disabling-a-token","text":"If you need to make sure a token cannot be used to send Metrics in you can Disable a token. Click on the Disable button to Disable the token, this means the token cannot be used for sending in data to SignalFX. The line with Your Token should become greyed out to indicate that is has been Disabled as you can see in the screenshot below. Go ahead and click on the 3 ... menu button to Disable and Enable your token.","title":"4.2 Disabling a token"},{"location":"module3/teams/#43-manage-token-usage-limits","text":"Now Lets start limiting usage by clicking on Manage Token Limit in the 3 ... menu. This will show the Manage Token Limit Dialog: In this Dialog you can set the limits per category. Please go ahead and specify the limits as shown above for each usage metric. For our lab use your own email address, and double check that you have the correct numbers in your dialog box as shown above. Token limits are used to trigger an alert that notify one or more recipients when the usage has been above 90% of the limit for 5 minutes. To specify the recipients, click Add Recipient, then select the recipient or notification method you want to use. (Specifying recipients is optional but highly recommended.) The severity for token alerts is always Critical. Click on Update to save your Access Tokens limits and The Alert Settings. Note When a token is at or above its limit in a usage category, new metrics for that usage category will not be stored and processed by SignalFx. This will make sure you there will be no unexpected cost due to a team sending in data without restriction. Note If you wish to get alerts before you hit 90%, you can create additional detectors using whatever values you want. These detectors could target the Teams consuming the specific Access Tokens so they can take action before the admins need to get involved. In your company you would distribute these new Access Tokens to various teams, controlling how much information/data they can send to SignalFx. This will allow you to fine tune the way you consume your SignalFx allotment and stop expensive surprises from happening. Congratulations! You have now have completed the Service Bureau module.","title":"4.3 Manage token usage limits"},{"location":"module4/k3s/","text":"Deploying the Smart Agent in Kubernetes (K3s) \u00b6 Use the SignalFx Helm chart to install the Smart Agent in K3s Explore your cluster in the Kubernetes Navigator 1. Obtain SignalFx Access Token \u00b6 You will need to obtain your Access Token from the SignalFx UI once Kubernetes is running. You can find your Access Token by clicking on your profile icon on the top right of the SignalFx UI. Then select Organization Settings \u2192 Access Tokens . Expand the Default token, then click on Show Token to expose your token. Click the Copy button to copy to clipboard. You will also need to obtain the name of the Realm for your SignalFx account. Click on the profile icon again, but this time select My Profile . The Realm can be found in the middle of the page within the Organizations section. In this example it is us1 . 2. Use Helm to deploy agent \u00b6 Create the following variables to use in the proceeding helm install command, replacing [VARIABLE] with the appropriate values. For instance, if your realm is us1 , you would export REALM=us1 . Input export ACCESS_TOKEN=[ACCESS_TOKEN] export REALM=[REALM e.g. us1] export INITIALS=[YOUR_INITIALS e.g. RWC] export VERSION=[VERSION e.g. 5.1.2] Note The latest version of the Smart Agent can be found on GitHub Install the agent using the SignalFx Helm chart. Firstly, add the SignalFx Helm chart repository to Helm. Input helm repo add signalfx https://dl.signalfx.com/helm-repo Ensure the latest version of the SignalFx Helm repository Input helm repo update Install the Smart Agent Helm chart with the following commands: Input : ${ACCESS_TOKEN:? needs to be set} : ${REALM:? needs to be set} : ${INITIALS:? needs to be set} : ${VERSION:? needs to be set} sed -i -e 's/\\[INITIALS\\]/'\"$INITIALS\"'/' ~/workshop/k3s/values.yaml helm install \\ --set signalFxAccessToken=$ACCESS_TOKEN \\ --set clusterName=$INITIALS-SFX-WORKSHOP \\ --set kubeletAPI.url=https://localhost:10250 \\ --set signalFxRealm=$REALM \\ --set agentVersion=$VERSION \\ --set traceEndpointUrl=https://ingest.$REALM.signalfx.com/v2/trace \\ --set gatherDockerMetrics=false \\ signalfx-agent signalfx/signalfx-agent \\ -f ~/workshop/k3s/values.yaml You can monitor the progress of the deployment by running kubectl get pods which should typically report a new pod is up and running after about 30 seconds. Ensure the status is reported as Running before continuing. Input kubectl get pods Output NAME READY STATUS RESTARTS AGE signalfx-agent-66tvr 1/1 Running 0 7s Ensure there are no errors by tailing the logs from the Smart Agent Pod. Output should look similar to the log output shown below. Use the label set by the helm install to tail logs (You will need to press Ctrl + C to exit). Or use the installed k9s terminal UI for bonus points! Input kubectl logs -l app = signalfx-agent -f Output time=\"2020-03-15T11:30:28Z\" level=info msg=\"Starting up agent version 5.0.0\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Watching for config file changes\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"New config loaded\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Using log level info\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Fetching host id dimensions\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Trying to get fully qualified hostname\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Using hostname PH-k3s\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Using host id dimensions map[host:PH-k3s kubernetes_node_uid:05ba9d7b-89d4-4c70-a3e9-4dc72923423a]\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Sending datapoints to https://ingest.us1.signalfx.com/v2/datapoint\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Sending events to https://ingest.us1.signalfx.com/v2/event\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=10 monitorType=kubelet-stats time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=11 monitorType=kubernetes-cluster time=\"2020-03-15T11:30:29Z\" level=info msg=\"Done configuring agent\" ... time=\"2020-03-15T11:30:29Z\" level=info msg=\"Serving internal metrics at localhost:8095\" I0315 11:30:29.922577 1 leaderelection.go:242] attempting to acquire leader lease default/signalfx-agent-leader... I0315 11:30:29.950448 1 leaderelection.go:252] successfully acquired lease default/signalfx-agent-leader time=\"2020-03-15T11:30:29Z\" level=info msg=\"K8s leader is now node ph-k3s\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Starting K8s API resource sync\" ... 3. Validate metrics in the UI \u00b6 In the SignalFx UI, goto INFRASTRUCTURE \u2192 Kubernetes Navigator \u2192 Cluster Map and open the Kubernetes Navigator Cluster Map to ensure metrics are being sent. Validate that your cluster is discovered and reporting by finding your cluster by searching for [YOUR_INITIALS]-SFX-WORKSHOP (in the workshop you will see many other clusters). To examine the health of your node, first click on the blue cross on your cluster. This will drill down to the node level. Next, open the side bar by clicking on the side bar button to open the Metrics side bar. Once it is open, you can use the slider on the side to explore the various charts relevant to your cluster/node: CPU, Memory, Network, Events etc.","title":"Deploy the Smart Agent in K3s"},{"location":"module4/k3s/#deploying-the-smart-agent-in-kubernetes-k3s","text":"Use the SignalFx Helm chart to install the Smart Agent in K3s Explore your cluster in the Kubernetes Navigator","title":"Deploying the Smart Agent in Kubernetes (K3s)"},{"location":"module4/k3s/#1-obtain-signalfx-access-token","text":"You will need to obtain your Access Token from the SignalFx UI once Kubernetes is running. You can find your Access Token by clicking on your profile icon on the top right of the SignalFx UI. Then select Organization Settings \u2192 Access Tokens . Expand the Default token, then click on Show Token to expose your token. Click the Copy button to copy to clipboard. You will also need to obtain the name of the Realm for your SignalFx account. Click on the profile icon again, but this time select My Profile . The Realm can be found in the middle of the page within the Organizations section. In this example it is us1 .","title":"1. Obtain SignalFx Access Token"},{"location":"module4/k3s/#2-use-helm-to-deploy-agent","text":"Create the following variables to use in the proceeding helm install command, replacing [VARIABLE] with the appropriate values. For instance, if your realm is us1 , you would export REALM=us1 . Input export ACCESS_TOKEN=[ACCESS_TOKEN] export REALM=[REALM e.g. us1] export INITIALS=[YOUR_INITIALS e.g. RWC] export VERSION=[VERSION e.g. 5.1.2] Note The latest version of the Smart Agent can be found on GitHub Install the agent using the SignalFx Helm chart. Firstly, add the SignalFx Helm chart repository to Helm. Input helm repo add signalfx https://dl.signalfx.com/helm-repo Ensure the latest version of the SignalFx Helm repository Input helm repo update Install the Smart Agent Helm chart with the following commands: Input : ${ACCESS_TOKEN:? needs to be set} : ${REALM:? needs to be set} : ${INITIALS:? needs to be set} : ${VERSION:? needs to be set} sed -i -e 's/\\[INITIALS\\]/'\"$INITIALS\"'/' ~/workshop/k3s/values.yaml helm install \\ --set signalFxAccessToken=$ACCESS_TOKEN \\ --set clusterName=$INITIALS-SFX-WORKSHOP \\ --set kubeletAPI.url=https://localhost:10250 \\ --set signalFxRealm=$REALM \\ --set agentVersion=$VERSION \\ --set traceEndpointUrl=https://ingest.$REALM.signalfx.com/v2/trace \\ --set gatherDockerMetrics=false \\ signalfx-agent signalfx/signalfx-agent \\ -f ~/workshop/k3s/values.yaml You can monitor the progress of the deployment by running kubectl get pods which should typically report a new pod is up and running after about 30 seconds. Ensure the status is reported as Running before continuing. Input kubectl get pods Output NAME READY STATUS RESTARTS AGE signalfx-agent-66tvr 1/1 Running 0 7s Ensure there are no errors by tailing the logs from the Smart Agent Pod. Output should look similar to the log output shown below. Use the label set by the helm install to tail logs (You will need to press Ctrl + C to exit). Or use the installed k9s terminal UI for bonus points! Input kubectl logs -l app = signalfx-agent -f Output time=\"2020-03-15T11:30:28Z\" level=info msg=\"Starting up agent version 5.0.0\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Watching for config file changes\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"New config loaded\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Using log level info\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Fetching host id dimensions\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Trying to get fully qualified hostname\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Using hostname PH-k3s\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Using host id dimensions map[host:PH-k3s kubernetes_node_uid:05ba9d7b-89d4-4c70-a3e9-4dc72923423a]\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Sending datapoints to https://ingest.us1.signalfx.com/v2/datapoint\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Sending events to https://ingest.us1.signalfx.com/v2/event\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=10 monitorType=kubelet-stats time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=11 monitorType=kubernetes-cluster time=\"2020-03-15T11:30:29Z\" level=info msg=\"Done configuring agent\" ... time=\"2020-03-15T11:30:29Z\" level=info msg=\"Serving internal metrics at localhost:8095\" I0315 11:30:29.922577 1 leaderelection.go:242] attempting to acquire leader lease default/signalfx-agent-leader... I0315 11:30:29.950448 1 leaderelection.go:252] successfully acquired lease default/signalfx-agent-leader time=\"2020-03-15T11:30:29Z\" level=info msg=\"K8s leader is now node ph-k3s\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Starting K8s API resource sync\" ...","title":"2. Use Helm to deploy agent"},{"location":"module4/k3s/#3-validate-metrics-in-the-ui","text":"In the SignalFx UI, goto INFRASTRUCTURE \u2192 Kubernetes Navigator \u2192 Cluster Map and open the Kubernetes Navigator Cluster Map to ensure metrics are being sent. Validate that your cluster is discovered and reporting by finding your cluster by searching for [YOUR_INITIALS]-SFX-WORKSHOP (in the workshop you will see many other clusters). To examine the health of your node, first click on the blue cross on your cluster. This will drill down to the node level. Next, open the side bar by clicking on the side bar button to open the Metrics side bar. Once it is open, you can use the slider on the side to explore the various charts relevant to your cluster/node: CPU, Memory, Network, Events etc.","title":"3. Validate metrics in the UI"},{"location":"module4/nginx/","text":"Deploying NGINX in K3s - Lab Summary \u00b6 Deploy a NGINX ReplicaSet into your K3s cluster and confirm the auto discovery of your NGINX deployment. Run a benchmark test to create metrics and confirm them streaming into SignalFX! 1. Start your NGINX \u00b6 Remain in the Multipass or AWS/EC2 shell session and change into the nginx directory: Input cd ~/workshop/k3s/nginx Verify the number of pods running in the SignalFx UI by selecting the WORKLOADS tab. This should give you an overview of the workloads on your cluster. Note the single agent container running per node among the default Kubernetes pods. This single container will monitor all the pods and services being deployed on this node! Now switch back to the default cluster node view by selecting the MAP tab and select your cluster again. 2. Create NGINX deployment \u00b6 Create the NGINX configmap using the nginx.conf file: Input kubectl create configmap nginxconfig --from-file=nginx.conf Output configmap/nginxconfig created Then create the deployment: Input kubectl create -f nginx-deployment.yaml Output deployment.apps/nginx-deployment created Validate the deployment has been successful and that the NGINX pods are running. If you have the SignalFx UI open you should see new Pods being started and containers being deployed. It should only take around 20 seconds for the pods to transition into a Running state. In the SignalFx UI you should have a cluster that looks like below: If you select the WORKLOADS tab again you should now see that there is a new replica set and a deployment added for NGINX: Let's validate this in your shell as well: Input kubectl get pods Output NAME READY STATUS RESTARTS AGE signalfx-agent-n7nz2 1/1 Running 0 11m nginx-deployment-f96cf6966-jhmjp 1/1 Running 0 21s nginx-deployment-f96cf6966-459vf 1/1 Running 0 21s nginx-deployment-f96cf6966-vrnfc 1/1 Running 0 21s nginx-deployment-f96cf6966-7z4tm 1/1 Running 0 21s Before running a benchmark against NGINX (to generate metrics) we need to expose port 80 (HTTP) Input kubectl create service nodeport nginx --tcp=80:80 Output service/nginx created Run kubectl get svc then make a note of the CLUSTER-IP address that is allocated to the NGINX service. Input kubectl get svc Output NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.96.0.1 <none> 443/TCP 9m3s nginx NodePort 10.110.36.62 <none> 80:30995/TCP 8s 3. Run Apache Benchmark \u00b6 Using the NGINX CLUSTER-IP address reported from above, use Apache Benchmark command ( ab ) to generate some traffic to light up your SignalFx NGINX dashboard. Run this a couple of times! Input ab -n1000 -c20 http://[INSERT_NGINX_IP_ADDRESS]/ Output This is ApacheBench, Version 2.3 <$Revision: 1826891 $> Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking localhost (be patient) Completed 100 requests ... Completed 1000 requests Finished 1000 requests Server Software: nginx/1.17.5 Server Hostname: localhost Server Port: 30995 ... Validate you are seeing metrics in the UI by going to Dashboards \u2192 NGINX \u2192 NGINX Servers Tip You can again apply the filter kubernetes_cluster: [YOUR_INITIALS]-SFX-WORKSHOP to focus on only your metrics.","title":"Deploy NGINX in K3s"},{"location":"module4/nginx/#deploying-nginx-in-k3s-lab-summary","text":"Deploy a NGINX ReplicaSet into your K3s cluster and confirm the auto discovery of your NGINX deployment. Run a benchmark test to create metrics and confirm them streaming into SignalFX!","title":"Deploying NGINX in K3s - Lab Summary"},{"location":"module4/nginx/#1-start-your-nginx","text":"Remain in the Multipass or AWS/EC2 shell session and change into the nginx directory: Input cd ~/workshop/k3s/nginx Verify the number of pods running in the SignalFx UI by selecting the WORKLOADS tab. This should give you an overview of the workloads on your cluster. Note the single agent container running per node among the default Kubernetes pods. This single container will monitor all the pods and services being deployed on this node! Now switch back to the default cluster node view by selecting the MAP tab and select your cluster again.","title":"1. Start your NGINX"},{"location":"module4/nginx/#2-create-nginx-deployment","text":"Create the NGINX configmap using the nginx.conf file: Input kubectl create configmap nginxconfig --from-file=nginx.conf Output configmap/nginxconfig created Then create the deployment: Input kubectl create -f nginx-deployment.yaml Output deployment.apps/nginx-deployment created Validate the deployment has been successful and that the NGINX pods are running. If you have the SignalFx UI open you should see new Pods being started and containers being deployed. It should only take around 20 seconds for the pods to transition into a Running state. In the SignalFx UI you should have a cluster that looks like below: If you select the WORKLOADS tab again you should now see that there is a new replica set and a deployment added for NGINX: Let's validate this in your shell as well: Input kubectl get pods Output NAME READY STATUS RESTARTS AGE signalfx-agent-n7nz2 1/1 Running 0 11m nginx-deployment-f96cf6966-jhmjp 1/1 Running 0 21s nginx-deployment-f96cf6966-459vf 1/1 Running 0 21s nginx-deployment-f96cf6966-vrnfc 1/1 Running 0 21s nginx-deployment-f96cf6966-7z4tm 1/1 Running 0 21s Before running a benchmark against NGINX (to generate metrics) we need to expose port 80 (HTTP) Input kubectl create service nodeport nginx --tcp=80:80 Output service/nginx created Run kubectl get svc then make a note of the CLUSTER-IP address that is allocated to the NGINX service. Input kubectl get svc Output NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.96.0.1 <none> 443/TCP 9m3s nginx NodePort 10.110.36.62 <none> 80:30995/TCP 8s","title":"2. Create NGINX deployment"},{"location":"module4/nginx/#3-run-apache-benchmark","text":"Using the NGINX CLUSTER-IP address reported from above, use Apache Benchmark command ( ab ) to generate some traffic to light up your SignalFx NGINX dashboard. Run this a couple of times! Input ab -n1000 -c20 http://[INSERT_NGINX_IP_ADDRESS]/ Output This is ApacheBench, Version 2.3 <$Revision: 1826891 $> Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking localhost (be patient) Completed 100 requests ... Completed 1000 requests Finished 1000 requests Server Software: nginx/1.17.5 Server Hostname: localhost Server Port: 30995 ... Validate you are seeing metrics in the UI by going to Dashboards \u2192 NGINX \u2192 NGINX Servers Tip You can again apply the filter kubernetes_cluster: [YOUR_INITIALS]-SFX-WORKSHOP to focus on only your metrics.","title":"3. Run Apache Benchmark"},{"location":"module4/prep/","text":"SignalFx Smart Agent - Lab Summary \u00b6 Download the Workshop Start a Multipass or AWS/EC2 instance Deploy the SignalFx Smart Agent in K3s Validate K3s cluster is visible in Kubernetes Navigator Deploy a NGINX ReplicaSet in K3s Validate NGNIX metrics are flowing Note If you have been give access to a pre-provisioned AWS/EC2 instance, you can ignore the rest of this preparation lab and go straight to the next lab Deploying the Smart Agent in Kubernetes (K3s) . 1. Module Pre-requisites \u00b6 Running Locally Multipass Install Multipass for your operating system. Make sure you are using at least version 1.2.0 . On a Mac you can also install via Homebrew e.g. brew cask install multipass Running in AWS AWS/EC2 Instance Install Terraform for your operating system. Please make sure it is version 0.12.18 or above. On a Mac you can also install via Homebrew e.g. brew install terraform . This will get around Mac OS Catalina security. 2. Download App Dev Workshop \u00b6 Regardless if you are running this lab locally or if you are going to create your own AWS/EC2 Instance you need to download the App Dev Workshop zip file locally, unzip the file, rename it and cd into the directory. Linux/Mac OS WSVERSION = 1 .13 curl -OL https://github.com/signalfx/app-dev-workshop/archive/v $WSVERSION .zip unzip v $WSVERSION .zip mv app-dev-workshop- $WSVERSION workshop cd workshop Windows Info Download the zip by clicking on the following URL https://github.com/signalfx/app-dev-workshop/archive/v1.13.zip . Once downloaded, unzip the the file and rename it to workshop . Then, from the command prompt change into that directory. If you are using your own AWS/EC2 instance please skip to 3. Launch Instance and select the Launch AWS/EC2 instance tab 3. Launch Instance \u00b6 Launch Multipass instance In this section you will build and launch the Multipass instance which will run the Kubernetes (K3s) environment that you will use in multiple labs. Make sure to use your initials During the build of your Multipass instance you need to provide a name, please use your initials [YOUR_INITIALS]-k3s so that the value of the instance hostname is unique e.g. rwc-k3s Warning In the \u00b5APM module there are two applications available for deployment to emit Traces/Spans for SignalFx \u00b5APM. Hot R.O.D Multipass min. requirements: 1 vCPU, 5Gb Disk, 1Gb Memory Sock Shop Multipass min. requirements: 4 vCPU, 15Gb Disk, 8Gb Memory Hot R.O.D multipass launch \\ --name [YOUR_INITIALS]-k3s \\ --cloud-init cloud-init/k3s.yaml Sock Shop multipass launch \\ --name [YOUR_INITIALS]-k3s \\ --cloud-init cloud-init/k3s.yaml \\ --cpus 4 --disk 15G --mem 8G Once the instance has been successfully created (this can take several minutes), shell into it. Input multipass shell [ YOUR_INITIALS ] -k3s Output \u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2557 \u2588\u2588\u2557 \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557 \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u255d \u2588\u2588\u2554\u2550\u2550\u2550\u255d \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u255d \u255a\u2588\u2588\u2557 \u2588\u2588\u2554\u255d \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u255a\u2588\u2588\u2588\u2588\u2554\u255d \u255a\u2550\u255d \u255a\u2550\u255d\u255a\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u255d To run a command as administrator (user \"root\"), use \"sudo <command>\". See \"man sudo_root\" for details ubuntu@rwc-k3s:~$ Once your instance presents you with the App Dev logo, you have completed the preparation for your Multipass instance and can go directly to the next lab Deploying the Smart Agent in K3s . Launch AWS/EC2 instance In this section you will use terraform to build an AWS/EC2 instance in your favorite AWS region and will automatically deploy the Kubernetes (K3s) environment that you will use in this Workshop. AWS Access Keys You will need access to an AWS account to obtain both AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY . Minimum requirements In the \u00b5APM module there are two applications available for deployment to emit Traces/Spans for SignalFx \u00b5APM. Hot R.O.D AWS/EC2 Instance min. requirements: t2.micro 1 vCPU, 8Gb Disk, 1Gb Memory Sock Shop AWS/EC2 Instance min. requirements: t2.large 2 vCPU, 15Gb Disk, 8Gb Memory Ask which version is going to be used as part of this Workshop, then select either the Hot R.O.D or Sock Shop option when using terraform to launch your instance. Prepare Terraform The first step is to go into the sub-directory where the Terraform files are located and initialise Terraform and upgrade the AWS Terraform Provider. Input cd ec2 terraform init -upgrade Output ~/workshop/ec2$ terraform init -upgrade Initializing the backend... Initializing provider plugins... - Checking for available provider plugins... - Downloading plugin for provider \"aws\" (hashicorp/aws) 2.60.0... The following providers do not have any version constraints in configuration, so the latest version was installed. To prevent automatic upgrades to new major versions that may contain breaking changes, it is recommended to add version = \"...\" constraints to the corresponding provider blocks in configuration, with the constraint strings suggested below. * provider.aws: version = \"~> 2.60\" Terraform has been successfully initialized! You may now begin working with Terraform. Try running \"terraform plan\" to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary. Create AWS/EC2 Instance Creating the AWS/EC2 instance is done in two steps, a planning phase and an apply phase. The planning phase will validate the Terraform scripts and check what changes it will make to your AWS environment. The apply phase will actually create the instance. First, you need to create environment variables for your AWS access keys. Input export AWS_ACCESS_KEY_ID = \"[YOUR_AWS_ACCESS_KEY_ID]\" export AWS_SECRET_ACCESS_KEY = \"[YOUR_AWS_SECRET_ACCESS_KEY]\" echo $AWS_ACCESS_KEY_ID $AWS_SECRET_ACCESS_KEY Output ID: Axxxxxxxxxxxxxxxxy, KEY: Axxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxb Once you have confirmed that you have set you AWS_SECRET_ACCESS_KEY_ID & AWS_SECRET_ACCESS_KEY correctly, you can start with the planning phase. Important Instance Count : (Type 1 to create a single Instance) Desired AWS Region : (Any AWS region by name, for example us-west-2 ) Instance Type : (Type 1 for Hot R.O.D. instance type or 2 for the Sock Shop instance type) Please remember these values as you will need them again for the planning phase and when you use Terraform to destroy your AWS/EC2 instance. As we only wish to provide the input once, we are going to capture the output in a .out file that we can use for the apply step. Please provide your initials for the output file as indicated. Input terraform plan -out =[ YOUR_INITIALS ] .out Next enter 1 to to create a single AWS/EC2 instance. Example var.aws_instance_count Instance Count Enter a value: 1 Enter your desired AWS Region where you wish to run the AWS/EC2 instance e.g. us-west-2 Example var.aws_region Provide the desired region Enter a value: us-west-2 Next, enter 1 for Hot R.O.D. instance size ( t2.micro ) or 2 for Sock Shop instance size ( t2.large ) Example var.instance_type Select instance type required ( 1 = Hot R.O.D. 2 = Sock Shop ) Enter a value: 1 Output Refreshing Terraform state in-memory prior to plan... The refreshed state will be used to calculate this plan, but will not be persisted to local or remote state storage. data.aws_ami.latest-ubuntu: Refreshing state... ------------------------------------------------------------------------ An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: **(BIG WALL OF AWS RELATED TEXT REMOVED)** Plan: 2 to add, 0 to change, 0 to destroy. ------------------------------------------------------------------------ This plan was saved to: [YOUR_INITIALS].out To perform exactly these actions, run the following command to apply: terraform apply \"[YOUR_INITIALS].out\" If there are no errors in the output and terraform has created your output file, you can start the apply phase of Terraform. This will create the AWS/EC2 instance. Input terraform apply \"[YOUR_INITIALS].out\" Output ws_security_group.instance: Creating... aws_security_group.instance: Creation complete after 2s [id=sg-0459afecae5953b51] aws_instance.app-dev-instance[0]: Creating... aws_instance.app-dev-instance[0]: Still creating... [10s elapsed] aws_instance.app-dev-instance[0]: Still creating... [20s elapsed] aws_instance.app-dev-instance[0]: Creation complete after 23s [id=i-095a12cd39f8e2283] Apply complete! Resources: 2 added, 0 changed, 0 destroyed. The state of your infrastructure has been saved to the path below. This state is required to modify and destroy your infrastructure, so keep it safe. To inspect the complete state use the `terraform show` command. State path: terraform.tfstate Outputs: ip = [ \"YOUR_IP-ADDRESS\", ] Verify there are no errors and copy the ip address that you see in the green output. SSH into AWS/EC2 Instance Once the instance has been successfully created (this can take several minutes), ssh into it. In most cases your ssh client will ask you to verify the connection. Input ssh ubuntu@ [ YOUR_IP-ADDRESS ] Output The authenticity of host '[YOUR_IP-ADDRESS] ([YOUR_IP-ADDRESS])' can't be established. ECDSA key fingerprint is SHA256:XdqN55g0z/ER660PARM+mGqtpYpwM3333YS9Ac8Y9hLY. Are you sure you want to continue connecting (yes/no/[fingerprint])? Please confirm that you wish to continue by replying to the prompt with yes Input Are you sure you want to continue connecting ( yes/no/ [ fingerprint ]) ? yes Output Warning: Permanently added 'YOUR_IP-ADDRESS' (ECDSA) to the list of known hosts. ubuntu@YOUR_IP-ADDRESS's password: To login to your instance please use the password provided by the Workshop host. Input ubuntu@ [ YOUR_IP-ADDRESS ] ' s password: [ PASSWORD ] Output \u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2557 \u2588\u2588\u2557 \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557 \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u255d \u2588\u2588\u2554\u2550\u2550\u2550\u255d \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u255d \u255a\u2588\u2588\u2557 \u2588\u2588\u2554\u255d \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u255a\u2588\u2588\u2588\u2588\u2554\u255d \u255a\u2550\u255d \u255a\u2550\u255d\u255a\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u255d To run a command as administrator (user \"root\"), use \"sudo <command>\". See \"man sudo_root\" for details ubuntu@ip-172-31-41-196:~$ Once your instance presents you with the App Dev logo, you have completed the preparation for your AWS/EC2 instance and can go directly to the next lab Deploying the Smart Agent in K3s .","title":"Preparation"},{"location":"module4/prep/#signalfx-smart-agent-lab-summary","text":"Download the Workshop Start a Multipass or AWS/EC2 instance Deploy the SignalFx Smart Agent in K3s Validate K3s cluster is visible in Kubernetes Navigator Deploy a NGINX ReplicaSet in K3s Validate NGNIX metrics are flowing Note If you have been give access to a pre-provisioned AWS/EC2 instance, you can ignore the rest of this preparation lab and go straight to the next lab Deploying the Smart Agent in Kubernetes (K3s) .","title":"SignalFx Smart Agent - Lab Summary"},{"location":"module4/prep/#1-module-pre-requisites","text":"Running Locally Multipass Install Multipass for your operating system. Make sure you are using at least version 1.2.0 . On a Mac you can also install via Homebrew e.g. brew cask install multipass Running in AWS AWS/EC2 Instance Install Terraform for your operating system. Please make sure it is version 0.12.18 or above. On a Mac you can also install via Homebrew e.g. brew install terraform . This will get around Mac OS Catalina security.","title":"1. Module Pre-requisites"},{"location":"module4/prep/#2-download-app-dev-workshop","text":"Regardless if you are running this lab locally or if you are going to create your own AWS/EC2 Instance you need to download the App Dev Workshop zip file locally, unzip the file, rename it and cd into the directory. Linux/Mac OS WSVERSION = 1 .13 curl -OL https://github.com/signalfx/app-dev-workshop/archive/v $WSVERSION .zip unzip v $WSVERSION .zip mv app-dev-workshop- $WSVERSION workshop cd workshop Windows Info Download the zip by clicking on the following URL https://github.com/signalfx/app-dev-workshop/archive/v1.13.zip . Once downloaded, unzip the the file and rename it to workshop . Then, from the command prompt change into that directory. If you are using your own AWS/EC2 instance please skip to 3. Launch Instance and select the Launch AWS/EC2 instance tab","title":"2. Download App Dev Workshop"},{"location":"module4/prep/#3-launch-instance","text":"Launch Multipass instance In this section you will build and launch the Multipass instance which will run the Kubernetes (K3s) environment that you will use in multiple labs. Make sure to use your initials During the build of your Multipass instance you need to provide a name, please use your initials [YOUR_INITIALS]-k3s so that the value of the instance hostname is unique e.g. rwc-k3s Warning In the \u00b5APM module there are two applications available for deployment to emit Traces/Spans for SignalFx \u00b5APM. Hot R.O.D Multipass min. requirements: 1 vCPU, 5Gb Disk, 1Gb Memory Sock Shop Multipass min. requirements: 4 vCPU, 15Gb Disk, 8Gb Memory Hot R.O.D multipass launch \\ --name [YOUR_INITIALS]-k3s \\ --cloud-init cloud-init/k3s.yaml Sock Shop multipass launch \\ --name [YOUR_INITIALS]-k3s \\ --cloud-init cloud-init/k3s.yaml \\ --cpus 4 --disk 15G --mem 8G Once the instance has been successfully created (this can take several minutes), shell into it. Input multipass shell [ YOUR_INITIALS ] -k3s Output \u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2557 \u2588\u2588\u2557 \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557 \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u255d \u2588\u2588\u2554\u2550\u2550\u2550\u255d \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u255d \u255a\u2588\u2588\u2557 \u2588\u2588\u2554\u255d \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u255a\u2588\u2588\u2588\u2588\u2554\u255d \u255a\u2550\u255d \u255a\u2550\u255d\u255a\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u255d To run a command as administrator (user \"root\"), use \"sudo <command>\". See \"man sudo_root\" for details ubuntu@rwc-k3s:~$ Once your instance presents you with the App Dev logo, you have completed the preparation for your Multipass instance and can go directly to the next lab Deploying the Smart Agent in K3s . Launch AWS/EC2 instance In this section you will use terraform to build an AWS/EC2 instance in your favorite AWS region and will automatically deploy the Kubernetes (K3s) environment that you will use in this Workshop. AWS Access Keys You will need access to an AWS account to obtain both AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY . Minimum requirements In the \u00b5APM module there are two applications available for deployment to emit Traces/Spans for SignalFx \u00b5APM. Hot R.O.D AWS/EC2 Instance min. requirements: t2.micro 1 vCPU, 8Gb Disk, 1Gb Memory Sock Shop AWS/EC2 Instance min. requirements: t2.large 2 vCPU, 15Gb Disk, 8Gb Memory Ask which version is going to be used as part of this Workshop, then select either the Hot R.O.D or Sock Shop option when using terraform to launch your instance. Prepare Terraform The first step is to go into the sub-directory where the Terraform files are located and initialise Terraform and upgrade the AWS Terraform Provider. Input cd ec2 terraform init -upgrade Output ~/workshop/ec2$ terraform init -upgrade Initializing the backend... Initializing provider plugins... - Checking for available provider plugins... - Downloading plugin for provider \"aws\" (hashicorp/aws) 2.60.0... The following providers do not have any version constraints in configuration, so the latest version was installed. To prevent automatic upgrades to new major versions that may contain breaking changes, it is recommended to add version = \"...\" constraints to the corresponding provider blocks in configuration, with the constraint strings suggested below. * provider.aws: version = \"~> 2.60\" Terraform has been successfully initialized! You may now begin working with Terraform. Try running \"terraform plan\" to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary. Create AWS/EC2 Instance Creating the AWS/EC2 instance is done in two steps, a planning phase and an apply phase. The planning phase will validate the Terraform scripts and check what changes it will make to your AWS environment. The apply phase will actually create the instance. First, you need to create environment variables for your AWS access keys. Input export AWS_ACCESS_KEY_ID = \"[YOUR_AWS_ACCESS_KEY_ID]\" export AWS_SECRET_ACCESS_KEY = \"[YOUR_AWS_SECRET_ACCESS_KEY]\" echo $AWS_ACCESS_KEY_ID $AWS_SECRET_ACCESS_KEY Output ID: Axxxxxxxxxxxxxxxxy, KEY: Axxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxb Once you have confirmed that you have set you AWS_SECRET_ACCESS_KEY_ID & AWS_SECRET_ACCESS_KEY correctly, you can start with the planning phase. Important Instance Count : (Type 1 to create a single Instance) Desired AWS Region : (Any AWS region by name, for example us-west-2 ) Instance Type : (Type 1 for Hot R.O.D. instance type or 2 for the Sock Shop instance type) Please remember these values as you will need them again for the planning phase and when you use Terraform to destroy your AWS/EC2 instance. As we only wish to provide the input once, we are going to capture the output in a .out file that we can use for the apply step. Please provide your initials for the output file as indicated. Input terraform plan -out =[ YOUR_INITIALS ] .out Next enter 1 to to create a single AWS/EC2 instance. Example var.aws_instance_count Instance Count Enter a value: 1 Enter your desired AWS Region where you wish to run the AWS/EC2 instance e.g. us-west-2 Example var.aws_region Provide the desired region Enter a value: us-west-2 Next, enter 1 for Hot R.O.D. instance size ( t2.micro ) or 2 for Sock Shop instance size ( t2.large ) Example var.instance_type Select instance type required ( 1 = Hot R.O.D. 2 = Sock Shop ) Enter a value: 1 Output Refreshing Terraform state in-memory prior to plan... The refreshed state will be used to calculate this plan, but will not be persisted to local or remote state storage. data.aws_ami.latest-ubuntu: Refreshing state... ------------------------------------------------------------------------ An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: **(BIG WALL OF AWS RELATED TEXT REMOVED)** Plan: 2 to add, 0 to change, 0 to destroy. ------------------------------------------------------------------------ This plan was saved to: [YOUR_INITIALS].out To perform exactly these actions, run the following command to apply: terraform apply \"[YOUR_INITIALS].out\" If there are no errors in the output and terraform has created your output file, you can start the apply phase of Terraform. This will create the AWS/EC2 instance. Input terraform apply \"[YOUR_INITIALS].out\" Output ws_security_group.instance: Creating... aws_security_group.instance: Creation complete after 2s [id=sg-0459afecae5953b51] aws_instance.app-dev-instance[0]: Creating... aws_instance.app-dev-instance[0]: Still creating... [10s elapsed] aws_instance.app-dev-instance[0]: Still creating... [20s elapsed] aws_instance.app-dev-instance[0]: Creation complete after 23s [id=i-095a12cd39f8e2283] Apply complete! Resources: 2 added, 0 changed, 0 destroyed. The state of your infrastructure has been saved to the path below. This state is required to modify and destroy your infrastructure, so keep it safe. To inspect the complete state use the `terraform show` command. State path: terraform.tfstate Outputs: ip = [ \"YOUR_IP-ADDRESS\", ] Verify there are no errors and copy the ip address that you see in the green output. SSH into AWS/EC2 Instance Once the instance has been successfully created (this can take several minutes), ssh into it. In most cases your ssh client will ask you to verify the connection. Input ssh ubuntu@ [ YOUR_IP-ADDRESS ] Output The authenticity of host '[YOUR_IP-ADDRESS] ([YOUR_IP-ADDRESS])' can't be established. ECDSA key fingerprint is SHA256:XdqN55g0z/ER660PARM+mGqtpYpwM3333YS9Ac8Y9hLY. Are you sure you want to continue connecting (yes/no/[fingerprint])? Please confirm that you wish to continue by replying to the prompt with yes Input Are you sure you want to continue connecting ( yes/no/ [ fingerprint ]) ? yes Output Warning: Permanently added 'YOUR_IP-ADDRESS' (ECDSA) to the list of known hosts. ubuntu@YOUR_IP-ADDRESS's password: To login to your instance please use the password provided by the Workshop host. Input ubuntu@ [ YOUR_IP-ADDRESS ] ' s password: [ PASSWORD ] Output \u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2557 \u2588\u2588\u2557 \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557 \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u255d \u2588\u2588\u2554\u2550\u2550\u2550\u255d \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u255d \u255a\u2588\u2588\u2557 \u2588\u2588\u2554\u255d \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u255a\u2588\u2588\u2588\u2588\u2554\u255d \u255a\u2550\u255d \u255a\u2550\u255d\u255a\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u255d To run a command as administrator (user \"root\"), use \"sudo <command>\". See \"man sudo_root\" for details ubuntu@ip-172-31-41-196:~$ Once your instance presents you with the App Dev logo, you have completed the preparation for your AWS/EC2 instance and can go directly to the next lab Deploying the Smart Agent in K3s .","title":"3. Launch Instance"},{"location":"module5/terraform/","text":"Using Terraform - Lab Summary \u00b6 Initialize the SignalFx Provider. Run Terraform to create SignalFx detectors and dashboards from code using the SignalFx Terraform Provider. See how Terraform can also delete detectors and dashboards. 1. Initial setup \u00b6 Remaining in your Multipass or AWS/EC2 instance from the Smart Agent module, change into the signalfx-jumpstart directory Input cd ~/signalfx-jumpstart The environment variables needed should already be set from Deploy the Smart Agent in K3s . If not, create the following environment variables to use in the Terraform steps below Input export ACCESS_TOKEN=[ACCESS_TOKEN] export REALM=[REALM e.g. us1] export INITIALS=[YOUR_INITIALS e.g. RWC] Initialize Terraform and upgrade to the latest version of the SignalFx Terraform Provider Upgrading the SignalFx Terraform Provider You will need to run this command each time a new version of the SignalFx Terraform Provider is released. You can track the releases on GitHub . Input terraform init -upgrade Output Upgrading modules... - aws in modules/aws - azure in modules/azure - docker in modules/docker - gcp in modules/gcp - host in modules/host - kubernetes in modules/kubernetes - parent_child_dashboard in modules/dashboards/parent - pivotal in modules/pivotal - usage_dashboard in modules/dashboards/usage Initializing the backend... Initializing provider plugins... - Checking for available provider plugins... - Downloading plugin for provider \"signalfx\" (terraform-providers/signalfx) 4.18.6... The following providers do not have any version constraints in configuration, so the latest version was installed. To prevent automatic upgrades to new major versions that may contain breaking changes, it is recommended to add version = \"...\" constraints to the corresponding provider blocks in configuration, with the constraint strings suggested below. * provider.signalfx: version = \"~> 4.18\" Terraform has been successfully initialized! You may now begin working with Terraform. Try running \"terraform plan\" to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary. Create a new workspace, replace [WORKSPACE_NAME] with what you want your workspace to be called: Input terraform workspace new [ WORKSPACE_NAME ] Output Created and switched to workspace \"my_workspace\"! You're now on a new, empty workspace. Workspaces isolate their state, so if you run \"terraform plan\" Terraform will not see any existing state for this configuration. 2. Create an execution plan \u00b6 Review the execution plan. Input terraform plan -var = \"access_token= $ACCESS_TOKEN \" -var = \"realm= $REALM \" -var = \"sfx_prefix= $INITIALS \" If the plan executes successfully, we can go ahead and apply: 3. Apply actions from execution plan \u00b6 Input terraform apply -var = \"access_token= $ACCESS_TOKEN \" -var = \"realm= $REALM \" -var = \"sfx_prefix= $INITIALS \" Validate that the detectors were created, under the ALERTS \u2192 Detectors , you should see a list of new detectors with the a prefix of your initials: 4. Destroy all your hard work \u00b6 You will first need to ensure you are in the correct workspace, replace [WORKSPACE_NAME] with the name created in the initial setup) Input terraform workspace select [WORKSPACE_NAME] Destroy all Detectors and Dashboards that were previously applied. Info The var=\u201dsfx_prefix=$INITIALS\u201d is not required! Input terraform destroy -var = \"access_token= $ACCESS_TOKEN \" -var = \"realm= $REALM \" Validate all the detectors have been removed by navigating to ALERTS \u2192 Detectors","title":"Using Terraform"},{"location":"module5/terraform/#using-terraform-lab-summary","text":"Initialize the SignalFx Provider. Run Terraform to create SignalFx detectors and dashboards from code using the SignalFx Terraform Provider. See how Terraform can also delete detectors and dashboards.","title":"Using Terraform - Lab Summary"},{"location":"module5/terraform/#1-initial-setup","text":"Remaining in your Multipass or AWS/EC2 instance from the Smart Agent module, change into the signalfx-jumpstart directory Input cd ~/signalfx-jumpstart The environment variables needed should already be set from Deploy the Smart Agent in K3s . If not, create the following environment variables to use in the Terraform steps below Input export ACCESS_TOKEN=[ACCESS_TOKEN] export REALM=[REALM e.g. us1] export INITIALS=[YOUR_INITIALS e.g. RWC] Initialize Terraform and upgrade to the latest version of the SignalFx Terraform Provider Upgrading the SignalFx Terraform Provider You will need to run this command each time a new version of the SignalFx Terraform Provider is released. You can track the releases on GitHub . Input terraform init -upgrade Output Upgrading modules... - aws in modules/aws - azure in modules/azure - docker in modules/docker - gcp in modules/gcp - host in modules/host - kubernetes in modules/kubernetes - parent_child_dashboard in modules/dashboards/parent - pivotal in modules/pivotal - usage_dashboard in modules/dashboards/usage Initializing the backend... Initializing provider plugins... - Checking for available provider plugins... - Downloading plugin for provider \"signalfx\" (terraform-providers/signalfx) 4.18.6... The following providers do not have any version constraints in configuration, so the latest version was installed. To prevent automatic upgrades to new major versions that may contain breaking changes, it is recommended to add version = \"...\" constraints to the corresponding provider blocks in configuration, with the constraint strings suggested below. * provider.signalfx: version = \"~> 4.18\" Terraform has been successfully initialized! You may now begin working with Terraform. Try running \"terraform plan\" to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary. Create a new workspace, replace [WORKSPACE_NAME] with what you want your workspace to be called: Input terraform workspace new [ WORKSPACE_NAME ] Output Created and switched to workspace \"my_workspace\"! You're now on a new, empty workspace. Workspaces isolate their state, so if you run \"terraform plan\" Terraform will not see any existing state for this configuration.","title":"1. Initial setup"},{"location":"module5/terraform/#2-create-an-execution-plan","text":"Review the execution plan. Input terraform plan -var = \"access_token= $ACCESS_TOKEN \" -var = \"realm= $REALM \" -var = \"sfx_prefix= $INITIALS \" If the plan executes successfully, we can go ahead and apply:","title":"2. Create an execution plan"},{"location":"module5/terraform/#3-apply-actions-from-execution-plan","text":"Input terraform apply -var = \"access_token= $ACCESS_TOKEN \" -var = \"realm= $REALM \" -var = \"sfx_prefix= $INITIALS \" Validate that the detectors were created, under the ALERTS \u2192 Detectors , you should see a list of new detectors with the a prefix of your initials:","title":"3. Apply actions from execution plan"},{"location":"module5/terraform/#4-destroy-all-your-hard-work","text":"You will first need to ensure you are in the correct workspace, replace [WORKSPACE_NAME] with the name created in the initial setup) Input terraform workspace select [WORKSPACE_NAME] Destroy all Detectors and Dashboards that were previously applied. Info The var=\u201dsfx_prefix=$INITIALS\u201d is not required! Input terraform destroy -var = \"access_token= $ACCESS_TOKEN \" -var = \"realm= $REALM \" Validate all the detectors have been removed by navigating to ALERTS \u2192 Detectors","title":"4. Destroy all your hard work"},{"location":"module6/","text":"\u00b5APM Architecture Overview \u00b6 Enabling \u00b5APM An Organization needs to be pre-provisioned as a \u00b5APM entitlement is required for the purposes of this module. Please contact someone from SignalFx to get a trial instance with \u00b5APM enabled if you don\u2019t have one already. To check if you have an Organization with \u00b5APM enabled, just login to SignalFx and check that you have the \u00b5APM tab on the top navbar next to Dashboards. SignalFx \u00b5APM captures end-to-end distributed transactions from your applications, with trace spans sent directly to SignalFx or via the SignalFx Smart Agent deployed on each host (recommended). Optionally, you can deploy an OpenTelemetry Collector to act as a central aggregation point prior to sending trace spans to SignalFx. In addition to proxying spans and infrastructure metrics, the OpenTelemetry Collector can also perform other functions, such as redacting sensitive tags prior to spans leaving your environment. The following illustration shows the recommended deployment model: SignalFx auto-instrumentation libraries send spans to the Smart Agent; the Smart Agent can send the spans to SignalFx directly or via an optional OpenTelemetry Collector.","title":"\u00b5APM Architecture Overview"},{"location":"module6/#apm-architecture-overview","text":"Enabling \u00b5APM An Organization needs to be pre-provisioned as a \u00b5APM entitlement is required for the purposes of this module. Please contact someone from SignalFx to get a trial instance with \u00b5APM enabled if you don\u2019t have one already. To check if you have an Organization with \u00b5APM enabled, just login to SignalFx and check that you have the \u00b5APM tab on the top navbar next to Dashboards. SignalFx \u00b5APM captures end-to-end distributed transactions from your applications, with trace spans sent directly to SignalFx or via the SignalFx Smart Agent deployed on each host (recommended). Optionally, you can deploy an OpenTelemetry Collector to act as a central aggregation point prior to sending trace spans to SignalFx. In addition to proxying spans and infrastructure metrics, the OpenTelemetry Collector can also perform other functions, such as redacting sensitive tags prior to spans leaving your environment. The following illustration shows the recommended deployment model: SignalFx auto-instrumentation libraries send spans to the Smart Agent; the Smart Agent can send the spans to SignalFx directly or via an optional OpenTelemetry Collector.","title":"\u00b5APM Architecture Overview"},{"location":"module6/hotrod/","text":"Deploying Hot R.O.D. in K3s - Lab Summary \u00b6 Deploy application into K3s Verify the application is running Generate some artificial traffic Validate traces in the UI Ensure you have a running instance The setup part is already documented in the Preparation and Deploy the Smart Agent in K3s steps. If you are using an AWS/EC2 instance, make sure it is available and skip to Step 1 , otherwise ensure your Multipass instance is available and running before continuing. Input multipass list Output Name State IPv4 Image rwc-k3s Running 192.168.64.17 Ubuntu 18.04 LTS 1. Deploy the Hot R.O.D. application into K3s \u00b6 To deploy the Hot R.O.D. application into K3s apply the deployment. Input kubectl apply -f ~/workshop/apm/hotrod/k8s/deployment.yaml Output deployment.apps/hotrod created service/hotrod created To ensure the Hot R.O.D. application is running: Input kubectl get pods Output NAME READY STATUS RESTARTS AGE signalfx-agent-mmzxk 1/1 Running 0 110s hotrod-7cc9fc85b7-n765r 1/1 Running 0 41s 2. Viewing the Hot R.O.D. application in your browser \u00b6 !!! note \"AWC/EC2 Users@ If you are using an AWS/EC2 instance, please skip to the next section Generate Traffic . In order to view the application in your web browser we need to find the LoadBalancer IP address and the port the application is listening on. Input kubectl get svc Output NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.43.0.1 <none> 443/TCP 43m hotrod LoadBalancer 10.43.32.97 192.168.64.35 8080:31521/TCP 40m Make note of the EXTERNAL-IP (in the example above this is 192.168.64.35 ). Open your web browser and type in http://[EXTERNAL-IP]:8080 , you will then be able to see the application running. Click on customer name to order a car: 3. Generate some traffic to the application using Apache Benchmark \u00b6 Return to your shell and create an environment variable for the IP address and port that the Hot R.O.D. application is exposed on: Input HOTROD_ENDPOINT=$(kubectl get svc hotrod -n default -o jsonpath='{.spec.clusterIP}:{.spec.ports[0].port}') Confirm the environment variable is set Input curl $HOTROD_ENDPOINT Then run the following command(s) to create load on the service: Input ab -n10 -c10 \"http:// $HOTROD_ENDPOINT /dispatch?customer=392&nonse=0.17041229755366172\" Create some errors with an invalid customer number Input ab -n10 -c10 \"http:// $HOTROD_ENDPOINT /dispatch?customer=391&nonse=0.17041229755366172\" 4. Verify that \u00b5APM traces are reaching SignalFx \u00b6 Open SignalFx in your browser and select the \u00b5APM tab. Select the Troubleshooting tab, and select your environment and set the time to 15 minutes. This will show you the Dependency Map for the Hot R.O.D. application. If you did create some errors, they will show up as the big red dot in the Redis service.","title":"Deploying Hot R.O.D. in K3s"},{"location":"module6/hotrod/#deploying-hot-rod-in-k3s-lab-summary","text":"Deploy application into K3s Verify the application is running Generate some artificial traffic Validate traces in the UI Ensure you have a running instance The setup part is already documented in the Preparation and Deploy the Smart Agent in K3s steps. If you are using an AWS/EC2 instance, make sure it is available and skip to Step 1 , otherwise ensure your Multipass instance is available and running before continuing. Input multipass list Output Name State IPv4 Image rwc-k3s Running 192.168.64.17 Ubuntu 18.04 LTS","title":"Deploying Hot R.O.D. in K3s - Lab Summary"},{"location":"module6/hotrod/#1-deploy-the-hot-rod-application-into-k3s","text":"To deploy the Hot R.O.D. application into K3s apply the deployment. Input kubectl apply -f ~/workshop/apm/hotrod/k8s/deployment.yaml Output deployment.apps/hotrod created service/hotrod created To ensure the Hot R.O.D. application is running: Input kubectl get pods Output NAME READY STATUS RESTARTS AGE signalfx-agent-mmzxk 1/1 Running 0 110s hotrod-7cc9fc85b7-n765r 1/1 Running 0 41s","title":"1. Deploy the Hot R.O.D. application into K3s"},{"location":"module6/hotrod/#2-viewing-the-hot-rod-application-in-your-browser","text":"!!! note \"AWC/EC2 Users@ If you are using an AWS/EC2 instance, please skip to the next section Generate Traffic . In order to view the application in your web browser we need to find the LoadBalancer IP address and the port the application is listening on. Input kubectl get svc Output NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.43.0.1 <none> 443/TCP 43m hotrod LoadBalancer 10.43.32.97 192.168.64.35 8080:31521/TCP 40m Make note of the EXTERNAL-IP (in the example above this is 192.168.64.35 ). Open your web browser and type in http://[EXTERNAL-IP]:8080 , you will then be able to see the application running. Click on customer name to order a car:","title":"2. Viewing the Hot R.O.D. application in your browser"},{"location":"module6/hotrod/#3-generate-some-traffic-to-the-application-using-apache-benchmark","text":"Return to your shell and create an environment variable for the IP address and port that the Hot R.O.D. application is exposed on: Input HOTROD_ENDPOINT=$(kubectl get svc hotrod -n default -o jsonpath='{.spec.clusterIP}:{.spec.ports[0].port}') Confirm the environment variable is set Input curl $HOTROD_ENDPOINT Then run the following command(s) to create load on the service: Input ab -n10 -c10 \"http:// $HOTROD_ENDPOINT /dispatch?customer=392&nonse=0.17041229755366172\" Create some errors with an invalid customer number Input ab -n10 -c10 \"http:// $HOTROD_ENDPOINT /dispatch?customer=391&nonse=0.17041229755366172\"","title":"3. Generate some traffic to the application using Apache Benchmark"},{"location":"module6/hotrod/#4-verify-that-apm-traces-are-reaching-signalfx","text":"Open SignalFx in your browser and select the \u00b5APM tab. Select the Troubleshooting tab, and select your environment and set the time to 15 minutes. This will show you the Dependency Map for the Hot R.O.D. application. If you did create some errors, they will show up as the big red dot in the Redis service.","title":"4. Verify that \u00b5APM traces are reaching SignalFx"},{"location":"module6/sockshop/","text":"Deploying Sock Shop in K3s \u00b6 Note The setup part is already documented in the Preparation and Deploy the Smart Agent in K3s steps. Please ensure this instance is available and running before continuing. Input multipass list Output Name State IPv4 Image rwc-k3s Running 192.168.64.17 Ubuntu 18.04 LTS Warning The Sock Shop application requires some horse power to run it, please ensure you are running a Multipass or AWS/EC2 instance that can handle it. Sock Shop Multipass min. requirements: 4 vCPU, 15Gb Disk, 8Gb Memory Sock Shop AWS/EC2 min. requirements: t2.large 2 vCPU, 15Gb Disk, 8Gb Memory 1. Deploy the Sock Shop application into K3s \u00b6 To deploy the Sock Shop application into K3s apply the deployment Input cd ~/workshop/apm/sockshop kubectl create namespace sock-shop kubectl apply -f k8s/deployment.yaml Output namespace/sock-shop created deployment.apps/carts-db created service/carts-db created deployment.apps/carts created service/carts created deployment.apps/catalogue-db created service/catalogue-db created deployment.apps/catalogue created service/catalogue created deployment.apps/front-end created service/front-end created deployment.apps/orders-db created service/orders-db created deployment.apps/orders created service/orders created deployment.apps/payment created service/payment created deployment.apps/queue-master created service/queue-master created deployment.apps/rabbitmq created service/rabbitmq created deployment.apps/shipping created service/shipping created deployment.apps/user-db created service/user-db created deployment.apps/user created service/user created 2. Ensure Sock Shop is fully deployed \u00b6 To monitor the deployment of Sock Shop using k9s to monitor: Input k9s Once in k9s press 0 to show all namespaces: 3. Take Sock Shop for a test drive \u00b6 Sock Shop should be running in your cluster and exposes services via cluster IP and port. Obtain the ip address for the front-end service. Input export SOCKS_ENDPOINT = $( kubectl get svc front-end -n sock-shop -o jsonpath = '{.spec.clusterIP}:{.spec.ports[0].port}' ) Then confirm the SOCKS_ENDPOINT environment variable has been set: Input curl http:// $SOCKS_ENDPOINT Output ... </ script > </ body > </ html > 4. Viewing the SockShop application in your browser \u00b6 (If you are using an AWS/EC2 instance, please skip to this section.) To view the application in your web browser we need to find the LoadBalancer IP address and the port the application is listening on. Input kubectl get svc -n sock-shop front-end Output NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE front-end LoadBalancer 10.43.247.97 192.168.64.35 8081:30001/TCP 34m Make note of the EXTERNAL-IP (in the example above this is 192.168.64.35 ). Then head over to your web browser and type in http://[EXTERNAL-IP]:8081 , you should then be able to see the application running. Happy Shopping! 5. Apply load on Sock Shop \u00b6 A load testing scenario is available for the Sock Shop application. To generate some load run the following command: Input ./loadgen.sh -c 50 -r 3m The parameter -c controls the amount of concurrent clients and -r the runtime of the load test. To apply continuous load set -r to the desired runtime. The load test runs as a job in the K8S cluster. Observe the progress: Input kubectl -n sock-shop logs -f jobs/loadgen If you want to abort a load test, delete the job: Input kubectl -n sock-shop delete jobs/loadgen 6. Visualize and analyze trace data \u00b6 Navigate to \u00b5APM ( not \u00b5APM PG) and select Monitoring, then ensure you have selected your environment from the dropdown at the top, you should see something like this: 6.1. Explore the User Interface \u00b6 Review an automatically generated Service Dashboard. How do you correlate Service performance with Infrastructure? 6.2. Troubleshoot a service \u00b6 Let's stress the sock shop a bit. Increase the amount of clients running for the load test to something ludicrous, e.g.: Input ./loadgen.sh -c 1000 -a 100 -r 5m While the load test is running observe in SignalFx what happens with the services. Troubleshoot a service with a higher error rate. Also review the service dependencies. Look at individual traces and span performance.","title":"Deploying Sock Shop in K3s"},{"location":"module6/sockshop/#deploying-sock-shop-in-k3s","text":"Note The setup part is already documented in the Preparation and Deploy the Smart Agent in K3s steps. Please ensure this instance is available and running before continuing. Input multipass list Output Name State IPv4 Image rwc-k3s Running 192.168.64.17 Ubuntu 18.04 LTS Warning The Sock Shop application requires some horse power to run it, please ensure you are running a Multipass or AWS/EC2 instance that can handle it. Sock Shop Multipass min. requirements: 4 vCPU, 15Gb Disk, 8Gb Memory Sock Shop AWS/EC2 min. requirements: t2.large 2 vCPU, 15Gb Disk, 8Gb Memory","title":"Deploying Sock Shop in K3s"},{"location":"module6/sockshop/#1-deploy-the-sock-shop-application-into-k3s","text":"To deploy the Sock Shop application into K3s apply the deployment Input cd ~/workshop/apm/sockshop kubectl create namespace sock-shop kubectl apply -f k8s/deployment.yaml Output namespace/sock-shop created deployment.apps/carts-db created service/carts-db created deployment.apps/carts created service/carts created deployment.apps/catalogue-db created service/catalogue-db created deployment.apps/catalogue created service/catalogue created deployment.apps/front-end created service/front-end created deployment.apps/orders-db created service/orders-db created deployment.apps/orders created service/orders created deployment.apps/payment created service/payment created deployment.apps/queue-master created service/queue-master created deployment.apps/rabbitmq created service/rabbitmq created deployment.apps/shipping created service/shipping created deployment.apps/user-db created service/user-db created deployment.apps/user created service/user created","title":"1. Deploy the Sock Shop application into K3s"},{"location":"module6/sockshop/#2-ensure-sock-shop-is-fully-deployed","text":"To monitor the deployment of Sock Shop using k9s to monitor: Input k9s Once in k9s press 0 to show all namespaces:","title":"2. Ensure Sock Shop is fully deployed"},{"location":"module6/sockshop/#3-take-sock-shop-for-a-test-drive","text":"Sock Shop should be running in your cluster and exposes services via cluster IP and port. Obtain the ip address for the front-end service. Input export SOCKS_ENDPOINT = $( kubectl get svc front-end -n sock-shop -o jsonpath = '{.spec.clusterIP}:{.spec.ports[0].port}' ) Then confirm the SOCKS_ENDPOINT environment variable has been set: Input curl http:// $SOCKS_ENDPOINT Output ... </ script > </ body > </ html >","title":"3. Take Sock Shop for a test drive"},{"location":"module6/sockshop/#4-viewing-the-sockshop-application-in-your-browser","text":"(If you are using an AWS/EC2 instance, please skip to this section.) To view the application in your web browser we need to find the LoadBalancer IP address and the port the application is listening on. Input kubectl get svc -n sock-shop front-end Output NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE front-end LoadBalancer 10.43.247.97 192.168.64.35 8081:30001/TCP 34m Make note of the EXTERNAL-IP (in the example above this is 192.168.64.35 ). Then head over to your web browser and type in http://[EXTERNAL-IP]:8081 , you should then be able to see the application running. Happy Shopping!","title":"4. Viewing the SockShop application in your browser"},{"location":"module6/sockshop/#5-apply-load-on-sock-shop","text":"A load testing scenario is available for the Sock Shop application. To generate some load run the following command: Input ./loadgen.sh -c 50 -r 3m The parameter -c controls the amount of concurrent clients and -r the runtime of the load test. To apply continuous load set -r to the desired runtime. The load test runs as a job in the K8S cluster. Observe the progress: Input kubectl -n sock-shop logs -f jobs/loadgen If you want to abort a load test, delete the job: Input kubectl -n sock-shop delete jobs/loadgen","title":"5. Apply load on Sock Shop"},{"location":"module6/sockshop/#6-visualize-and-analyze-trace-data","text":"Navigate to \u00b5APM ( not \u00b5APM PG) and select Monitoring, then ensure you have selected your environment from the dropdown at the top, you should see something like this:","title":"6. Visualize and analyze trace data"},{"location":"module6/sockshop/#61-explore-the-user-interface","text":"Review an automatically generated Service Dashboard. How do you correlate Service performance with Infrastructure?","title":"6.1. Explore the User Interface"},{"location":"module6/sockshop/#62-troubleshoot-a-service","text":"Let's stress the sock shop a bit. Increase the amount of clients running for the load test to something ludicrous, e.g.: Input ./loadgen.sh -c 1000 -a 100 -r 5m While the load test is running observe in SignalFx what happens with the services. Troubleshoot a service with a higher error rate. Also review the service dependencies. Look at individual traces and span performance.","title":"6.2. Troubleshoot a service"},{"location":"module7/vo_getting_started/","text":"VictorOps Getting Started - Lab Summary \u00b6 Activate your login Configure your Profile Create your Team Configure Rotations Configure Escalation Policies Create Routing Keys 1. Activate your login \u00b6 You will have received an invitation to Activate your VictorOps account via e-mail, click the 'Activate Account' link and follow the prompts. 2. Configure Your Profile \u00b6 Once you are logged in to VictorOps you now need to set up your profile. Click on your login name in the top right hand corner and chose Profile from the drop down. 2.1. Contact Methods \u00b6 Confirm your contact methods are listed correctly and add any additional phone numbers and e-mail address you wish to use. 2.2. Devices \u00b6 Install the VictorOps app for your smartphone. Search your phones App Store for VictorOps to find the appropriate version of the app. The publisher should be listed as VictorOps Inc. Configuration help guides are available here: Apple Android Install the App and login, then refresh the Profile page and your device should now be listed under the devices section. Click the Test push notification button and confirm you receive the test message. 2.3. Personal Calendar \u00b6 This link will enable you to sync your VictorOps on-call schedule with your calendar, however as you do not have any allocated shifts yet this will currently be empty. You can add it to you calendar by copying the link into your preferred application and setting it up as a new subscription. 2.4. Paging Polices \u00b6 Paging Polices specify how you will be contacted by VictorOps when on-call. The Primary Paging Policy will have defaulted to sending you an SMS assuming you added your phone number when activating your account. We will now configure this policy into a three tier multi-stage policy. Click the edit policy button for the Primary Paging Policy. Step 1 Send a push notification to all my devices Execute the next step if I have not responded within 5 minutes Then add an new step Step 2 Send an email to [your email address] Execute the next step if I have not responded within 5 minutes Then add a new step Step 3 Every 5 minutes until we have reached you Make a phone call to [your phone number] Then save the policy. When you are on-call or in the escalation path of an incident, you will receive notifications in this order following these time delays. To cease the paging you must acknowledge the incident. Acknowledgements can occur in one of the following ways: Expanding the Push Notification on your device and selecting Acknowledge Responding to the SMS with the 5 digit code included Pressing 4 during the Phone Call Slack Button For more information on Notification Types, see here . Custom paging polices enable you to override the primary policy based on the time and day of the week. A good example would be get the system to immediately phone you whenever you get a page during the evening or weekends as this is more likely to get your attention than a push notification. Create a new Custom Policy by clicking Add a Policy and configure with the following settings: Policy Name: Evening Step 1 Every 5 minutes until we have reached you Make a phone call to [your phone number] Time Period: All 7 Days Timezone [your time zone] Between 7pm and 9am Save the policy then add one more Policy Name: Weekend Step 1 Every 5 minutes until we have reached you Make a phone call to [your phone number] Time Period: Sat & Sun Timezone [your time zone] Between 9am and 7pm These custom paging policies will be used during the specified times in place of the Primary Policy, however admins do have the ability to ignore these custom policies, and we will highlight how this is achieved in a later module. The final option here is the setting for Recovery Notifications. As these are typically low priority simply sending you an email is the typical setting used. Your profile is now fully configured using these example configurations. Organizations will have different views on how profiles should be configured and will typically issue guidelines for paging policies and times between escalations etc. 3. Create Your Team \u00b6 Navigate to the Teams Tab on the main toolbar, select Add Team , then enter your team name using the format \"[Your Initials] Workshop\" and then save by clicking the Add Team button. You now need to add other users to your team. If you are running this workshop using the Splunk provided environment, the following accounts are available for testing. If you are running this lab in your own environment, you will have been provided a list of usernames you can use in place of the table below. Name Username Shift Duane Chow duanechow Europe Steven Gomez gomez Europe Walter White heisenberg Europe Jim Halpert jimhalpert Asia Lydia Rodarte-Quayle lydia Asia Marie Schrader marie Asia Maximo Arciniega maximo West Coast Michael Scott michaelscott West Coast Tuco Salamanca tuco West Coast Jack Welker jackwelker 24/7 Hank Schrader hankschrader 24/7 Pam Beesly pambeesly 24/7 Add the users to your team, using either the above list or the alternate one provided to you. The value in the Shift column can be ignored for now, but will be required for a later step. Click the Invite User button then either start typing the usernames (this will filter the list), or copy and paste them into the dialogue box. Once all users are added click the Add User button. To make a team member a Team Admin, simply click the Pencil icon in the right hand column, pick any user and make them an Admin. Tip For large team management you could use the API to streamline this process, and we will look at that in a later module 4. Configure Rotations \u00b6 Navigate to the Rotations tab on the Teams sub menu, you should have no existing Rotations so we need to create some. The 1st Rotation you will create is for a follow the sun support pattern where the members of each shift provide cover during their normal working hours within their time zone. The 2nd will be a Rotation used to provide escalation support by more experienced senior members of the team, based on a 24/7, 1 week shift pattern. 4.1. Follow the Sun Support - Business Hours \u00b6 Click Add Rotation Enter a name of \" Follow the Sun Support - Business Hours \" Select Partial day from the three available shift templates Enter a Shift name of \" Asia \" Time Zone set to \" Asia/Tokyo \" Each user is on duty from \" Monday through Friday from 9.00am to 5.00pm \" Handoff happens every \" 7 days \" The next handoff happens - Select the next Monday using the calendar Click Save Rotation Now add an 2nd shift for Europe by clicking +Add a shift - Partial Day Enter a Shift name of \" Europe \" Time Zone set to \" Europe/London \" Each user is on duty from \" Monday through Friday from 9.00am to 5.00pm \" Handoff happens every \" 7 days \" The next handoff happens - Select the next Monday using the calendar Click Save Shift Now add a 3rd shift for West Coast USA by clicking +Add a shift - Partial Day Enter a Shift name of \" West Coast \" Time Zone set to \" US/Pacific \" Each user is on duty from \" Monday through Friday from 9.00am to 5.00pm \" Handoff happens every \" 7 days \" The next handoff happens - Select the next Monday using the calendar Click Save Shift You new need to add the users into their allocated shift patterns using either the table above, or the list of users provided to you separately For each Shift, click on the Manage Members icon which is the left of the three icons and resembles the image of three heads Add the users to each Shift (note how you have to use their Username and not their real names) The first user added will be the 'current' user for that shift You can re-order the shifts by simply dragging the users up and down, and you can change the current user by clicking Set Current on an alternate user You will now have three different Shift patterns, that provide cover 24hr hours, Mon - Fri, but with no cover at weekends. We will now add the 2nd Rotation for our Senior SRE Escalation cover. 4.2. Senior SRE Escalation \u00b6 Click Add Rotation Enter a name of \" Senior SRE Escalation \" Select 24/7 from the three available shift templates Enter a Shift name of \" Senior SRE Escalation \" Time Zone set to \" Asia/Tokyo \" Handoff happens every \" 7 days at 9.00am \" The next handoff happens [select the next Monday from the date picker] Click Save Rotation Add the users who are allocated the 24/7 shift That completes the configuration of the Rotations, we now need to configure the Escalation Policies and Routing Keys. 5. Configure Escalation Policies \u00b6 Navigate to the Escalation Polices tab on the Teams sub menu, you should have no existing Polices so we need to create some. We are going to create three different Polices to cover off three typical use cases. 5.1. 24/7 \u00b6 Click Add Escalation Policy Policy Name: \" 24/7 \" Step 1 Immediately Notify the on-duty user(s) in rotation \u2192 Senior SRE Escalation Click Save 5.2. Primary \u00b6 Click Add Escalation Policy Policy Name: \" Primary \" Step 1 Immediately Notify the on-duty user(s) in rotation \u2192 Follow the Sun Support - Business Hours Click Add Step Step 2 If still unacked after 15 minutes Notify the next user(s) in the current on-duty shift \u2192 Follow the Sun Support - Business Hours Click Add Step Step 3 If still unacked after 15 more minutes Execute Policy \u2192 [Your Team Name] : 24/7 Click Save 5.3. Waiting Room \u00b6 Click Add Escalation Policy Policy Name: \" Waiting Room \" Step 1 If still unacked after 10 more minutes Execute Policy \u2192 [Your Team Name] : Primary Click Save You may have noticed that when we created each policy there was the warning message There are no routing keys for this policy - it will only receive incidents via manual reroute or when on another escalation policy This is because there are no Routing Keys linked to these Escalation Polices, so now that we have these polices configured we can go and create the Routing Keys. 6. Create Routing Keys \u00b6 Routing Keys map the incoming alert messages from your monitoring system to an Escalation Policy which in turn sends the notifications to the appropriate team. Navigate to Settings on the main menu bar. You'll be dropped into the Routing Key configuration by default. There will probably already be a number of Routing Keys configured, but to add a new one simply click Add Key then enter the name for the key in the empty box in the Routing Key column, and then select the appropriate policy from the drop down in the Escalation Polices column. Create the following two Routing Keys: Routing Key Escalation Policies [Your Initials]_PRI [Your Team Name] : Primary [Your Initials]_WR [Your Team Name] : Waiting Room Note You can assign a Routing Key to multiple Escalation Policies if required by simply selecting more from the list If you now navigate back to Teams \u2192 [Your Team Name] \u2192 Escalation Policies and look at the settings for your Primary and Waiting Room polices you will see that these now have Routes assigned to them. The 24/7 policy does not have a Route assigned as this will only be triggered via an Execute Policy escalation from the Primary policy. This completes the initial getting started steps for VictorOps, the next step will be to configure the Integration between VictorOps and SignalFx.","title":"Getting Started"},{"location":"module7/vo_getting_started/#victorops-getting-started-lab-summary","text":"Activate your login Configure your Profile Create your Team Configure Rotations Configure Escalation Policies Create Routing Keys","title":"VictorOps Getting Started - Lab Summary"},{"location":"module7/vo_getting_started/#1-activate-your-login","text":"You will have received an invitation to Activate your VictorOps account via e-mail, click the 'Activate Account' link and follow the prompts.","title":"1. Activate your login"},{"location":"module7/vo_getting_started/#2-configure-your-profile","text":"Once you are logged in to VictorOps you now need to set up your profile. Click on your login name in the top right hand corner and chose Profile from the drop down.","title":"2. Configure Your Profile"},{"location":"module7/vo_getting_started/#21-contact-methods","text":"Confirm your contact methods are listed correctly and add any additional phone numbers and e-mail address you wish to use.","title":"2.1. Contact Methods"},{"location":"module7/vo_getting_started/#22-devices","text":"Install the VictorOps app for your smartphone. Search your phones App Store for VictorOps to find the appropriate version of the app. The publisher should be listed as VictorOps Inc. Configuration help guides are available here: Apple Android Install the App and login, then refresh the Profile page and your device should now be listed under the devices section. Click the Test push notification button and confirm you receive the test message.","title":"2.2. Devices"},{"location":"module7/vo_getting_started/#23-personal-calendar","text":"This link will enable you to sync your VictorOps on-call schedule with your calendar, however as you do not have any allocated shifts yet this will currently be empty. You can add it to you calendar by copying the link into your preferred application and setting it up as a new subscription.","title":"2.3. Personal Calendar"},{"location":"module7/vo_getting_started/#24-paging-polices","text":"Paging Polices specify how you will be contacted by VictorOps when on-call. The Primary Paging Policy will have defaulted to sending you an SMS assuming you added your phone number when activating your account. We will now configure this policy into a three tier multi-stage policy. Click the edit policy button for the Primary Paging Policy. Step 1 Send a push notification to all my devices Execute the next step if I have not responded within 5 minutes Then add an new step Step 2 Send an email to [your email address] Execute the next step if I have not responded within 5 minutes Then add a new step Step 3 Every 5 minutes until we have reached you Make a phone call to [your phone number] Then save the policy. When you are on-call or in the escalation path of an incident, you will receive notifications in this order following these time delays. To cease the paging you must acknowledge the incident. Acknowledgements can occur in one of the following ways: Expanding the Push Notification on your device and selecting Acknowledge Responding to the SMS with the 5 digit code included Pressing 4 during the Phone Call Slack Button For more information on Notification Types, see here . Custom paging polices enable you to override the primary policy based on the time and day of the week. A good example would be get the system to immediately phone you whenever you get a page during the evening or weekends as this is more likely to get your attention than a push notification. Create a new Custom Policy by clicking Add a Policy and configure with the following settings: Policy Name: Evening Step 1 Every 5 minutes until we have reached you Make a phone call to [your phone number] Time Period: All 7 Days Timezone [your time zone] Between 7pm and 9am Save the policy then add one more Policy Name: Weekend Step 1 Every 5 minutes until we have reached you Make a phone call to [your phone number] Time Period: Sat & Sun Timezone [your time zone] Between 9am and 7pm These custom paging policies will be used during the specified times in place of the Primary Policy, however admins do have the ability to ignore these custom policies, and we will highlight how this is achieved in a later module. The final option here is the setting for Recovery Notifications. As these are typically low priority simply sending you an email is the typical setting used. Your profile is now fully configured using these example configurations. Organizations will have different views on how profiles should be configured and will typically issue guidelines for paging policies and times between escalations etc.","title":"2.4. Paging Polices"},{"location":"module7/vo_getting_started/#3-create-your-team","text":"Navigate to the Teams Tab on the main toolbar, select Add Team , then enter your team name using the format \"[Your Initials] Workshop\" and then save by clicking the Add Team button. You now need to add other users to your team. If you are running this workshop using the Splunk provided environment, the following accounts are available for testing. If you are running this lab in your own environment, you will have been provided a list of usernames you can use in place of the table below. Name Username Shift Duane Chow duanechow Europe Steven Gomez gomez Europe Walter White heisenberg Europe Jim Halpert jimhalpert Asia Lydia Rodarte-Quayle lydia Asia Marie Schrader marie Asia Maximo Arciniega maximo West Coast Michael Scott michaelscott West Coast Tuco Salamanca tuco West Coast Jack Welker jackwelker 24/7 Hank Schrader hankschrader 24/7 Pam Beesly pambeesly 24/7 Add the users to your team, using either the above list or the alternate one provided to you. The value in the Shift column can be ignored for now, but will be required for a later step. Click the Invite User button then either start typing the usernames (this will filter the list), or copy and paste them into the dialogue box. Once all users are added click the Add User button. To make a team member a Team Admin, simply click the Pencil icon in the right hand column, pick any user and make them an Admin. Tip For large team management you could use the API to streamline this process, and we will look at that in a later module","title":"3. Create Your Team"},{"location":"module7/vo_getting_started/#4-configure-rotations","text":"Navigate to the Rotations tab on the Teams sub menu, you should have no existing Rotations so we need to create some. The 1st Rotation you will create is for a follow the sun support pattern where the members of each shift provide cover during their normal working hours within their time zone. The 2nd will be a Rotation used to provide escalation support by more experienced senior members of the team, based on a 24/7, 1 week shift pattern.","title":"4. Configure Rotations"},{"location":"module7/vo_getting_started/#41-follow-the-sun-support-business-hours","text":"Click Add Rotation Enter a name of \" Follow the Sun Support - Business Hours \" Select Partial day from the three available shift templates Enter a Shift name of \" Asia \" Time Zone set to \" Asia/Tokyo \" Each user is on duty from \" Monday through Friday from 9.00am to 5.00pm \" Handoff happens every \" 7 days \" The next handoff happens - Select the next Monday using the calendar Click Save Rotation Now add an 2nd shift for Europe by clicking +Add a shift - Partial Day Enter a Shift name of \" Europe \" Time Zone set to \" Europe/London \" Each user is on duty from \" Monday through Friday from 9.00am to 5.00pm \" Handoff happens every \" 7 days \" The next handoff happens - Select the next Monday using the calendar Click Save Shift Now add a 3rd shift for West Coast USA by clicking +Add a shift - Partial Day Enter a Shift name of \" West Coast \" Time Zone set to \" US/Pacific \" Each user is on duty from \" Monday through Friday from 9.00am to 5.00pm \" Handoff happens every \" 7 days \" The next handoff happens - Select the next Monday using the calendar Click Save Shift You new need to add the users into their allocated shift patterns using either the table above, or the list of users provided to you separately For each Shift, click on the Manage Members icon which is the left of the three icons and resembles the image of three heads Add the users to each Shift (note how you have to use their Username and not their real names) The first user added will be the 'current' user for that shift You can re-order the shifts by simply dragging the users up and down, and you can change the current user by clicking Set Current on an alternate user You will now have three different Shift patterns, that provide cover 24hr hours, Mon - Fri, but with no cover at weekends. We will now add the 2nd Rotation for our Senior SRE Escalation cover.","title":"4.1. Follow the Sun Support - Business Hours"},{"location":"module7/vo_getting_started/#42-senior-sre-escalation","text":"Click Add Rotation Enter a name of \" Senior SRE Escalation \" Select 24/7 from the three available shift templates Enter a Shift name of \" Senior SRE Escalation \" Time Zone set to \" Asia/Tokyo \" Handoff happens every \" 7 days at 9.00am \" The next handoff happens [select the next Monday from the date picker] Click Save Rotation Add the users who are allocated the 24/7 shift That completes the configuration of the Rotations, we now need to configure the Escalation Policies and Routing Keys.","title":"4.2. Senior SRE Escalation"},{"location":"module7/vo_getting_started/#5-configure-escalation-policies","text":"Navigate to the Escalation Polices tab on the Teams sub menu, you should have no existing Polices so we need to create some. We are going to create three different Polices to cover off three typical use cases.","title":"5. Configure Escalation Policies"},{"location":"module7/vo_getting_started/#51-247","text":"Click Add Escalation Policy Policy Name: \" 24/7 \" Step 1 Immediately Notify the on-duty user(s) in rotation \u2192 Senior SRE Escalation Click Save","title":"5.1. 24/7"},{"location":"module7/vo_getting_started/#52-primary","text":"Click Add Escalation Policy Policy Name: \" Primary \" Step 1 Immediately Notify the on-duty user(s) in rotation \u2192 Follow the Sun Support - Business Hours Click Add Step Step 2 If still unacked after 15 minutes Notify the next user(s) in the current on-duty shift \u2192 Follow the Sun Support - Business Hours Click Add Step Step 3 If still unacked after 15 more minutes Execute Policy \u2192 [Your Team Name] : 24/7 Click Save","title":"5.2. Primary"},{"location":"module7/vo_getting_started/#53-waiting-room","text":"Click Add Escalation Policy Policy Name: \" Waiting Room \" Step 1 If still unacked after 10 more minutes Execute Policy \u2192 [Your Team Name] : Primary Click Save You may have noticed that when we created each policy there was the warning message There are no routing keys for this policy - it will only receive incidents via manual reroute or when on another escalation policy This is because there are no Routing Keys linked to these Escalation Polices, so now that we have these polices configured we can go and create the Routing Keys.","title":"5.3. Waiting Room"},{"location":"module7/vo_getting_started/#6-create-routing-keys","text":"Routing Keys map the incoming alert messages from your monitoring system to an Escalation Policy which in turn sends the notifications to the appropriate team. Navigate to Settings on the main menu bar. You'll be dropped into the Routing Key configuration by default. There will probably already be a number of Routing Keys configured, but to add a new one simply click Add Key then enter the name for the key in the empty box in the Routing Key column, and then select the appropriate policy from the drop down in the Escalation Polices column. Create the following two Routing Keys: Routing Key Escalation Policies [Your Initials]_PRI [Your Team Name] : Primary [Your Initials]_WR [Your Team Name] : Waiting Room Note You can assign a Routing Key to multiple Escalation Policies if required by simply selecting more from the list If you now navigate back to Teams \u2192 [Your Team Name] \u2192 Escalation Policies and look at the settings for your Primary and Waiting Room polices you will see that these now have Routes assigned to them. The 24/7 policy does not have a Route assigned as this will only be triggered via an Execute Policy escalation from the Primary policy. This completes the initial getting started steps for VictorOps, the next step will be to configure the Integration between VictorOps and SignalFx.","title":"6. Create Routing Keys"},{"location":"module7/vo_incident_lifecycle/","text":"Lab Summary \u00b6 UI Overview Generate Incidents Manage Incidents 1. UI Overview \u00b6 The aim of VictorOps is to \"Make On Call Suck Less\", and it does this by getting the critical data, to the right people, at the right time. The key to making VictorOps work for you is to centralize all your alerting sources, sending them all to the VictorOps platform, then you have a single pane of glass in which to manage all of your alerting. Login to the VictorOps UI and select the Timeline tab on the main menu bar, you should have a screen similar to the following image: 1.1 People \u00b6 On the left we have the People section with the Teams and Users sub tabs. On the Teams tab, click on All Teams then expand [Your Teamname]. Users with the VictorOps Logo against their name are currently on call. Here you can see who is on call within a particular Team, or across all Teams via Users \u2192 On-Call . If you click into one of the currently on call users, you can see their status. It shows which Rotation they are on call for, when their current Shift ends and their next Shift starts (times are displayed in your timezone), what contact methods they have and which Teams they belong to (dummy users such as Hank do not have Contact Methods configured). 1.2 Timeline \u00b6 In the centre Timeline section you get a realtime view of what is happening within your environment with the newest messages at the top. Here you can quickly post update messages to make your colleagues aware of important developments etc. You can filter the view using the buttons on the top toolbar showing only update messages, github integrations, or apply more advanced filters. Lets change the Filters settings to streamline your view. Click the Filters button then within the Routing Keys tab change the show setting from all routing keys to selected routing keys , then change the My Keys value to all and the Other Keys value to selected and deselect all keys under the Other Keys section. Click anywhere outside of the dialogue box to close it. You will probably now have a much simpler view as you will not currently have Incidents created using your Routing Keys, so you are left with the other types of messages that the Timeline can display. Click on Filters again, but this time switch to the Message Types tab. Here you control the types of messages that are displayed. For example deselect On-call Changes and Escalations , this will reduce the amount of messages displayed. 1.3 Incidents \u00b6 On the right we have the Incidents section. Here we get a list of all the incidents within the platform, or we view a more specific list such as incidents you are specifically assigned to, or for any of the Teams you are a member of. Select the Team Incidents tab you should find that the Triggered , Acknowledged & Resolved tabs are currently all empty as you have had no incidents logged, yet so let's change that by generating your first incident. 2. Generate Incidents \u00b6 2.1 On-Call \u00b6 Before generating any incidents you should assign yourself to the current Shift within your Follow the Sun Support - Business Hours Rotation and also place yourself On-Call . Click on the Schedule link within your Team in the People section on the left Or navigate to Teams \u2192 [Your Team] \u2192 Rotations Expand the Follow the Sun Support - Business Hours Rotation Click on the Manage members icon (the figures) for the current active shift depending on your timezone Use the Select a user to add... dropdown to add yourself to the shift Then click on Set Current to make yourself the current on-call user within the shift You should now get a Push Notification to your phone informing you that You Are Now On-Call 2.2 Trigger Alert \u00b6 Log into your first VM you created during step 2. Creating a Test Environment in VictorOps Integrations Input multipass shell [YOUR INITIALS]-vo1 Example multipass shell gh-vo1 Output Welcome to Ubuntu 18.04.4 LTS (GNU/Linux 4.15.0-96-generic x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage System information as of Wed Apr 22 11:13:48 BST 2020 System load: 0.0 Processes: 105 Usage of /: 88.7% of 1.96GB Users logged in: 0 Memory usage: 19% IP address for enp0s2: 192.168.64.13 Swap usage: 0% => / is using 88.7% of 1.96GB * Kubernetes 1.18 GA is now available! See https://microk8s.io for docs or install it with: sudo snap install microk8s --channel=1.18 --classic * Multipass 1.1 adds proxy support for developers behind enterprise firewalls. Rapid prototyping for cloud operations just got easier. https://multipass.run/ * Canonical Livepatch is available for installation. - Reduce system reboots and improve kernel security. Activate at: https://ubuntu.com/livepatch 0 packages can be updated. 0 updates are security updates. Last login: Tue Apr 21 17:29:23 2020 from 192.168.64.1 To run a command as administrator (user \"root\"), use \"sudo <command>\". See \"man sudo_root\" for details. ubuntu@gh-vo1:~$ Force the CPU to spike to 100% by running the following command: Input openssl speed -multi $(grep -ci processor /proc/cpuinfo) Output Forked child 0 +DT:md4:3:16 +R:19357020:md4:3.000000 +DT:md4:3:64 +R:14706608:md4:3.010000 +DT:md4:3:256 +R:8262960:md4:3.000000 +DT:md4:3:1024 This will result in an Alert being generated by SignalFx which in turn will generate an Incident within VictorOps within a maximum of 10 seconds as this is the default poling time for the SignalFx Agent we installed (it can be reduced to 1sec if required). 3. Managing Incidents \u00b6 Use your VictorOps App on your phone to acknowledge the Incident by clicking on the push notification ... ...clicking on the alert... ...then clicking on either the single tick in the top right hand corner, or the Acknowledge link. The single tick will then transform into a double tick , and the status will change from TRIGGERED to ACKNOWLEDGED . Still on your phone, select the Alert Details tab. Then on the Web UI, navigate back to Timeline , select Team Incidents on the right, then select Acknowledged and click into the new Incident . You should now have the Details tab displayed on both your Phone and the Web UI. Notice how they both show the exact same information. Now select the Annotations tab on both the Phone and the Web UI, you should have a Graph displayed in the UI which is generated by SignalFx. On your phone click the Chart Showing Alert link... ...and you should now get the exact same image on your phone. VictorOps is a 'Mobile First' platform meaning the phone app is full functionality and you can manage an incident directly from your phone. For the remainder of this module we will focus on the Web UI however please spend some time later exploring the phone app features. Sticking with the Web UI, click the 2. Alert Details in SignalFx link... ...this will open a new browser tab and take you directly to the Alert within SignalFx where you could then progress your troubleshooting using the powerful tools built into the SignalFx UI. However, we are focussing on VictorOps so close this tab and return to the VictorOps UI. What if VictorOps could identify previous incidents within the system which may give you a clue to the best way to tackle this incident. The Similar Incidents tab does exactly that, surfacing previous incidents allowing you to look at them and see what actions were taken to resolve them, actions which could be easily repeated for this incident. At the top right in the UI are a number of icons that allow quick access to various actions, click on the far right one which will open this Incident in a new window. With the Incident expanded, you can see on the right we have a Time Line view where you can add messages and see the history of previous alerts and interactions. On the far left you have the option of allocating additional resources to this incident by clicking on the Add Responders link. This allows you build a virtual team specific to this incident by adding other Teams or individual Users, and also share details of a Conference Bridge where you can all get together and collaborate. Close the Add Responders dialogue by clicking cancel . You can also snooze this incident for up to 24hrs by clicking on the alarm clock in the very top left, or re-route it to a different team who may be better placed to deal with this particular incident. Now lets fix this issue and update the Incident with what we did. Add a new message at the top right such as Discovered rogue process, terminated it . Now kill off the process we started in the VM to max out the CPU. Within no greater than 10 seconds SignalFx should detect the new CPU value, clear the alert state in SignalFx, then automatically update the Incident in VictorOps marking it as `Resolved'. That completes this introduction to VictorOps, but feel free to checkout the more advanced modules which will be published in the coming weeks in the Optional Modules section. These will cover topics such as: Reporting Using the API Webhooks Alert Rules Engine Maintenance Mode 4. Post Workshop Clean Up \u00b6 Once you have finished with this workshop exit from the Multipass instance(s) you are in and get back to your system command prompt and enter the following to delete the Multipass instance(s), replace [YOUR_INITIALS] with the ones you used in Integrations - Step #2.3 : Input multipass delete --purge [ YOUR_INITIALS ] -vo1","title":"Incident Lifecycle"},{"location":"module7/vo_incident_lifecycle/#lab-summary","text":"UI Overview Generate Incidents Manage Incidents","title":"Lab Summary"},{"location":"module7/vo_incident_lifecycle/#1-ui-overview","text":"The aim of VictorOps is to \"Make On Call Suck Less\", and it does this by getting the critical data, to the right people, at the right time. The key to making VictorOps work for you is to centralize all your alerting sources, sending them all to the VictorOps platform, then you have a single pane of glass in which to manage all of your alerting. Login to the VictorOps UI and select the Timeline tab on the main menu bar, you should have a screen similar to the following image:","title":"1. UI Overview"},{"location":"module7/vo_incident_lifecycle/#11-people","text":"On the left we have the People section with the Teams and Users sub tabs. On the Teams tab, click on All Teams then expand [Your Teamname]. Users with the VictorOps Logo against their name are currently on call. Here you can see who is on call within a particular Team, or across all Teams via Users \u2192 On-Call . If you click into one of the currently on call users, you can see their status. It shows which Rotation they are on call for, when their current Shift ends and their next Shift starts (times are displayed in your timezone), what contact methods they have and which Teams they belong to (dummy users such as Hank do not have Contact Methods configured).","title":"1.1 People"},{"location":"module7/vo_incident_lifecycle/#12-timeline","text":"In the centre Timeline section you get a realtime view of what is happening within your environment with the newest messages at the top. Here you can quickly post update messages to make your colleagues aware of important developments etc. You can filter the view using the buttons on the top toolbar showing only update messages, github integrations, or apply more advanced filters. Lets change the Filters settings to streamline your view. Click the Filters button then within the Routing Keys tab change the show setting from all routing keys to selected routing keys , then change the My Keys value to all and the Other Keys value to selected and deselect all keys under the Other Keys section. Click anywhere outside of the dialogue box to close it. You will probably now have a much simpler view as you will not currently have Incidents created using your Routing Keys, so you are left with the other types of messages that the Timeline can display. Click on Filters again, but this time switch to the Message Types tab. Here you control the types of messages that are displayed. For example deselect On-call Changes and Escalations , this will reduce the amount of messages displayed.","title":"1.2 Timeline"},{"location":"module7/vo_incident_lifecycle/#13-incidents","text":"On the right we have the Incidents section. Here we get a list of all the incidents within the platform, or we view a more specific list such as incidents you are specifically assigned to, or for any of the Teams you are a member of. Select the Team Incidents tab you should find that the Triggered , Acknowledged & Resolved tabs are currently all empty as you have had no incidents logged, yet so let's change that by generating your first incident.","title":"1.3 Incidents"},{"location":"module7/vo_incident_lifecycle/#2-generate-incidents","text":"","title":"2. Generate Incidents"},{"location":"module7/vo_incident_lifecycle/#21-on-call","text":"Before generating any incidents you should assign yourself to the current Shift within your Follow the Sun Support - Business Hours Rotation and also place yourself On-Call . Click on the Schedule link within your Team in the People section on the left Or navigate to Teams \u2192 [Your Team] \u2192 Rotations Expand the Follow the Sun Support - Business Hours Rotation Click on the Manage members icon (the figures) for the current active shift depending on your timezone Use the Select a user to add... dropdown to add yourself to the shift Then click on Set Current to make yourself the current on-call user within the shift You should now get a Push Notification to your phone informing you that You Are Now On-Call","title":"2.1 On-Call"},{"location":"module7/vo_incident_lifecycle/#22-trigger-alert","text":"Log into your first VM you created during step 2. Creating a Test Environment in VictorOps Integrations Input multipass shell [YOUR INITIALS]-vo1 Example multipass shell gh-vo1 Output Welcome to Ubuntu 18.04.4 LTS (GNU/Linux 4.15.0-96-generic x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage System information as of Wed Apr 22 11:13:48 BST 2020 System load: 0.0 Processes: 105 Usage of /: 88.7% of 1.96GB Users logged in: 0 Memory usage: 19% IP address for enp0s2: 192.168.64.13 Swap usage: 0% => / is using 88.7% of 1.96GB * Kubernetes 1.18 GA is now available! See https://microk8s.io for docs or install it with: sudo snap install microk8s --channel=1.18 --classic * Multipass 1.1 adds proxy support for developers behind enterprise firewalls. Rapid prototyping for cloud operations just got easier. https://multipass.run/ * Canonical Livepatch is available for installation. - Reduce system reboots and improve kernel security. Activate at: https://ubuntu.com/livepatch 0 packages can be updated. 0 updates are security updates. Last login: Tue Apr 21 17:29:23 2020 from 192.168.64.1 To run a command as administrator (user \"root\"), use \"sudo <command>\". See \"man sudo_root\" for details. ubuntu@gh-vo1:~$ Force the CPU to spike to 100% by running the following command: Input openssl speed -multi $(grep -ci processor /proc/cpuinfo) Output Forked child 0 +DT:md4:3:16 +R:19357020:md4:3.000000 +DT:md4:3:64 +R:14706608:md4:3.010000 +DT:md4:3:256 +R:8262960:md4:3.000000 +DT:md4:3:1024 This will result in an Alert being generated by SignalFx which in turn will generate an Incident within VictorOps within a maximum of 10 seconds as this is the default poling time for the SignalFx Agent we installed (it can be reduced to 1sec if required).","title":"2.2 Trigger Alert"},{"location":"module7/vo_incident_lifecycle/#3-managing-incidents","text":"Use your VictorOps App on your phone to acknowledge the Incident by clicking on the push notification ... ...clicking on the alert... ...then clicking on either the single tick in the top right hand corner, or the Acknowledge link. The single tick will then transform into a double tick , and the status will change from TRIGGERED to ACKNOWLEDGED . Still on your phone, select the Alert Details tab. Then on the Web UI, navigate back to Timeline , select Team Incidents on the right, then select Acknowledged and click into the new Incident . You should now have the Details tab displayed on both your Phone and the Web UI. Notice how they both show the exact same information. Now select the Annotations tab on both the Phone and the Web UI, you should have a Graph displayed in the UI which is generated by SignalFx. On your phone click the Chart Showing Alert link... ...and you should now get the exact same image on your phone. VictorOps is a 'Mobile First' platform meaning the phone app is full functionality and you can manage an incident directly from your phone. For the remainder of this module we will focus on the Web UI however please spend some time later exploring the phone app features. Sticking with the Web UI, click the 2. Alert Details in SignalFx link... ...this will open a new browser tab and take you directly to the Alert within SignalFx where you could then progress your troubleshooting using the powerful tools built into the SignalFx UI. However, we are focussing on VictorOps so close this tab and return to the VictorOps UI. What if VictorOps could identify previous incidents within the system which may give you a clue to the best way to tackle this incident. The Similar Incidents tab does exactly that, surfacing previous incidents allowing you to look at them and see what actions were taken to resolve them, actions which could be easily repeated for this incident. At the top right in the UI are a number of icons that allow quick access to various actions, click on the far right one which will open this Incident in a new window. With the Incident expanded, you can see on the right we have a Time Line view where you can add messages and see the history of previous alerts and interactions. On the far left you have the option of allocating additional resources to this incident by clicking on the Add Responders link. This allows you build a virtual team specific to this incident by adding other Teams or individual Users, and also share details of a Conference Bridge where you can all get together and collaborate. Close the Add Responders dialogue by clicking cancel . You can also snooze this incident for up to 24hrs by clicking on the alarm clock in the very top left, or re-route it to a different team who may be better placed to deal with this particular incident. Now lets fix this issue and update the Incident with what we did. Add a new message at the top right such as Discovered rogue process, terminated it . Now kill off the process we started in the VM to max out the CPU. Within no greater than 10 seconds SignalFx should detect the new CPU value, clear the alert state in SignalFx, then automatically update the Incident in VictorOps marking it as `Resolved'. That completes this introduction to VictorOps, but feel free to checkout the more advanced modules which will be published in the coming weeks in the Optional Modules section. These will cover topics such as: Reporting Using the API Webhooks Alert Rules Engine Maintenance Mode","title":"3. Managing Incidents"},{"location":"module7/vo_incident_lifecycle/#4-post-workshop-clean-up","text":"Once you have finished with this workshop exit from the Multipass instance(s) you are in and get back to your system command prompt and enter the following to delete the Multipass instance(s), replace [YOUR_INITIALS] with the ones you used in Integrations - Step #2.3 : Input multipass delete --purge [ YOUR_INITIALS ] -vo1","title":"4. Post Workshop Clean Up"},{"location":"module7/vo_integrations/","text":"VictorOps Integrations - Lab Summary \u00b6 Configuring the Integration between VictorOps and SignalFx Creating a test environment using Multipass You are going to need to record a number of values during this module which we will export as variables in a later step so I suggest you create a values document to store the following values as you work through it. Values export SFXVOPSID = export ACCESS_TOKEN = export REALM = export ROUTINGKEY = export INITIALS = Service_API_Endpoint = 1. Configuring the Integration between VictorOps and SignalFx \u00b6 1.1. VictorOps Service API Endpoint \u00b6 Warning The SignalFx Integration only needs to be enabled once per VictorOps instance, so you will probably find it has already been enabled, please DO NOT disable an already active integration when completing this lab. In order to integrate SignalFx with VictorOps we need to first obtain the Service API Endpoint for VictorOps. Within the VictorOps UI navigate to Integrations main tab and then use the search feature to find the SignalFx Integration. If it is not already enabled, click the Enable Integration button to activate it. You simply need to copy the Service API Endpoint, including the $routing_key into your values document using the Service_API_Endpoint parameter. This will be used when configuring the VictorOps Integration within the SignalFx UI. 1.2. Enable VictorOps Integration within SignalFx \u00b6 Login to your SignalFx account and navigate to Integrations and use the search feature to find the VictorOps integration. Assuming you are using the AppDev EMEA instance of VictorOps you will find the VictorOps Integration has already been configured so there is no need to create a new one. However the process of creating a new Integration is simply to click on Create New Integration like in the image below, or if there are existing integrations and you want to add another one you would click New Integration . ...give it a descriptive Name then paste the Service_API_Endpoint value you copied in the previous step into the Post URL field, then save it. Important SignalFx can integrate with multiple VictorOps accounts so it is important when creating one to use a descriptive name and to not simply call it VictorOps. This name will be used within the SignalFx UI when selecting this integration, so ensure it is unambiguous Once saved you need to copy the ID and save it in your values document using the SFXVOPSID parameter for use later in the module. Warning Please do not create additional VictorOps integrations if one already exists, it will not break anything but simply creates extra clean up work after the workshop has completed. The aim of this part of the lab was to show you how you would go about configuring the Integration if it was not already enabled. 2. Creating a Test Environment \u00b6 2.1. Multipass \u00b6 The easiest way to test VictorOps is to use Multipass to run some local test VMs which will be monitored by SignalFx. If you do not already have Multipass installed you can download the installer from here . Mac OS users can install it using Homebrew by running: Code brew cask install multipass 2.2. SignalFx Details \u00b6 We will use cloud-init to install the SignalFx Agent into the VMs but we first need to obtain the Token and Realm from your SignalFx account. You can find your Access Token by clicking on the settings icon on the top right of the SignalFx UI, select Organization Settings \u2192 Access Tokens , expand the Default token, then click on Show Token to expose your token, click the Copy button to copy it to your clipboard, then paste it into your values document using the ACCESS_TOKEN parameter. You will also need to obtain the name of the Realm for your SignalFx account. Click on the account icon again, but this time select My Profile . The Ream can be found in the middle of the page within the Organizations section. In this example it is us1 . Again, make a note of this in your values document using the REALM parameter. 2.3. Local VMs using Multipass \u00b6 The next step is to create a cloud-init file that will automatically install the SignalFx Agent when the VMs are created. Create a victorops.yaml file using your preferred editor and populate it with the following, but replacing [YOUR REALM] & [YOUR TOKEN] with the values stored in your values document . victorops.yaml #cloud-config package_update: true package_upgrade: true runcmd: - curl -sSL https://dl.signalfx.com/signalfx-agent.sh > /tmp/signalfx-agent.sh - sudo sh /tmp/signalfx-agent.sh --realm [ YOUR REALM ] -- [ YOUR TOKEN ] With the victorops.yaml file created, from the same directory where you created it run the following commands to create two VMs. As in other modules prefix the name of each VM with your initials to make them unique within your SignalFx account. You may also want to first shutdown any other VMs you still have running from previous modules to free up resources. Tip Use two terminal windows to create the two VMs in parallel 1st VictorOps VM Input multipass launch \\ --name [ YOUR INITIALS ] -vo1 \\ --cloud-init victorops.yaml Output multipass launch \\ --name gh-vo1 \\ --cloud-init victorops.yaml Launched: gh-vo1 2nd VictorOps VM Input multipass launch \\ --name [ YOUR INITIALS ] -vo2 \\ --cloud-init victorops.yaml Output multipass launch \\ --name gh-vo2 \\ --cloud-init victorops.yaml Launched: gh-vo2 Once your two VMs have been created check within the SignalFx UI, Infrastructure Tab, and confirm they are reporting in correctly. Allow a couple or minutes for the VMs to spin up, install updates and then install the SignalFx Agent etc. If they fail to appear, double check your Token and Realm settings within your victorops.yaml file. If errors are found these can easily be updated directly within the VM. Simply update the token or api_url and ingest_url files located within /etc/signalfx . 2.4. SignalFx Detector \u00b6 We now need to create a new Detector within SignalFx which will use VictorOps as the target to send alerts to. We will use Terraform to create the detector in a similar way to the 'Monitoring as Code' module. If you have not completed the Monitoring as Code module, and do not have Terraform already installed, download and install it for your platform - https://www.terraform.io/downloads.html (min. requirement v. 0.12.18) Copy and run the following code to download the VictorOps Workshop Detectors master zip file, unzip the file, then change into the victorops-workshop-detectors-master directory. Input curl -LO https://github.com/signalfx/victorops-workshop-detectors/archive/master.zip unzip master.zip mv victorops-workshop-detectors-master victorops cd victorops Output % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 142 100 142 0 0 459 0 --:--:-- --:--:-- --:--:-- 459 100 4007 0 4007 0 0 5466 0 --:--:-- --:--:-- --:--:-- 17197 Archive: master.zip fcc95b101225ddb876d16106b5d7ece74a41f6c1 creating: victorops-workshop-detectors-master/ inflating: victorops-workshop-detectors-master/.DS_Store inflating: victorops-workshop-detectors-master/.gitignore inflating: victorops-workshop-detectors-master/README.md inflating: victorops-workshop-detectors-master/main.tf creating: victorops-workshop-detectors-master/modules/ inflating: victorops-workshop-detectors-master/modules/.DS_Store creating: victorops-workshop-detectors-master/modules/host/ inflating: victorops-workshop-detectors-master/modules/host/cpu.tf inflating: victorops-workshop-detectors-master/modules/host/variables.tf inflating: victorops-workshop-detectors-master/variables.tf extracting: victorops-workshop-detectors-master/versions.tf \u279c victorops-workshop-detectors-master Create the following environment variables to use in the Terraform steps below. The 1st three variables should be stored in your values document if you have been populating it as you have worked through this module. You can populate the final two now then simply copy all five lines into your terminal window where you downloaded the terraform files in the previous step. Variables export SFXVOPSID =[ VictorOps Integration ID from Step 2 ] export ACCESS_TOKEN =[ SignalFx Access Token from Step 2 ] export REALM =[ SignalFx Realm from Step 2 ] export ROUTINGKEY =[ YOUR_INITIALS ] _PRI export INITIALS =[ YOUR_INITIALS ] Example export SFXVOPSID = xxxxxxxxxxxx export ACCESS_TOKEN = xxxxxxxxxxxxxxx export REALM = us1 export ROUTINGKEY = GH_PRI export INITIALS = GH Initialize Terraform. Note You will need to run this command each time a new version of the Terraform Provider is released. You can track the releases on GitHub . Input terraform init -upgrade Output Upgrading modules... - host in modules/host Initializing the backend... Initializing provider plugins... - Checking for available provider plugins... - Downloading plugin for provider \"signalfx\" (terraform-providers/signalfx) 4.19.1... The following providers do not have any version constraints in configuration, so the latest version was installed. To prevent automatic upgrades to new major versions that may contain breaking changes, it is recommended to add version = \"...\" constraints to the corresponding provider blocks in configuration, with the constraint strings suggested below. * provider.signalfx: version = \"~> 4.19\" Terraform has been successfully initialized! You may now begin working with Terraform. Try running \"terraform plan\" to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary. Create a new Terraform Workspace which will track the state for this environment. Workspaces allow you to run Terraform against different environments each with their own state data stored in the workspace. In the following example we create a workspace called 'Workshop' but feel free to use whatever name you like. Input terraform workspace new Workshop Output Created and switched to workspace \"Workshop\"! You're now on a new, empty workspace. Workspaces isolate their state, so if you run \"terraform plan\" Terraform will not see any existing state for this configuration. It is considered best practice to run a terraform plan to see what changes may get made and check for potential errors before running an apply as we did in Monitoring as Code , however as the first stage of apply is to plan we can safely skip that step and just run apply. Check the plan output for errors before typing yes to commit the apply. Input terraform apply -var=\"access_token=$ACCESS_TOKEN\" -var=\"realm=$REALM\" -var=\"sfx_prefix=$INITIALS\" -var=\"sfx_vo_id=$SFXVOPSID\" -var=\"routing_key=$ROUTINGKEY\" Output An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # module.host.signalfx_detector.cpu_greater_90 will be created + resource \"signalfx_detector\" \"cpu_greater_90\" { + description = \"Alerts when CPU usage is greater than 90%\" + id = (known after apply) + max_delay = 0 + name = \"GH CPU greater than 90%\" + program_text = <<~EOT from signalfx.detectors.against_recent import against_recent A = data('cpu.utilization').publish(label='A') detect(when(A > threshold(90))).publish('CPU utilization is greater than 90%') EOT + show_data_markers = true + time_range = 3600 + url = (known after apply) + rule { + detect_label = \"CPU utilization is greater than 90%\" + disabled = false + notifications = [ + \"VictorOps,ERI0R2GAIAA,GH_PRI\", ] + parameterized_body = <<~EOT {{#if anomalous}} Rule \"{{{ruleName}}}\" in detector \"{{{detectorName}}}\" triggered at {{timestamp}}. {{else}} Rule \"{{{ruleName}}}\" in detector \"{{{detectorName}}}\" cleared at {{timestamp}}. {{/if}} {{#if anomalous}} Triggering condition: {{{readableRule}}} {{/if}} {{#if anomalous}} Signal value: {{inputs.A.value}} {{else}} Current signal value: {{inputs.A.value}} {{/if}} {{#notEmpty dimensions}} Signal details: {{{dimensions}}} {{/notEmpty}} {{#if anomalous}} {{#if runbookUrl}} Runbook: {{{runbookUrl}}} {{/if}} {{#if tip}} Tip: {{{tip}}} {{/if}} {{/if}} EOT + parameterized_subject = \"{{ruleSeverity}} Alert: {{{ruleName}}} ({{{detectorName}}})\" + severity = \"Warning\" } } Plan: 1 to add, 0 to change, 0 to destroy. Do you want to perform these actions in workspace \"Workshop\"? Terraform will perform the actions described above. Only 'yes' will be accepted to approve. Enter a value: yes module.host.signalfx_detector.cpu_greater_90: Creating... module.host.signalfx_detector.cpu_greater_90: Creation complete after 2s [id=EWHU-YAAAAA] Apply complete! Resources: 1 added, 0 changed, 0 destroyed. You have now configured the Integrations between VictorOps and SignalFx so the final part of this module is to test the flow of alerts from SignalFx into VictorOps and see how you can manage the incident with both the VictorOps UI and Mobile App.","title":"Integrations"},{"location":"module7/vo_integrations/#victorops-integrations-lab-summary","text":"Configuring the Integration between VictorOps and SignalFx Creating a test environment using Multipass You are going to need to record a number of values during this module which we will export as variables in a later step so I suggest you create a values document to store the following values as you work through it. Values export SFXVOPSID = export ACCESS_TOKEN = export REALM = export ROUTINGKEY = export INITIALS = Service_API_Endpoint =","title":"VictorOps Integrations - Lab Summary"},{"location":"module7/vo_integrations/#1-configuring-the-integration-between-victorops-and-signalfx","text":"","title":"1. Configuring the Integration between VictorOps and SignalFx"},{"location":"module7/vo_integrations/#11-victorops-service-api-endpoint","text":"Warning The SignalFx Integration only needs to be enabled once per VictorOps instance, so you will probably find it has already been enabled, please DO NOT disable an already active integration when completing this lab. In order to integrate SignalFx with VictorOps we need to first obtain the Service API Endpoint for VictorOps. Within the VictorOps UI navigate to Integrations main tab and then use the search feature to find the SignalFx Integration. If it is not already enabled, click the Enable Integration button to activate it. You simply need to copy the Service API Endpoint, including the $routing_key into your values document using the Service_API_Endpoint parameter. This will be used when configuring the VictorOps Integration within the SignalFx UI.","title":"1.1. VictorOps Service API Endpoint"},{"location":"module7/vo_integrations/#12-enable-victorops-integration-within-signalfx","text":"Login to your SignalFx account and navigate to Integrations and use the search feature to find the VictorOps integration. Assuming you are using the AppDev EMEA instance of VictorOps you will find the VictorOps Integration has already been configured so there is no need to create a new one. However the process of creating a new Integration is simply to click on Create New Integration like in the image below, or if there are existing integrations and you want to add another one you would click New Integration . ...give it a descriptive Name then paste the Service_API_Endpoint value you copied in the previous step into the Post URL field, then save it. Important SignalFx can integrate with multiple VictorOps accounts so it is important when creating one to use a descriptive name and to not simply call it VictorOps. This name will be used within the SignalFx UI when selecting this integration, so ensure it is unambiguous Once saved you need to copy the ID and save it in your values document using the SFXVOPSID parameter for use later in the module. Warning Please do not create additional VictorOps integrations if one already exists, it will not break anything but simply creates extra clean up work after the workshop has completed. The aim of this part of the lab was to show you how you would go about configuring the Integration if it was not already enabled.","title":"1.2. Enable VictorOps Integration within SignalFx"},{"location":"module7/vo_integrations/#2-creating-a-test-environment","text":"","title":"2. Creating a Test Environment"},{"location":"module7/vo_integrations/#21-multipass","text":"The easiest way to test VictorOps is to use Multipass to run some local test VMs which will be monitored by SignalFx. If you do not already have Multipass installed you can download the installer from here . Mac OS users can install it using Homebrew by running: Code brew cask install multipass","title":"2.1. Multipass"},{"location":"module7/vo_integrations/#22-signalfx-details","text":"We will use cloud-init to install the SignalFx Agent into the VMs but we first need to obtain the Token and Realm from your SignalFx account. You can find your Access Token by clicking on the settings icon on the top right of the SignalFx UI, select Organization Settings \u2192 Access Tokens , expand the Default token, then click on Show Token to expose your token, click the Copy button to copy it to your clipboard, then paste it into your values document using the ACCESS_TOKEN parameter. You will also need to obtain the name of the Realm for your SignalFx account. Click on the account icon again, but this time select My Profile . The Ream can be found in the middle of the page within the Organizations section. In this example it is us1 . Again, make a note of this in your values document using the REALM parameter.","title":"2.2. SignalFx Details"},{"location":"module7/vo_integrations/#23-local-vms-using-multipass","text":"The next step is to create a cloud-init file that will automatically install the SignalFx Agent when the VMs are created. Create a victorops.yaml file using your preferred editor and populate it with the following, but replacing [YOUR REALM] & [YOUR TOKEN] with the values stored in your values document . victorops.yaml #cloud-config package_update: true package_upgrade: true runcmd: - curl -sSL https://dl.signalfx.com/signalfx-agent.sh > /tmp/signalfx-agent.sh - sudo sh /tmp/signalfx-agent.sh --realm [ YOUR REALM ] -- [ YOUR TOKEN ] With the victorops.yaml file created, from the same directory where you created it run the following commands to create two VMs. As in other modules prefix the name of each VM with your initials to make them unique within your SignalFx account. You may also want to first shutdown any other VMs you still have running from previous modules to free up resources. Tip Use two terminal windows to create the two VMs in parallel 1st VictorOps VM Input multipass launch \\ --name [ YOUR INITIALS ] -vo1 \\ --cloud-init victorops.yaml Output multipass launch \\ --name gh-vo1 \\ --cloud-init victorops.yaml Launched: gh-vo1 2nd VictorOps VM Input multipass launch \\ --name [ YOUR INITIALS ] -vo2 \\ --cloud-init victorops.yaml Output multipass launch \\ --name gh-vo2 \\ --cloud-init victorops.yaml Launched: gh-vo2 Once your two VMs have been created check within the SignalFx UI, Infrastructure Tab, and confirm they are reporting in correctly. Allow a couple or minutes for the VMs to spin up, install updates and then install the SignalFx Agent etc. If they fail to appear, double check your Token and Realm settings within your victorops.yaml file. If errors are found these can easily be updated directly within the VM. Simply update the token or api_url and ingest_url files located within /etc/signalfx .","title":"2.3. Local VMs using Multipass"},{"location":"module7/vo_integrations/#24-signalfx-detector","text":"We now need to create a new Detector within SignalFx which will use VictorOps as the target to send alerts to. We will use Terraform to create the detector in a similar way to the 'Monitoring as Code' module. If you have not completed the Monitoring as Code module, and do not have Terraform already installed, download and install it for your platform - https://www.terraform.io/downloads.html (min. requirement v. 0.12.18) Copy and run the following code to download the VictorOps Workshop Detectors master zip file, unzip the file, then change into the victorops-workshop-detectors-master directory. Input curl -LO https://github.com/signalfx/victorops-workshop-detectors/archive/master.zip unzip master.zip mv victorops-workshop-detectors-master victorops cd victorops Output % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 142 100 142 0 0 459 0 --:--:-- --:--:-- --:--:-- 459 100 4007 0 4007 0 0 5466 0 --:--:-- --:--:-- --:--:-- 17197 Archive: master.zip fcc95b101225ddb876d16106b5d7ece74a41f6c1 creating: victorops-workshop-detectors-master/ inflating: victorops-workshop-detectors-master/.DS_Store inflating: victorops-workshop-detectors-master/.gitignore inflating: victorops-workshop-detectors-master/README.md inflating: victorops-workshop-detectors-master/main.tf creating: victorops-workshop-detectors-master/modules/ inflating: victorops-workshop-detectors-master/modules/.DS_Store creating: victorops-workshop-detectors-master/modules/host/ inflating: victorops-workshop-detectors-master/modules/host/cpu.tf inflating: victorops-workshop-detectors-master/modules/host/variables.tf inflating: victorops-workshop-detectors-master/variables.tf extracting: victorops-workshop-detectors-master/versions.tf \u279c victorops-workshop-detectors-master Create the following environment variables to use in the Terraform steps below. The 1st three variables should be stored in your values document if you have been populating it as you have worked through this module. You can populate the final two now then simply copy all five lines into your terminal window where you downloaded the terraform files in the previous step. Variables export SFXVOPSID =[ VictorOps Integration ID from Step 2 ] export ACCESS_TOKEN =[ SignalFx Access Token from Step 2 ] export REALM =[ SignalFx Realm from Step 2 ] export ROUTINGKEY =[ YOUR_INITIALS ] _PRI export INITIALS =[ YOUR_INITIALS ] Example export SFXVOPSID = xxxxxxxxxxxx export ACCESS_TOKEN = xxxxxxxxxxxxxxx export REALM = us1 export ROUTINGKEY = GH_PRI export INITIALS = GH Initialize Terraform. Note You will need to run this command each time a new version of the Terraform Provider is released. You can track the releases on GitHub . Input terraform init -upgrade Output Upgrading modules... - host in modules/host Initializing the backend... Initializing provider plugins... - Checking for available provider plugins... - Downloading plugin for provider \"signalfx\" (terraform-providers/signalfx) 4.19.1... The following providers do not have any version constraints in configuration, so the latest version was installed. To prevent automatic upgrades to new major versions that may contain breaking changes, it is recommended to add version = \"...\" constraints to the corresponding provider blocks in configuration, with the constraint strings suggested below. * provider.signalfx: version = \"~> 4.19\" Terraform has been successfully initialized! You may now begin working with Terraform. Try running \"terraform plan\" to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary. Create a new Terraform Workspace which will track the state for this environment. Workspaces allow you to run Terraform against different environments each with their own state data stored in the workspace. In the following example we create a workspace called 'Workshop' but feel free to use whatever name you like. Input terraform workspace new Workshop Output Created and switched to workspace \"Workshop\"! You're now on a new, empty workspace. Workspaces isolate their state, so if you run \"terraform plan\" Terraform will not see any existing state for this configuration. It is considered best practice to run a terraform plan to see what changes may get made and check for potential errors before running an apply as we did in Monitoring as Code , however as the first stage of apply is to plan we can safely skip that step and just run apply. Check the plan output for errors before typing yes to commit the apply. Input terraform apply -var=\"access_token=$ACCESS_TOKEN\" -var=\"realm=$REALM\" -var=\"sfx_prefix=$INITIALS\" -var=\"sfx_vo_id=$SFXVOPSID\" -var=\"routing_key=$ROUTINGKEY\" Output An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # module.host.signalfx_detector.cpu_greater_90 will be created + resource \"signalfx_detector\" \"cpu_greater_90\" { + description = \"Alerts when CPU usage is greater than 90%\" + id = (known after apply) + max_delay = 0 + name = \"GH CPU greater than 90%\" + program_text = <<~EOT from signalfx.detectors.against_recent import against_recent A = data('cpu.utilization').publish(label='A') detect(when(A > threshold(90))).publish('CPU utilization is greater than 90%') EOT + show_data_markers = true + time_range = 3600 + url = (known after apply) + rule { + detect_label = \"CPU utilization is greater than 90%\" + disabled = false + notifications = [ + \"VictorOps,ERI0R2GAIAA,GH_PRI\", ] + parameterized_body = <<~EOT {{#if anomalous}} Rule \"{{{ruleName}}}\" in detector \"{{{detectorName}}}\" triggered at {{timestamp}}. {{else}} Rule \"{{{ruleName}}}\" in detector \"{{{detectorName}}}\" cleared at {{timestamp}}. {{/if}} {{#if anomalous}} Triggering condition: {{{readableRule}}} {{/if}} {{#if anomalous}} Signal value: {{inputs.A.value}} {{else}} Current signal value: {{inputs.A.value}} {{/if}} {{#notEmpty dimensions}} Signal details: {{{dimensions}}} {{/notEmpty}} {{#if anomalous}} {{#if runbookUrl}} Runbook: {{{runbookUrl}}} {{/if}} {{#if tip}} Tip: {{{tip}}} {{/if}} {{/if}} EOT + parameterized_subject = \"{{ruleSeverity}} Alert: {{{ruleName}}} ({{{detectorName}}})\" + severity = \"Warning\" } } Plan: 1 to add, 0 to change, 0 to destroy. Do you want to perform these actions in workspace \"Workshop\"? Terraform will perform the actions described above. Only 'yes' will be accepted to approve. Enter a value: yes module.host.signalfx_detector.cpu_greater_90: Creating... module.host.signalfx_detector.cpu_greater_90: Creation complete after 2s [id=EWHU-YAAAAA] Apply complete! Resources: 1 added, 0 changed, 0 destroyed. You have now configured the Integrations between VictorOps and SignalFx so the final part of this module is to test the flow of alerts from SignalFx into VictorOps and see how you can manage the incident with both the VictorOps UI and Mobile App.","title":"2.4. SignalFx Detector"}]}