{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"SignalFx Infrastructure Monitoring is able to monitor today\u2019s elastic cloud-native environment in real-time. With SignalFx\u2019s patented SignalFlow streaming analytics technology, users get real-time visibility and analytics-driven alerting. SignalFx is the only infrastructure monitoring solution that can detect and alert on meaningful conditions within seconds \u2013 and let you automatically remediate issues before customers are ever affected. Act in Real-Time with High-Resolution Metrics \u00b6 High-resolution metrics drive real-time dashboards, alerts, and insights so you can act before infrastructure performance affects end-user experience Build interactive dashboards with up to one-second resolution to get real-time status of infrastructure Create prescriptive alerts on hosts metrics or on the performance metrics of an entire cluster Quickly troubleshoot a performance bottleneck and drive down MTTR Scale with Confidence Modernize your applications and adopt cloud-native infrastructure with confidence. SignalFx is built from the ground up to support hyper-scale requirements of containers, microservices, and serverless architectures Analyze performance across 100,000s of dynamic and ephemeral components, multiple deployment environments, application versions, billions of events Embrace infrastructure immutability. Deploy infrastructure and monitoring-as-code. Instantly start monitoring high-churn, ephemeral infrastructure components Drive closed-loop automation such as auto-scaling cloud environments to ensure a flawless end-user experience Continually Improve with High-Cardinality Analytics \u00b6 Leverage unique insights powered by high-cardinality analytics to optimize infrastructure, application performance and business outcomes Dig deep and examine every detail using granular analytics across tens of thousands of dimensions on metric time series Aggregate thousands of time series to get the high-fidelity view of the entire infrastructure stack using built-in aggregate functions Unlock the value of data science by leveraging SignalFlow Analytics, a data-flow-oriented programming language syntactically similar to python, to express complex data computations with a large library of built-in functions Let's get started!","title":"Overview"},{"location":"#act-in-real-time-with-high-resolution-metrics","text":"High-resolution metrics drive real-time dashboards, alerts, and insights so you can act before infrastructure performance affects end-user experience Build interactive dashboards with up to one-second resolution to get real-time status of infrastructure Create prescriptive alerts on hosts metrics or on the performance metrics of an entire cluster Quickly troubleshoot a performance bottleneck and drive down MTTR Scale with Confidence Modernize your applications and adopt cloud-native infrastructure with confidence. SignalFx is built from the ground up to support hyper-scale requirements of containers, microservices, and serverless architectures Analyze performance across 100,000s of dynamic and ephemeral components, multiple deployment environments, application versions, billions of events Embrace infrastructure immutability. Deploy infrastructure and monitoring-as-code. Instantly start monitoring high-churn, ephemeral infrastructure components Drive closed-loop automation such as auto-scaling cloud environments to ensure a flawless end-user experience","title":"Act in Real-Time with High-Resolution Metrics"},{"location":"#continually-improve-with-high-cardinality-analytics","text":"Leverage unique insights powered by high-cardinality analytics to optimize infrastructure, application performance and business outcomes Dig deep and examine every detail using granular analytics across tens of thousands of dimensions on metric time series Aggregate thousands of time series to get the high-fidelity view of the entire infrastructure stack using built-in aggregate functions Unlock the value of data science by leveraging SignalFlow Analytics, a data-flow-oriented programming language syntactically similar to python, to express complex data computations with a large library of built-in functions Let's get started!","title":"Continually Improve with High-Cardinality Analytics"},{"location":"module1/dashboards/","text":"Summary of this lab: \u00b6 Introduction to the SignalFx Dashboards and charts How to create Charts and Dashboards Step 1: Introduction to the SignalFx environment \u00b6 Logon to the SignalFx organization you have been invited to Hover over DASHBOARDS in the top menu, and then click on All Dashboards at the bottom You will see a number of prebuilt dashboards If you are getting metrics already through cloud API integration or the Smart Agent you will see relevant dashboards for the services you are getting metrics for in SignalFx. Among the dashboards there you will see a Dashboard group called Sample Data. This group exists by default in all SignalFx accounts. Let's take a closer look at it. In the All Dashboards window expand the Sample Data dashboard group by clicking on it, and then click on Intro to SignalFx dashboard You will see a selection of sample charts. To learn more about charts you can click on the Intro to SignalFx, Part 1, 2 and Part 3 dashboards and read the description of the charts and its metrics. Let's take a look at the Sample charts Click on the Sample charts dashboard name In the SAMPLE CHARTS dashboard you see a selection of charts that shows the different styles, colours and formats you can apply to the different visualisations available. Let's work on a specific chart. Click on the three dots (...) on the Latency histogram chart (circled in the screenshot above) and then on Open. You will see the plot options, current plot and signal (metric) for the Latency histogram chart. Click on the different chart type icons to explore each of the visualisations See how the chart changes. You can use different ways to visualise your metrics - you choose which chart type fits best for the visualisation you want to have. For more info on the different chart types see: Choosing a chart type Click on Line chart type and you will see the line plot. In the PLOT EDITOR tab under Signal you see the metric demo.trans.latency we are currently plotting. Step 2: How to create Charts and Dashboards \u00b6 Let's now create a new chart and save it in a new dashboard! Click on the plus icon and from the drop down, click on Chart You will now see a chart template like the following. Let's enter a metric to plot. We are going to use the same metric we saw in step 7, namely demo.trans.latency In the PLOT EDITOR tab under Signal enter demo.trans.latency You will instantly see a number of Line plots, like below. The number \"18 ts\" indicates that we are plotting 18 metric time series in the chart. Click on the DATA TABLE tab You see now 18 rows, each representing a metics time series with a number of columns. If you swipe over the plot horizontally you will see the metrics in these columns at different times. In the demo_datacenter column you see that there are two data centers, Paris and Tokyo, for which we are getting metrics. Let's now select the Paris datacenter to do some analytics - for that we will use a filter. Let's go back to the PLOT EDITOR tab Click on Add filter, wait until it automatically populates, choose demo_datacenter, and then Paris In the F(x) column, add the analytic function Percentile:Aggregation, and leave the value to 95 (click outside to confirm) For info on the Percentile function and the other functions see: Analytics reference Let's now compare with older metrics. Click on ... and then on Clone in the dropdown to clone that Signal You will see a new row identical to A, called B, both visible and plotted For the B Signal, In F(x) add the analytic function Timeshift and enter 7d (7 days = 1 week), and click outside to confirm Click on the cogwheel on the far right, and choose a color, say pink, from Plot Color, to change color for the plot of B Click on Close Click on the field next to Time and choose Past Day from the dropdown We now see datapoint for A for the last day (rolling) as a blue plot, and 7 days ago in pink Click on Area chart icon We now have a better view of our two plots Let's now plot the difference of all metric values for a day with 7 days between Click on Enter Formula then enter A-B (A minus B) and hide (deselect) all Signals using the eye, except C We now see only the difference of all metric values of A and B being plotted. We see that we have some negative values on the plot because a metric value of B has some times larger value than the metric value of A at that time. If you click on DATA TABLE you can swipe horizontally along the X axis to see the metric values at different times. Let's apply another function to get the values of C to positive values. By doing so we will the difference between the metric values for a period of 24 hours with 7 days between. This difference can be used to see an alarming trend if we consider last week to be a baseline (the bigger the number - the more we deviate from the baseline) - but mainly we do this for you to get a bit more training on using functions... In the PLOT EDITOR for C click on Add Analytics and choose Absolute Value You will see the C plot now having only positive values Let's now overlay metrics and events to our initial plot to see if there is any correlation with high latency To discover and add new metrics to the chart from the ones that are being sent to SignalFx already, click on Browse on the bottom of the screen Then, in the Metrics sidebar on the right, enter \"demo\" and click on the search icon to search. Observe that the Find Metrics option is pre selected The metrics search is showing 3 metrics with demo in the name Select demo.trans.count and click on the Add Plot green button Click on the blue eye icon next to C to hide that Signal, and on the greyed eye icon for Signal A to show it Filter the Paris datacenter (see step 12 above if you need help with this) and function percentile 95 (see step 13 above) and enter 1h in the Time frame for the entire chart We see that there is a correlation between latency and number of transactions! Hooray! Likewise we could check Find Events and find events like deployment events etc. to correlate with. Click on the icon to collapse the Metrics sidebar Let's take a look at SignalFlow - the analytics language of SignalFx that can be used to setup monitoring as code. Click on View SignalFlow You will see the SignalFlow code that composes the chart we were working on ...this is the analytics language of SignalFx. Between the many benefits it provides, It can be used to setup monitoring as code. In the next lab we will see it being used in action. For more info on SignalFlow see: https://docs.signalfx.com/en/latest/getting-started/concepts/analytics-signalflow.html#signalflow-analytics-language Click on View Builder to go back to the UI Signal builder Let's now save our chart. Click on Save as... and enter a name for your chart, use your initials like ' 's Latency Chart' and click OK In the next window... Find your email address in the list and select it, then click Ok You will immediately be transported to the dashboard created under your selected group (make sure the group name on the top left is your email) Last but not least, change the dashboard's name, by clicking the ... icon on the top right and selecting Dashboard Info Enter a new name for your dashboard and click on Done Congratulations! You have created your first chart and dashboard! Continue the workshop with Working with Detectors","title":"1. Working with Dashboards, Charts and Metrics"},{"location":"module1/dashboards/#summary-of-this-lab","text":"Introduction to the SignalFx Dashboards and charts How to create Charts and Dashboards","title":"Summary of this lab:"},{"location":"module1/dashboards/#step-1-introduction-to-the-signalfx-environment","text":"Logon to the SignalFx organization you have been invited to Hover over DASHBOARDS in the top menu, and then click on All Dashboards at the bottom You will see a number of prebuilt dashboards If you are getting metrics already through cloud API integration or the Smart Agent you will see relevant dashboards for the services you are getting metrics for in SignalFx. Among the dashboards there you will see a Dashboard group called Sample Data. This group exists by default in all SignalFx accounts. Let's take a closer look at it. In the All Dashboards window expand the Sample Data dashboard group by clicking on it, and then click on Intro to SignalFx dashboard You will see a selection of sample charts. To learn more about charts you can click on the Intro to SignalFx, Part 1, 2 and Part 3 dashboards and read the description of the charts and its metrics. Let's take a look at the Sample charts Click on the Sample charts dashboard name In the SAMPLE CHARTS dashboard you see a selection of charts that shows the different styles, colours and formats you can apply to the different visualisations available. Let's work on a specific chart. Click on the three dots (...) on the Latency histogram chart (circled in the screenshot above) and then on Open. You will see the plot options, current plot and signal (metric) for the Latency histogram chart. Click on the different chart type icons to explore each of the visualisations See how the chart changes. You can use different ways to visualise your metrics - you choose which chart type fits best for the visualisation you want to have. For more info on the different chart types see: Choosing a chart type Click on Line chart type and you will see the line plot. In the PLOT EDITOR tab under Signal you see the metric demo.trans.latency we are currently plotting.","title":"Step 1: Introduction to the SignalFx environment"},{"location":"module1/dashboards/#step-2-how-to-create-charts-and-dashboards","text":"Let's now create a new chart and save it in a new dashboard! Click on the plus icon and from the drop down, click on Chart You will now see a chart template like the following. Let's enter a metric to plot. We are going to use the same metric we saw in step 7, namely demo.trans.latency In the PLOT EDITOR tab under Signal enter demo.trans.latency You will instantly see a number of Line plots, like below. The number \"18 ts\" indicates that we are plotting 18 metric time series in the chart. Click on the DATA TABLE tab You see now 18 rows, each representing a metics time series with a number of columns. If you swipe over the plot horizontally you will see the metrics in these columns at different times. In the demo_datacenter column you see that there are two data centers, Paris and Tokyo, for which we are getting metrics. Let's now select the Paris datacenter to do some analytics - for that we will use a filter. Let's go back to the PLOT EDITOR tab Click on Add filter, wait until it automatically populates, choose demo_datacenter, and then Paris In the F(x) column, add the analytic function Percentile:Aggregation, and leave the value to 95 (click outside to confirm) For info on the Percentile function and the other functions see: Analytics reference Let's now compare with older metrics. Click on ... and then on Clone in the dropdown to clone that Signal You will see a new row identical to A, called B, both visible and plotted For the B Signal, In F(x) add the analytic function Timeshift and enter 7d (7 days = 1 week), and click outside to confirm Click on the cogwheel on the far right, and choose a color, say pink, from Plot Color, to change color for the plot of B Click on Close Click on the field next to Time and choose Past Day from the dropdown We now see datapoint for A for the last day (rolling) as a blue plot, and 7 days ago in pink Click on Area chart icon We now have a better view of our two plots Let's now plot the difference of all metric values for a day with 7 days between Click on Enter Formula then enter A-B (A minus B) and hide (deselect) all Signals using the eye, except C We now see only the difference of all metric values of A and B being plotted. We see that we have some negative values on the plot because a metric value of B has some times larger value than the metric value of A at that time. If you click on DATA TABLE you can swipe horizontally along the X axis to see the metric values at different times. Let's apply another function to get the values of C to positive values. By doing so we will the difference between the metric values for a period of 24 hours with 7 days between. This difference can be used to see an alarming trend if we consider last week to be a baseline (the bigger the number - the more we deviate from the baseline) - but mainly we do this for you to get a bit more training on using functions... In the PLOT EDITOR for C click on Add Analytics and choose Absolute Value You will see the C plot now having only positive values Let's now overlay metrics and events to our initial plot to see if there is any correlation with high latency To discover and add new metrics to the chart from the ones that are being sent to SignalFx already, click on Browse on the bottom of the screen Then, in the Metrics sidebar on the right, enter \"demo\" and click on the search icon to search. Observe that the Find Metrics option is pre selected The metrics search is showing 3 metrics with demo in the name Select demo.trans.count and click on the Add Plot green button Click on the blue eye icon next to C to hide that Signal, and on the greyed eye icon for Signal A to show it Filter the Paris datacenter (see step 12 above if you need help with this) and function percentile 95 (see step 13 above) and enter 1h in the Time frame for the entire chart We see that there is a correlation between latency and number of transactions! Hooray! Likewise we could check Find Events and find events like deployment events etc. to correlate with. Click on the icon to collapse the Metrics sidebar Let's take a look at SignalFlow - the analytics language of SignalFx that can be used to setup monitoring as code. Click on View SignalFlow You will see the SignalFlow code that composes the chart we were working on ...this is the analytics language of SignalFx. Between the many benefits it provides, It can be used to setup monitoring as code. In the next lab we will see it being used in action. For more info on SignalFlow see: https://docs.signalfx.com/en/latest/getting-started/concepts/analytics-signalflow.html#signalflow-analytics-language Click on View Builder to go back to the UI Signal builder Let's now save our chart. Click on Save as... and enter a name for your chart, use your initials like ' 's Latency Chart' and click OK In the next window... Find your email address in the list and select it, then click Ok You will immediately be transported to the dashboard created under your selected group (make sure the group name on the top left is your email) Last but not least, change the dashboard's name, by clicking the ... icon on the top right and selecting Dashboard Info Enter a new name for your dashboard and click on Done Congratulations! You have created your first chart and dashboard! Continue the workshop with Working with Detectors","title":"Step 2: How to create Charts and Dashboards"},{"location":"module1/detectors/","text":"Summary of this lab: \u00b6 Create a Detector from one of you charts 1. Create a Detector from one of your charts \u00b6 Logon to your account in SignalFx, and click on DASHBOARDS in the menu. In DASHBOARDS click on your dashboard group (the one with your email address) and then on the dashboard name where the chart you created in the previous lab resides. OR Search for your previously created dashboard's name, and click on that dashboard's name in the results. Once you see the chart... Click on the bell icon on your chart and on New Detector From Chart - ADD YOUR INITIALS TO THE NAME (see next step). We are going to create a new alert detector from the chart. IMPORTANT - In the window that opens, add your initials in front of the proposed text, and click on Create Alert Rule. It should be something like this: LI's Latency Chart Detector. In the detector window, inside Alert signal, the signal we will alert on is marked with a bell. The bell in the 'Alert on' column indicates which Signal is being used to generate the alert. Click on Proceed to Alert Condition. On Alert Condition, click on Static Threshold and then on Proceed to Alert Settings. In Alert Settings, enter the value \"290\" in the Threshold box and change Time on top right to past day. Once you set an alert condition, SignalFx shows how many alerts you would get based on the current settings, and in the timeframe set on the upper right corner - in this case, the past day. Immediately, the platform will start analysing the signals with the current settings, and perform something we call a Pre-flight Check, This enables me to test the alert conditions using the historical data in the platform, to ensure the settings are logical and will not inadvertently generate an alert storm, removing the guess work from configuring alerts in a simple but very powerful way, only available using SignalFx. I can see that based on my current settings, the amount of alerts I would\u2019ve received in 1 day would've been around 18. To read more about Detector Previews, please visit this link: https://docs.signalfx.com/en/latest/detect-alert/set-up-detectors.html#previewing-the-results-of-a-detector Click on Proceed to Alert Message In Severity choose Major Click on Proceed to Alert Recipients Click on Add Recipient and then on your email displayed as the first option That's the same as entering that email address OR you can enter another email address by clicking on E-mail... That's just one example of the many Notification Services SignalFx has available You can check this out by going to the INTEGRATIONS tab of the top menu, and see Notification Services Click on Proceed to Alert Activation In Activate...click on Activate Alert Rule If you want to get alerts quicker you can click back on Alert Settings and lower the value from 290 to say 280. If you change the Time to 1h you can see how many alerts you will be getting with the threshold you have chosen based on the metics from the last 1 hour. Hover over ALERTS in the top menu and then click on Detectors You will see you alert detector listed here. Congrats! You have created your first alert detector and activated it! Continue the workshop with Working with Muting Rules","title":"2. Working with Detectors"},{"location":"module1/detectors/#summary-of-this-lab","text":"Create a Detector from one of you charts","title":"Summary of this lab:"},{"location":"module1/detectors/#1-create-a-detector-from-one-of-your-charts","text":"Logon to your account in SignalFx, and click on DASHBOARDS in the menu. In DASHBOARDS click on your dashboard group (the one with your email address) and then on the dashboard name where the chart you created in the previous lab resides. OR Search for your previously created dashboard's name, and click on that dashboard's name in the results. Once you see the chart... Click on the bell icon on your chart and on New Detector From Chart - ADD YOUR INITIALS TO THE NAME (see next step). We are going to create a new alert detector from the chart. IMPORTANT - In the window that opens, add your initials in front of the proposed text, and click on Create Alert Rule. It should be something like this: LI's Latency Chart Detector. In the detector window, inside Alert signal, the signal we will alert on is marked with a bell. The bell in the 'Alert on' column indicates which Signal is being used to generate the alert. Click on Proceed to Alert Condition. On Alert Condition, click on Static Threshold and then on Proceed to Alert Settings. In Alert Settings, enter the value \"290\" in the Threshold box and change Time on top right to past day. Once you set an alert condition, SignalFx shows how many alerts you would get based on the current settings, and in the timeframe set on the upper right corner - in this case, the past day. Immediately, the platform will start analysing the signals with the current settings, and perform something we call a Pre-flight Check, This enables me to test the alert conditions using the historical data in the platform, to ensure the settings are logical and will not inadvertently generate an alert storm, removing the guess work from configuring alerts in a simple but very powerful way, only available using SignalFx. I can see that based on my current settings, the amount of alerts I would\u2019ve received in 1 day would've been around 18. To read more about Detector Previews, please visit this link: https://docs.signalfx.com/en/latest/detect-alert/set-up-detectors.html#previewing-the-results-of-a-detector Click on Proceed to Alert Message In Severity choose Major Click on Proceed to Alert Recipients Click on Add Recipient and then on your email displayed as the first option That's the same as entering that email address OR you can enter another email address by clicking on E-mail... That's just one example of the many Notification Services SignalFx has available You can check this out by going to the INTEGRATIONS tab of the top menu, and see Notification Services Click on Proceed to Alert Activation In Activate...click on Activate Alert Rule If you want to get alerts quicker you can click back on Alert Settings and lower the value from 290 to say 280. If you change the Time to 1h you can see how many alerts you will be getting with the threshold you have chosen based on the metics from the last 1 hour. Hover over ALERTS in the top menu and then click on Detectors You will see you alert detector listed here. Congrats! You have created your first alert detector and activated it! Continue the workshop with Working with Muting Rules","title":"1. Create a Detector from one of your charts"},{"location":"module1/k3s/","text":"Summary of this lab: \u00b6 Download the workshop and configure Kubernetes ( K3s ) environment. \u2028 Use the SignalFx Helm chart to install the Smart Agent in K3s. Explore Your cluster in the Kubernetes Navigator If you have been given access to the workshop instance on AWS Ec2, please follow instructions and go to step 2. 1. Let\u2019s bake some K8s \u00b6 Install Multipass for your OS - https://multipass.run/. On a Mac you can also install via brew e.g. brew cask install multipass Download the App Dev Workshop master zip file, unzip the file and change into the app-dev-workshop-master directory curl -LO https://github.com/signalfx/app-dev-workshop/archive/master.zip unzip master.zip cd app-dev-workshop-master Launch the Multipass instance which will run Kubernetes. Note: Use [YOUR-INITIALS]-k3s this is so the value of the instance hostname is unique e.g. rwc-k3s multipass launch --name [ YOUR-INITIALS ] -k3s --cloud-init cloud-init-k3s.yaml --cpus = 2 --mem = 2G Once the instance has been successfully created shell into it. multipass shell [ YOUR-INITIALS ] -k3s 2. I\u2019ve got the key, I\u2019ve got the secret! \u00b6 You will need to obtain your Access Token from the SignalFx UI once Kubernetes is running. You can find your Access Token by clicking on your profile icon on the top right of the SignalFx UI. Then select Organisation Settings \u2192 Access Tokens . Expand the Default token, then click on Show Token to expose your token. Later in the lab you can come back here and click the Copy button which will copy it to your clipboard so you can paste it when you need to provide an access token in the lab. You will also need to obtain the name of the Realm for your SignalFx account. Click on the profile icon again, but this time select 'My Profile'. The Ream can be found in the middle of the page within the Organizations section. In this example it is us1. Step 3: Take the Helm! \u00b6 Create the following variables to use in the proceeding helm install command: export ACCESS_TOKEN=<token from Step 2> export REALM=<realm from Step 2> export INITIALS=<your initials e.g. GH> export VERSION=<Smart Agent version e.g. 5.0.4> The latest version of the Smart Agent can be found on GitHub Install the agent using the SignalFx Helm chart. Firstly, add the SignalFx Helm chart repository to Helm. helm repo add signalfx https://dl.signalfx.com/helm-repo Ensure the latest state of the repository helm repo update Install the Smart Agent chart with the following configuration values for the chart. sed -i -e 's/\\[INITIALS\\]/'\"$INITIALS\"'/' workshop/k3s/values.yaml helm install --set signalFxAccessToken=$ACCESS_TOKEN --set clusterName=$INITIALS-SFX-WORKSHOP --set kubeletAPI.url=https://localhost:10250 --set signalFxRealm=$REALM --set agentVersion=$VERSION --set traceEndpointUrl=https://ingest.$REALM.signalfx.com/v2/trace --set gatherDockerMetrics=false signalfx-agent signalfx/signalfx-agent -f workshop/k3s/values.yaml You can monitor the progress of the deployment by running kubectl get pods which should typically report a new pod is up and running after about 30 seconds. Ensure the status is reported as Running before continuing. kubectl get pods NAME READY STATUS RESTARTS AGE signalfx-agent-66tvr 1 /1 Running 0 7s Ensure there are no errors by tailing the logs from the Smart Agent Pod. Output should look similar to the log output shown below. Use the label set by the helm install to tail logs (You will need to press Ctrl-C to exit). Or use the installed k9s terminal UI for bonus points! kubectl logs -l app = signalfx-agent -f time=\"2020-03-15T11:30:28Z\" level=info msg=\"Starting up agent version 5.0.0\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Watching for config file changes\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"New config loaded\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Using log level info\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Fetching host id dimensions\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Trying to get fully qualified hostname\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Using hostname PH-k3s\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Using host id dimensions map[host:PH-k3s kubernetes_node_uid:05ba9d7b-89d4-4c70-a3e9-4dc72923423a]\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Sending datapoints to https://ingest.us1.signalfx.com/v2/datapoint\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Sending events to https://ingest.us1.signalfx.com/v2/event\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Sending trace spans to https://ingest.us1.signalfx.com/v1/trace\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Setting cluster:SFX-WORKSHOP property on host:PH-k3s dimension\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=1 monitorType=cpu time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=2 monitorType=filesystems time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=3 monitorType=disk-io time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=4 monitorType=net-io time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=5 monitorType=load time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=6 monitorType=memory time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=7 monitorType=host-metadata time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=8 monitorType=processlist time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=9 monitorType=vmem time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=10 monitorType=kubelet-stats time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=11 monitorType=kubernetes-cluster time=\"2020-03-15T11:30:29Z\" level=info msg=\"Done configuring agent\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Serving internal metrics at localhost:8095\" I0315 11:30:29.922577 1 leaderelection.go:242] attempting to acquire leader lease default/signalfx-agent-leader... I0315 11:30:29.950448 1 leaderelection.go:252] successfully acquired lease default/signalfx-agent-leader time=\"2020-03-15T11:30:29Z\" level=info msg=\"K8s leader is now node ph-k3s\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Starting K8s API resource sync\" In the SignalFx UI, goto INFRASTRUCTURE \u2192 Kubernetes Navigator \u2192 Cluster Map and open the Kubernetes Navigator Cluster Map to ensure metrics are being sent. Validate that your cluster is discovered and shown (In a workshop you can see many more clusters) by finding your cluster by searching for [YOUR-INITIALS]-SFX-WORKSHOP : If there are many clusters you can use the dashboard filter to narrow down to your K8s cluster e.g. kubernetes_cluster: [YOUR-INITIALS]-SFX-WORKSHOP or do this by clicking on the blue cross after selecting your cluster with your mouse. To examine the health of your cluster, open the side bar by clicking on the button to open the Metrics side bar. Once it is open, you can use the slider on the side to explore the various charts relevant to your cluster/node: Cpu%, Mem%, Network in & out. Events and Container list. Once you are finished please proceed to Deploying NGINX in Kubernetes","title":"4. Running the Smart Agent in Kubernetes (K3s)"},{"location":"module1/k3s/#summary-of-this-lab","text":"Download the workshop and configure Kubernetes ( K3s ) environment. \u2028 Use the SignalFx Helm chart to install the Smart Agent in K3s. Explore Your cluster in the Kubernetes Navigator If you have been given access to the workshop instance on AWS Ec2, please follow instructions and go to step 2.","title":"Summary of this lab:"},{"location":"module1/k3s/#1-lets-bake-some-k8s","text":"Install Multipass for your OS - https://multipass.run/. On a Mac you can also install via brew e.g. brew cask install multipass Download the App Dev Workshop master zip file, unzip the file and change into the app-dev-workshop-master directory curl -LO https://github.com/signalfx/app-dev-workshop/archive/master.zip unzip master.zip cd app-dev-workshop-master Launch the Multipass instance which will run Kubernetes. Note: Use [YOUR-INITIALS]-k3s this is so the value of the instance hostname is unique e.g. rwc-k3s multipass launch --name [ YOUR-INITIALS ] -k3s --cloud-init cloud-init-k3s.yaml --cpus = 2 --mem = 2G Once the instance has been successfully created shell into it. multipass shell [ YOUR-INITIALS ] -k3s","title":"1. Let\u2019s bake some K8s"},{"location":"module1/k3s/#2-ive-got-the-key-ive-got-the-secret","text":"You will need to obtain your Access Token from the SignalFx UI once Kubernetes is running. You can find your Access Token by clicking on your profile icon on the top right of the SignalFx UI. Then select Organisation Settings \u2192 Access Tokens . Expand the Default token, then click on Show Token to expose your token. Later in the lab you can come back here and click the Copy button which will copy it to your clipboard so you can paste it when you need to provide an access token in the lab. You will also need to obtain the name of the Realm for your SignalFx account. Click on the profile icon again, but this time select 'My Profile'. The Ream can be found in the middle of the page within the Organizations section. In this example it is us1.","title":"2. I\u2019ve got the key, I\u2019ve got the secret!"},{"location":"module1/k3s/#step-3-take-the-helm","text":"Create the following variables to use in the proceeding helm install command: export ACCESS_TOKEN=<token from Step 2> export REALM=<realm from Step 2> export INITIALS=<your initials e.g. GH> export VERSION=<Smart Agent version e.g. 5.0.4> The latest version of the Smart Agent can be found on GitHub Install the agent using the SignalFx Helm chart. Firstly, add the SignalFx Helm chart repository to Helm. helm repo add signalfx https://dl.signalfx.com/helm-repo Ensure the latest state of the repository helm repo update Install the Smart Agent chart with the following configuration values for the chart. sed -i -e 's/\\[INITIALS\\]/'\"$INITIALS\"'/' workshop/k3s/values.yaml helm install --set signalFxAccessToken=$ACCESS_TOKEN --set clusterName=$INITIALS-SFX-WORKSHOP --set kubeletAPI.url=https://localhost:10250 --set signalFxRealm=$REALM --set agentVersion=$VERSION --set traceEndpointUrl=https://ingest.$REALM.signalfx.com/v2/trace --set gatherDockerMetrics=false signalfx-agent signalfx/signalfx-agent -f workshop/k3s/values.yaml You can monitor the progress of the deployment by running kubectl get pods which should typically report a new pod is up and running after about 30 seconds. Ensure the status is reported as Running before continuing. kubectl get pods NAME READY STATUS RESTARTS AGE signalfx-agent-66tvr 1 /1 Running 0 7s Ensure there are no errors by tailing the logs from the Smart Agent Pod. Output should look similar to the log output shown below. Use the label set by the helm install to tail logs (You will need to press Ctrl-C to exit). Or use the installed k9s terminal UI for bonus points! kubectl logs -l app = signalfx-agent -f time=\"2020-03-15T11:30:28Z\" level=info msg=\"Starting up agent version 5.0.0\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Watching for config file changes\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"New config loaded\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Using log level info\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Fetching host id dimensions\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Trying to get fully qualified hostname\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Using hostname PH-k3s\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Using host id dimensions map[host:PH-k3s kubernetes_node_uid:05ba9d7b-89d4-4c70-a3e9-4dc72923423a]\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Sending datapoints to https://ingest.us1.signalfx.com/v2/datapoint\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Sending events to https://ingest.us1.signalfx.com/v2/event\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Sending trace spans to https://ingest.us1.signalfx.com/v1/trace\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Setting cluster:SFX-WORKSHOP property on host:PH-k3s dimension\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=1 monitorType=cpu time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=2 monitorType=filesystems time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=3 monitorType=disk-io time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=4 monitorType=net-io time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=5 monitorType=load time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=6 monitorType=memory time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=7 monitorType=host-metadata time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=8 monitorType=processlist time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=9 monitorType=vmem time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=10 monitorType=kubelet-stats time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=11 monitorType=kubernetes-cluster time=\"2020-03-15T11:30:29Z\" level=info msg=\"Done configuring agent\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Serving internal metrics at localhost:8095\" I0315 11:30:29.922577 1 leaderelection.go:242] attempting to acquire leader lease default/signalfx-agent-leader... I0315 11:30:29.950448 1 leaderelection.go:252] successfully acquired lease default/signalfx-agent-leader time=\"2020-03-15T11:30:29Z\" level=info msg=\"K8s leader is now node ph-k3s\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Starting K8s API resource sync\" In the SignalFx UI, goto INFRASTRUCTURE \u2192 Kubernetes Navigator \u2192 Cluster Map and open the Kubernetes Navigator Cluster Map to ensure metrics are being sent. Validate that your cluster is discovered and shown (In a workshop you can see many more clusters) by finding your cluster by searching for [YOUR-INITIALS]-SFX-WORKSHOP : If there are many clusters you can use the dashboard filter to narrow down to your K8s cluster e.g. kubernetes_cluster: [YOUR-INITIALS]-SFX-WORKSHOP or do this by clicking on the blue cross after selecting your cluster with your mouse. To examine the health of your cluster, open the side bar by clicking on the button to open the Metrics side bar. Once it is open, you can use the slider on the side to explore the various charts relevant to your cluster/node: Cpu%, Mem%, Network in & out. Events and Container list. Once you are finished please proceed to Deploying NGINX in Kubernetes","title":"Step 3: Take the Helm!"},{"location":"module1/muting/","text":"Summary of this lab: \u00b6 Learn how to configure how to mute Alerts 1. Learn how to configure muting your alerts \u00b6 There are times when you, for a period of time, don't want to be disturbed by notifications for some non ## critical alerts. For that you can use muting rules in SignalFx. Let's create one! Hover over ALERTS in the menu and click on Detectors If you created an alert detector in \"Working with Detectors\" you can click on the three dots (...) on the far right and click on Create Muting Rule... In the Muting Rule window check Mute Indefinitely. This will mute the rule permanently, let's say for maintenance windows, until you come back here and uncheck this box. Click Next and in the new window read the muting rule setup Click on Mute Indefinitely to confirm. You won't be receiving any email notifications from you alert detector until you resume notifications again. To Resume notifications, hover over ALERTS in the top menu and click on Muting Rules. You will see the name of the detector you muted notifications for under Detector. Click on the thee dots (...) on the far right Click on Resume Notifications Click on Resume to confirm and resume notifications for this detector Congratulations! You have now resumed your alert notifications! Continue the workshop with Running the SmartAgent in Kubernetes","title":"3. Working with Muting Rules"},{"location":"module1/muting/#summary-of-this-lab","text":"Learn how to configure how to mute Alerts","title":"Summary of this lab:"},{"location":"module1/muting/#1-learn-how-to-configure-muting-your-alerts","text":"There are times when you, for a period of time, don't want to be disturbed by notifications for some non ## critical alerts. For that you can use muting rules in SignalFx. Let's create one! Hover over ALERTS in the menu and click on Detectors If you created an alert detector in \"Working with Detectors\" you can click on the three dots (...) on the far right and click on Create Muting Rule... In the Muting Rule window check Mute Indefinitely. This will mute the rule permanently, let's say for maintenance windows, until you come back here and uncheck this box. Click Next and in the new window read the muting rule setup Click on Mute Indefinitely to confirm. You won't be receiving any email notifications from you alert detector until you resume notifications again. To Resume notifications, hover over ALERTS in the top menu and click on Muting Rules. You will see the name of the detector you muted notifications for under Detector. Click on the thee dots (...) on the far right Click on Resume Notifications Click on Resume to confirm and resume notifications for this detector Congratulations! You have now resumed your alert notifications! Continue the workshop with Running the SmartAgent in Kubernetes","title":"1. Learn how to configure muting your alerts"},{"location":"module1/nginx/","text":"Summary of this lab: \u00b6 Deploy a NGINX ReplicaSet into your K3s cluster and confirm the auto discovery of your NGINX deployment. Run a benchmark test to create metrics and confirm them streaming into SignalFX! 1. Start your NGINX! \u00b6 Still within the k3s shell session, change into the nginx directory cd ~/workshop/k3s/nginx Create the NGINX configmap using the nginx.conf file kubectl create configmap nginxconfig --from-file = nginx.conf Verify the number of pods running in the SignalFx UI by selecting the WORKLOADS tab. This should give you an overview of the workloads on your cluster. Note the single agent container running per node among the default Kubernetes pods. This single container will monitor all the pods and services being deployed on this node! Now switch back to the default cluster node view by selecting the MAP tab and select your cluster again. Continue the workshop in your shell with the next steps Create the NGINX deployment kubectl create -f nginx-deployment.yaml Validate the deployment has been successful and that the NGINX pods are running. If you have the SignalFx UI open you should see new Pods being started and containers being deployed. It should only take around 20 seconds for the pods to transition into a Running state. In the SignalFx UI you should have a cluster that looks like below: If you select the WORKLOADS tab again you should now see that there is a new replica set and a deployment added for the NGINX deployment: Let's validate this in your shell as well, before creating load on you system: kubectl get pods NAME READY STATUS RESTARTS AGE signalfx-agent-n7nz2 1 /1 Running 0 11m nginx-deployment-f96cf6966-jhmjp 1 /1 Running 0 21s nginx-deployment-f96cf6966-459vf 1 /1 Running 0 21s nginx-deployment-f96cf6966-vrnfc 1 /1 Running 0 21s nginx-deployment-f96cf6966-7z4tm 1 /1 Running 0 21s Next we need to expose port 80 (HTTP) kubectl create service nodeport nginx --tcp = 80 :80 service/nginx created Run kubectl get svc then make a note of the IP address allocated to the NGINX service. kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.96.0.1 <none> 443/TCP 9m3s nginx NodePort 10.110.36.62 <none> 80:30995/TCP 8s Using the NGINX IP address reported from Step #6 above, use Apache Benchmark ( ab ) to create some traffic to light up your SignalFx NGINX dashboard. Run this a couple of times to generate some metrics! Input: ab -n1000 -c20 http://<INSERT_NGINX_IP_ADDRESS>/ Output: ``` This is ApacheBench, Version 2.3 <$Revision: 1826891 $> Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking localhost (be patient) Completed 100 requests ... Completed 1000 requests Finished 1000 requests Server Software: nginx/1.17.5 Server Hostname: localhost Server Port: 30995... ``` Validate you are seeing metrics in the UI by going to Dashboards \u2192 NGINX \u2192 NGINX Servers Tip: you can again apply the filter kubernetes_cluster: [YOUR-INITIALS]-SFX-WORKSHOP to focus on only your containers. 2. Cleaning up \u00b6 Once you have finished with this workshop exit from the Multipass instance you are in and get back to your system command prompt and enter the following to delete the Multipass instance (replace [YOUR-INITIALS] with the ones you used in Step #1.3 ): multipass delete --purge [YOUR-INITIALS]-k3s If you are using a workshop instance on EC2 please ignore the previous instruction. Once you are finished please proceed to Monitoring as Code with Detectors","title":"5. Deploying NGINX in K3s"},{"location":"module1/nginx/#summary-of-this-lab","text":"Deploy a NGINX ReplicaSet into your K3s cluster and confirm the auto discovery of your NGINX deployment. Run a benchmark test to create metrics and confirm them streaming into SignalFX!","title":"Summary of this lab:"},{"location":"module1/nginx/#1-start-your-nginx","text":"Still within the k3s shell session, change into the nginx directory cd ~/workshop/k3s/nginx Create the NGINX configmap using the nginx.conf file kubectl create configmap nginxconfig --from-file = nginx.conf Verify the number of pods running in the SignalFx UI by selecting the WORKLOADS tab. This should give you an overview of the workloads on your cluster. Note the single agent container running per node among the default Kubernetes pods. This single container will monitor all the pods and services being deployed on this node! Now switch back to the default cluster node view by selecting the MAP tab and select your cluster again. Continue the workshop in your shell with the next steps Create the NGINX deployment kubectl create -f nginx-deployment.yaml Validate the deployment has been successful and that the NGINX pods are running. If you have the SignalFx UI open you should see new Pods being started and containers being deployed. It should only take around 20 seconds for the pods to transition into a Running state. In the SignalFx UI you should have a cluster that looks like below: If you select the WORKLOADS tab again you should now see that there is a new replica set and a deployment added for the NGINX deployment: Let's validate this in your shell as well, before creating load on you system: kubectl get pods NAME READY STATUS RESTARTS AGE signalfx-agent-n7nz2 1 /1 Running 0 11m nginx-deployment-f96cf6966-jhmjp 1 /1 Running 0 21s nginx-deployment-f96cf6966-459vf 1 /1 Running 0 21s nginx-deployment-f96cf6966-vrnfc 1 /1 Running 0 21s nginx-deployment-f96cf6966-7z4tm 1 /1 Running 0 21s Next we need to expose port 80 (HTTP) kubectl create service nodeport nginx --tcp = 80 :80 service/nginx created Run kubectl get svc then make a note of the IP address allocated to the NGINX service. kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.96.0.1 <none> 443/TCP 9m3s nginx NodePort 10.110.36.62 <none> 80:30995/TCP 8s Using the NGINX IP address reported from Step #6 above, use Apache Benchmark ( ab ) to create some traffic to light up your SignalFx NGINX dashboard. Run this a couple of times to generate some metrics! Input: ab -n1000 -c20 http://<INSERT_NGINX_IP_ADDRESS>/ Output: ``` This is ApacheBench, Version 2.3 <$Revision: 1826891 $> Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking localhost (be patient) Completed 100 requests ... Completed 1000 requests Finished 1000 requests Server Software: nginx/1.17.5 Server Hostname: localhost Server Port: 30995... ``` Validate you are seeing metrics in the UI by going to Dashboards \u2192 NGINX \u2192 NGINX Servers Tip: you can again apply the filter kubernetes_cluster: [YOUR-INITIALS]-SFX-WORKSHOP to focus on only your containers.","title":"1. Start your NGINX!"},{"location":"module1/nginx/#2-cleaning-up","text":"Once you have finished with this workshop exit from the Multipass instance you are in and get back to your system command prompt and enter the following to delete the Multipass instance (replace [YOUR-INITIALS] with the ones you used in Step #1.3 ): multipass delete --purge [YOUR-INITIALS]-k3s If you are using a workshop instance on EC2 please ignore the previous instruction. Once you are finished please proceed to Monitoring as Code with Detectors","title":"2. Cleaning up"},{"location":"module1/terraform/","text":"Summary of this lab \u00b6 Install Terraform and initialise the SignalFx Provider. Run Terraform to create SignalFx detectors and dashboards from code using our Terraform provider. See how Terraform can also delete detectors and dashboards. (Optional) Upgrade the SignalFx Provider. 1. Initial setup \u00b6 Download and install Terraform for your platform - https://www.terraform.io/downloads.html (min. requirement v. 0.12.18) Download the SignalFx Jumpstart Terraform master zip file, unzip the file and change into the signalfx-jumpstart-master directory curl -LO https://github.com/signalfx/signalfx-jumpstart/archive/master.zip unzip master.zip cd signalfx-jumpstart-master Initialise Terraform. Note: You will need to run this command each time a new version of the Terraform Provider is released. You can track the releases on GitHub . terraform init -upgrade Create a new workspace (replace WORKSPACE_NAME with what you want your workspace to be called) terraform workspace new WORKSPACE_NAME 2. Plan and apply the Terraform \u00b6 Review the execution plan. Replace [YOUR-INITIALS] e.g. -var=\u201dsfx_prefix=RWC\u201d terraform plan -var = \"access_token=abc123\" -var = \"realm=us1\" -var = \"sfx_prefix=[YOUR-INITIALS]\" Where access_token is the SignalFx Access Token and realm is either eu0 , us1 or ap0 If the plan executes successfully, we can go ahead and apply terraform apply -var = \"access_token=abc123\" -var = \"realm=us1\" -var = \"sfx_prefix=[YOUR-INITIALS]\" To deploy only a subset (by module see main.tf ) e.g. terraform apply -var = \"access_token=abc123\" -var = \"realm=us1\" -var = \"sfx_prefix=[YOUR-INITIALS]\" -target = module.aws terraform apply -var = \"access_token=abc123\" -var = \"realm=us1\" -var = \"sfx_prefix=[YOUR-INITIALS]\" - target = module.usage_dashboard terraform apply -var = \"access_token=abc123\" -var = \"realm=us1\" -var = \"sfx_prefix=[YOUR-INITIALS]\" -target = module.gcp Validate that the detectors were created, under the Alerts tab \u2192 Detectors , you should see a list of new detectors with the a prefix of your initials: 3. Destroy all your hard work \u00b6 You will first need to ensure you are in the correct workspace (replace WORKSPACE_NAME with the name created in the initial setup) terraform workspace select WORKSPACE_NAME Destroy all Detectors and Dashboards that were previously applied. NOTE: The var=\u201dsfx_prefix=[YOUR-INITIALS]\u201d is not required! terraform destroy -var = \"access_token=abc123\" -var = \"realm=us1\"","title":"6. Monitoring as Code with Detectors & Dashboards"},{"location":"module1/terraform/#summary-of-this-lab","text":"Install Terraform and initialise the SignalFx Provider. Run Terraform to create SignalFx detectors and dashboards from code using our Terraform provider. See how Terraform can also delete detectors and dashboards. (Optional) Upgrade the SignalFx Provider.","title":"Summary of this lab"},{"location":"module1/terraform/#1-initial-setup","text":"Download and install Terraform for your platform - https://www.terraform.io/downloads.html (min. requirement v. 0.12.18) Download the SignalFx Jumpstart Terraform master zip file, unzip the file and change into the signalfx-jumpstart-master directory curl -LO https://github.com/signalfx/signalfx-jumpstart/archive/master.zip unzip master.zip cd signalfx-jumpstart-master Initialise Terraform. Note: You will need to run this command each time a new version of the Terraform Provider is released. You can track the releases on GitHub . terraform init -upgrade Create a new workspace (replace WORKSPACE_NAME with what you want your workspace to be called) terraform workspace new WORKSPACE_NAME","title":"1. Initial setup"},{"location":"module1/terraform/#2-plan-and-apply-the-terraform","text":"Review the execution plan. Replace [YOUR-INITIALS] e.g. -var=\u201dsfx_prefix=RWC\u201d terraform plan -var = \"access_token=abc123\" -var = \"realm=us1\" -var = \"sfx_prefix=[YOUR-INITIALS]\" Where access_token is the SignalFx Access Token and realm is either eu0 , us1 or ap0 If the plan executes successfully, we can go ahead and apply terraform apply -var = \"access_token=abc123\" -var = \"realm=us1\" -var = \"sfx_prefix=[YOUR-INITIALS]\" To deploy only a subset (by module see main.tf ) e.g. terraform apply -var = \"access_token=abc123\" -var = \"realm=us1\" -var = \"sfx_prefix=[YOUR-INITIALS]\" -target = module.aws terraform apply -var = \"access_token=abc123\" -var = \"realm=us1\" -var = \"sfx_prefix=[YOUR-INITIALS]\" - target = module.usage_dashboard terraform apply -var = \"access_token=abc123\" -var = \"realm=us1\" -var = \"sfx_prefix=[YOUR-INITIALS]\" -target = module.gcp Validate that the detectors were created, under the Alerts tab \u2192 Detectors , you should see a list of new detectors with the a prefix of your initials:","title":"2. Plan and apply the Terraform"},{"location":"module1/terraform/#3-destroy-all-your-hard-work","text":"You will first need to ensure you are in the correct workspace (replace WORKSPACE_NAME with the name created in the initial setup) terraform workspace select WORKSPACE_NAME Destroy all Detectors and Dashboards that were previously applied. NOTE: The var=\u201dsfx_prefix=[YOUR-INITIALS]\u201d is not required! terraform destroy -var = \"access_token=abc123\" -var = \"realm=us1\"","title":"3. Destroy all your hard work"},{"location":"module2/hotrod/","text":"Before We Start - SignalFx Org Access \u00b6 An organisation needs to be pre-provisioned as a \u00b5APM entitlement is required for the purposes of this module. Please contact someone from SignalFx to get a trial instance with \u00b5APM enabled if you don\u2019t have one already. To check if you have an organisation with \u00b5APM enabled, just login to SignalFx and check that you have the \u00b5APM tab on the top navbar next to Dashboards. 1. Create an instance running Kubernetes \u00b6 This is already documented in 1.4 Running the SmartAgent in Kubernetes using K3s . 2. Deploy the Hotrod application into K3s \u00b6 To deploy the Hotrod application into K3s apply the deployment kubectl apply -f workshop/apm/hotrod/k8s/deployment.yaml deployment.apps/hotrod created service/hotrod created Make sure the application is now running ``` bash tab=\"Input\" kubectl get pods ``` text tab=\"Output\" NAME READY STATUS RESTARTS AGE signalfx-agent-mmzxk 1/1 Running 0 110s hotrod-7cc9fc85b7-n765r 1/1 Running 0 41s To find the IP address assigned to the Hotrod service kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.43.0.1 <none> 443/TCP 25m hotrod ClusterIP 10.43.124.159 <none> 8080/TCP 94s Make note of the ClusterIP address associated with Hotrod 3. Generate some traffic to the application using Apache Benchmark \u00b6 ab -n10 -c10 \"http://[CLUSTERIP]:8080/dispatch?customer=392&nonse=0.17041229755366172\" Create some errors with an invalid customer number ab -n10 -c10 \"http://[CLUSTERIP]:8080/dispatch?customer=391&nonse=0.17041229755366172\"","title":"1. \u00b5APM: Hotrod in K3s"},{"location":"module2/hotrod/#before-we-start-signalfx-org-access","text":"An organisation needs to be pre-provisioned as a \u00b5APM entitlement is required for the purposes of this module. Please contact someone from SignalFx to get a trial instance with \u00b5APM enabled if you don\u2019t have one already. To check if you have an organisation with \u00b5APM enabled, just login to SignalFx and check that you have the \u00b5APM tab on the top navbar next to Dashboards.","title":"Before We Start - SignalFx Org Access"},{"location":"module2/hotrod/#1-create-an-instance-running-kubernetes","text":"This is already documented in 1.4 Running the SmartAgent in Kubernetes using K3s .","title":"1. Create an instance running Kubernetes"},{"location":"module2/hotrod/#2-deploy-the-hotrod-application-into-k3s","text":"To deploy the Hotrod application into K3s apply the deployment kubectl apply -f workshop/apm/hotrod/k8s/deployment.yaml deployment.apps/hotrod created service/hotrod created Make sure the application is now running ``` bash tab=\"Input\" kubectl get pods ``` text tab=\"Output\" NAME READY STATUS RESTARTS AGE signalfx-agent-mmzxk 1/1 Running 0 110s hotrod-7cc9fc85b7-n765r 1/1 Running 0 41s To find the IP address assigned to the Hotrod service kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.43.0.1 <none> 443/TCP 25m hotrod ClusterIP 10.43.124.159 <none> 8080/TCP 94s Make note of the ClusterIP address associated with Hotrod","title":"2. Deploy the Hotrod application into K3s"},{"location":"module2/hotrod/#3-generate-some-traffic-to-the-application-using-apache-benchmark","text":"ab -n10 -c10 \"http://[CLUSTERIP]:8080/dispatch?customer=392&nonse=0.17041229755366172\" Create some errors with an invalid customer number ab -n10 -c10 \"http://[CLUSTERIP]:8080/dispatch?customer=391&nonse=0.17041229755366172\"","title":"3. Generate some traffic to the application using Apache Benchmark"},{"location":"module2/sockshop/","text":"Before We Start - SignalFx Org Access \u00b6 An organisation needs to be pre-provisioned as a \u00b5APM entitlement is required for the purposes of this module. Please contact someone from SignalFx to get a trial instance with \u00b5APM enabled if you don\u2019t have one already. To check if you have an organisation with \u00b5APM enabled, just login to SignalFx and check that you have the \u00b5APM tab on the top navbar next to Dashboards. 1. Deploy the Sock Shop application into K3s \u00b6 To deploy the Sock Shop application into K3s apply the deployment cd apm/sockshop kubectl create ns sock-shop kubectl apply -f k8s/complete-demo.yaml namespace/sock-shop created deployment.apps/carts-db created service/carts-db created deployment.apps/carts created service/carts created deployment.apps/catalogue-db created service/catalogue-db created deployment.apps/catalogue created service/catalogue created deployment.apps/front-end created service/front-end created deployment.apps/orders-db created service/orders-db created deployment.apps/orders created service/orders created deployment.apps/payment created service/payment created deployment.apps/queue-master created service/queue-master created deployment.apps/rabbitmq created service/rabbitmq created deployment.apps/shipping created service/shipping created deployment.apps/user-db created service/user-db created deployment.apps/user created service/user created 2. Take Sock Shop for a test drive \u00b6 Sock Shop should be running in your cluster and exposes services via cluster IP and port. Obtain the ip address for the front-end service. SOCKS_ENDPOINT = $( kubectl get svc front-end -n sock-shop -o jsonpath = '{.spec.clusterIP}:{.spec.ports[0].port}' ) Then send a curl $SOCKS_ENDPOINT and it should respond with HTML markup: ... </ script > </ body > </ html > 3. Apply load on Sock Shop \u00b6 Use a load test for sock shop. kubectl run --generator = run-pod/v1 load-test --rm -i --tty --image weaveworksdemos/load-test -- -d 5 -h $SOCKS_ENDPOINT -c 15 -r 1000 The parameter -c controls the amount of concurrent clients and -r the amount of requests sent. To apply continuous load just set -r to some higher number. 4. Visualize and analyze trace data \u00b6 Navigate to \u00b5APM ( not \u00b5APM PG) and select Monitoring, then ensure you have selected your environment from the dropdown at the top, you should see something like this: Explore the User Interface: Review an automatically generated Service Dashboard. How do you correlate Service performance with Infrastructure? Troubleshoot a service. Let's stress the sock shop a bit. Increase the amount of clients running for the load test to something ludicrous (1000+ seems to do the trick). What happens with the services? Troubleshoot a service with a higher error rate. Also review the service dependencies. Look at individual traces and span performance.","title":"2. \u00b5APM: Sock Shop in K3s"},{"location":"module2/sockshop/#before-we-start-signalfx-org-access","text":"An organisation needs to be pre-provisioned as a \u00b5APM entitlement is required for the purposes of this module. Please contact someone from SignalFx to get a trial instance with \u00b5APM enabled if you don\u2019t have one already. To check if you have an organisation with \u00b5APM enabled, just login to SignalFx and check that you have the \u00b5APM tab on the top navbar next to Dashboards.","title":"Before We Start - SignalFx Org Access"},{"location":"module2/sockshop/#1-deploy-the-sock-shop-application-into-k3s","text":"To deploy the Sock Shop application into K3s apply the deployment cd apm/sockshop kubectl create ns sock-shop kubectl apply -f k8s/complete-demo.yaml namespace/sock-shop created deployment.apps/carts-db created service/carts-db created deployment.apps/carts created service/carts created deployment.apps/catalogue-db created service/catalogue-db created deployment.apps/catalogue created service/catalogue created deployment.apps/front-end created service/front-end created deployment.apps/orders-db created service/orders-db created deployment.apps/orders created service/orders created deployment.apps/payment created service/payment created deployment.apps/queue-master created service/queue-master created deployment.apps/rabbitmq created service/rabbitmq created deployment.apps/shipping created service/shipping created deployment.apps/user-db created service/user-db created deployment.apps/user created service/user created","title":"1. Deploy the Sock Shop application into K3s"},{"location":"module2/sockshop/#2-take-sock-shop-for-a-test-drive","text":"Sock Shop should be running in your cluster and exposes services via cluster IP and port. Obtain the ip address for the front-end service. SOCKS_ENDPOINT = $( kubectl get svc front-end -n sock-shop -o jsonpath = '{.spec.clusterIP}:{.spec.ports[0].port}' ) Then send a curl $SOCKS_ENDPOINT and it should respond with HTML markup: ... </ script > </ body > </ html >","title":"2. Take Sock Shop for a test drive"},{"location":"module2/sockshop/#3-apply-load-on-sock-shop","text":"Use a load test for sock shop. kubectl run --generator = run-pod/v1 load-test --rm -i --tty --image weaveworksdemos/load-test -- -d 5 -h $SOCKS_ENDPOINT -c 15 -r 1000 The parameter -c controls the amount of concurrent clients and -r the amount of requests sent. To apply continuous load just set -r to some higher number.","title":"3. Apply load on Sock Shop"},{"location":"module2/sockshop/#4-visualize-and-analyze-trace-data","text":"Navigate to \u00b5APM ( not \u00b5APM PG) and select Monitoring, then ensure you have selected your environment from the dropdown at the top, you should see something like this: Explore the User Interface: Review an automatically generated Service Dashboard. How do you correlate Service performance with Infrastructure? Troubleshoot a service. Let's stress the sock shop a bit. Increase the amount of clients running for the load test to something ludicrous (1000+ seems to do the trick). What happens with the services? Troubleshoot a service with a higher error rate. Also review the service dependencies. Look at individual traces and span performance.","title":"4. Visualize and analyze trace data"}]}