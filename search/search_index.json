{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"","title":"<b>Home</b>"},{"location":"introduction/","text":"SignalFx enables real-time cloud monitoring and observability for infrastructure, microservices, and applications by collecting and analyzing metrics and traces across every component in your cloud environment. Built on a massively-scalable streaming architecture, SignalFx applies advanced analytics and data science-directed troubleshooting to let operators find the root cause of issues in seconds. SignalFx was acquired by Splunk in October 2019. With Splunk\u2019s market-leading log analytics technology, SignalFx and Splunk provide the industry\u2019s first enterprise-grade, end-to-end observability platform. Act in Real-Time with High-Resolution Metrics \u00b6 High-resolution metrics drive real-time dashboards, alerts, and insights so you can act before infrastructure performance affects end-user experience Build interactive dashboards with up to one-second resolution to get real-time status of infrastructure Create prescriptive alerts on hosts metrics or on the performance metrics of an entire cluster Quickly troubleshoot a performance bottleneck and drive down MTTR Scale with Confidence \u00b6 Modernize your applications and adopt cloud-native infrastructure with confidence. SignalFx is built from the ground up to support hyper-scale requirements of containers, microservices, and serverless architectures Analyze performance across 100,000s of dynamic and ephemeral components, multiple deployment environments, application versions, billions of events Embrace infrastructure immutability. Deploy infrastructure and monitoring-as-code. Instantly start monitoring high-churn, ephemeral infrastructure components Drive closed-loop automation such as auto-scaling cloud environments to ensure a flawless end-user experience Continually Improve with High-Cardinality Analytics \u00b6 Leverage unique insights powered by high-cardinality analytics to optimize infrastructure, application performance and business outcomes Dig deep and examine every detail using granular analytics across tens of thousands of dimensions on metric time series Aggregate thousands of time series to get the high-fidelity view of the entire infrastructure stack using built-in aggregate functions Unlock the value of data science by leveraging SignalFlow Analytics, a data-flow-oriented programming language syntactically similar to python, to express complex data computations with a large library of built-in functions Analyze Every Transaction, Focus on What Matters Most \u00b6 SignalFx Smart Gateway observes every transaction across distributed services and uses machine learning algorithms to define a true anomaly. Never miss an anomaly \u2013 Deliver flawless end-user experience by catching performance outliers across all the microservices; Cut through the noise \u2013 Using statistical computations, Smart Gateway cuts through the noise and enables you to focus on the traces that matter; Capture one-in-a-thousand issues \u2013 Traditional APM tools use random and probabilistic sampling resulting in missing important diagnostic data when it is needed the most \u2013 during troubleshooting. The SignalFx Smart Gateway intelligently captures every edge case, such as p(99) outliers, so you can confidently address intermittent issues. Quickly Isolate the Root Cause \u00b6 SignalFx provides a unified, single-pane-of-glass view of infrastructure and applications monitoring \u2013 all contextual and fully correlated. Narrow down the root cause within seconds to infrastructure, PaaS or application code; Correlate how infrastructure performance is impacting application performance; Navigate to the application code-level insights within seconds using contextual alerts pointing to the relevant traces; Reduce MTTR and enable DevOps practices by having a single source of truth across infrastructure and deployed microservices. Use the Next link in the footer below to move to the first module and start the workshop","title":"<b>Introduction</b>"},{"location":"introduction/#act-in-real-time-with-high-resolution-metrics","text":"High-resolution metrics drive real-time dashboards, alerts, and insights so you can act before infrastructure performance affects end-user experience Build interactive dashboards with up to one-second resolution to get real-time status of infrastructure Create prescriptive alerts on hosts metrics or on the performance metrics of an entire cluster Quickly troubleshoot a performance bottleneck and drive down MTTR","title":"Act in Real-Time with High-Resolution Metrics"},{"location":"introduction/#scale-with-confidence","text":"Modernize your applications and adopt cloud-native infrastructure with confidence. SignalFx is built from the ground up to support hyper-scale requirements of containers, microservices, and serverless architectures Analyze performance across 100,000s of dynamic and ephemeral components, multiple deployment environments, application versions, billions of events Embrace infrastructure immutability. Deploy infrastructure and monitoring-as-code. Instantly start monitoring high-churn, ephemeral infrastructure components Drive closed-loop automation such as auto-scaling cloud environments to ensure a flawless end-user experience","title":"Scale with Confidence"},{"location":"introduction/#continually-improve-with-high-cardinality-analytics","text":"Leverage unique insights powered by high-cardinality analytics to optimize infrastructure, application performance and business outcomes Dig deep and examine every detail using granular analytics across tens of thousands of dimensions on metric time series Aggregate thousands of time series to get the high-fidelity view of the entire infrastructure stack using built-in aggregate functions Unlock the value of data science by leveraging SignalFlow Analytics, a data-flow-oriented programming language syntactically similar to python, to express complex data computations with a large library of built-in functions","title":"Continually Improve with High-Cardinality Analytics"},{"location":"introduction/#analyze-every-transaction-focus-on-what-matters-most","text":"SignalFx Smart Gateway observes every transaction across distributed services and uses machine learning algorithms to define a true anomaly. Never miss an anomaly \u2013 Deliver flawless end-user experience by catching performance outliers across all the microservices; Cut through the noise \u2013 Using statistical computations, Smart Gateway cuts through the noise and enables you to focus on the traces that matter; Capture one-in-a-thousand issues \u2013 Traditional APM tools use random and probabilistic sampling resulting in missing important diagnostic data when it is needed the most \u2013 during troubleshooting. The SignalFx Smart Gateway intelligently captures every edge case, such as p(99) outliers, so you can confidently address intermittent issues.","title":"Analyze Every Transaction, Focus on What Matters Most"},{"location":"introduction/#quickly-isolate-the-root-cause","text":"SignalFx provides a unified, single-pane-of-glass view of infrastructure and applications monitoring \u2013 all contextual and fully correlated. Narrow down the root cause within seconds to infrastructure, PaaS or application code; Correlate how infrastructure performance is impacting application performance; Navigate to the application code-level insights within seconds using contextual alerts pointing to the relevant traces; Reduce MTTR and enable DevOps practices by having a single source of truth across infrastructure and deployed microservices. Use the Next link in the footer below to move to the first module and start the workshop","title":"Quickly Isolate the Root Cause"},{"location":"archive/apm-initial/","text":"Before We Start - SignalFx Org Access \u00b6 An organisation needs to be pre-provisioned as a \u00b5APM entitlement is required for the purposes of this module. Please contact someone from SignalFx to get a trial instance with \u00b5APM enabled if you don\u2019t have one already. To check if you have an organisation with \u00b5APM enabled, just login to SignalFx and check that you have the \u00b5APM tab on the top navbar next to Dashboards. Step 1: Create an instance with Multipass and deploy the SmartGateway \u00b6 If you have executed Module 1 of this workshop, then skip the multipass installation and zip download as you already have this, and go straight to Step#1.5 Install Multipass for your OS - https://multipass.run/. On a Mac you can also install via brew, e.g. brew cask install multipass Obtain your Access Token (and take note of your Realm from under My Profile) in the SignalFx UI Download the App Dev Workshop master zip file and unzip it curl -LO https://github.com/signalfx/app-dev-workshop/archive/master.zip unzip master.zip Change into the app-dev-workshop-master directory cd app-dev-workshop-master Edit cloud-init/smart-gateway.yaml and on line #30 replace ACCESS_TOKEN with your SignalFx token, REALM with the SignalFx realm you are running in, HOSTNAME with YOUR_INITIALS-sg and CLUSTER_NAME with YOUR_INITIALS-sg-cluster. NOTE: The hostname defined here will be the same hostname that we will use to launch the instance in Step #1.7 #cloud-config package_update : true package_upgrade : true write_files : - content : | [Unit] Description=SignalFx Smart Gateway After=network.target [Service] ExecStart=/usr/local/bin/smart-gateway --configfile /var/lib/gateway/etc/gateway.conf KillMode=mixed Restart=on-failure Type=simple User=root Group=root [Install] WantedBy=multi-user.target path : /lib/systemd/system/smart-gateway.service permissons : '0644' runcmd : - 'curl https://raw.githubusercontent.com/signalfx/app-dev-workshop/master/etc/motd -o /etc/motd' - 'curl https://raw.githubusercontent.com/signalfx/app-dev-workshop/master/smart-gateway/install.sh -o /home/ubuntu/smartgateway-install.sh' - chown ubuntu:ubuntu /home/ubuntu/smartgateway-install.sh - chmod 755 /home/ubuntu/smartgateway-install.sh # Replace ACCESS_TOKEN, REALM, HOSTNAME & CLUSTER_NAME accordingly - ./home/ubuntu/smartgateway-install.sh ACCESS_TOKEN REALM HOSTNAME CLUSTER_NAME - systemctl enable smart-gateway.service - systemctl daemon-reload - systemctl restart smart-gateway Now we can start up the SmartGateway instance, replacing YOUR_INITIALS accordingly. multipass launch --name YOUR_INITIALS-sg --cloud-init cloud-init/smart-gateway.yaml Find out which IP address has been assigned for the newly created instance and make a note of the IPv4 address that has been assigned. multipass list Name State IPv4 Image rwc-sg Running 192.168.64.30 Ubuntu 18.04 LTS Shell into the newly created Smart-Gateway instance. Please use your initials to prefix sg for the name of the instance. multipass shell YOUR_INITIALS-sg Test the gateway is running and working with the following curl command curl -d'[]' -H'Content-Type:application/json' 127.0.0.1:8080/v1/trace If result is \"OK\" we can continue, else validate the steps above. Step 2: Deploy the SmartAgent in the SmartGateway instance to monitor the SmartGateway (now that\u2019s a really smart instance!) \u00b6 Remaining in the shell for the SmartGateway instance, next we need to install a SmartAgent to monitor SmartGateway. Using the same ACCESS_TOKEN that was used in Step #1 above. curl -sSL https://dl.signalfx.com/signalfx-agent.sh > /tmp/signalfx-agent.sh sudo sh /tmp/signalfx-agent.sh --realm YOUR_REALM YOUR_ACCESS_TOKEN Once the Agent has installed edit sudo vi /etc/signalfx/agent.yaml and add the extraDimensions under the signalfx-metadata plugin. For the cluster parameter you will need to set it to exactly what was used for the SmartGateway installation above e.g. YOUR_INITIALS-sg-cluster . You do not need to restart the agent for this change to take effect. - type : collectd/signalfx-metadata extraDimensions : source : gateway cluster : YOUR_INITIALS-sg-cluster Once the installation and configuration is complete, validate the agent is running. signalfx-agent status SignalFx Agent version: 4.18.3 Agent uptime: 3s Observers active: host Active Monitors: 10 Configured Monitors: 10 Discovered Endpoint Count: 6 Bad Monitor Config: None Global Dimensions: {host: rwc} Datapoints sent (last minute): 0 Datapoints failed (last minute): 0 Datapoints overwritten (total): 0 Events Sent (last minute): 0 Trace Spans Sent (last minute): 0 Trace Spans overwritten (total): 0 Step 3: Create the Application instance with Multipass and deploy the SmartAgent \u00b6 Open a new terminal and create a Multipass instance to host the application and the SmartAgent. We shall refer to this as the Application instance. Please use your initials to prefix app for the name of the instance. multipass launch --name YOUR_INITIALS-app --cloud-init cloud-init/application.yaml Find out which IP address has been assigned for the newly created instance and make a note of the IPv4 address that has been assigned. multipass list Name State IPv4 Image rwc-app Running 192.168.64.31 Ubuntu 18.04 LTS rwc-sg Running 192.168.64.30 Ubuntu 18.04 LTS Once the instance has been successfully created shell into it. multipass shell YOUR_INITIALS-app Next we need to install the SmartAgent itself using the same ACCESS_TOKEN that was used in Step #1 above. curl -sSL https://dl.signalfx.com/signalfx-agent.sh > /tmp/signalfx-agent.sh sudo sh /tmp/signalfx-agent.sh --realm YOUR_REALM YOUR_ACCESS_TOKEN Once the installation is complete, validate the agent is running. signalfx-agent status SignalFx Agent version: 4.18.3 Agent uptime: 3s Observers active: host Active Monitors: 10 Configured Monitors: 10 Discovered Endpoint Count: 6 Bad Monitor Config: None Global Dimensions: {host: rwc} Datapoints sent (last minute): 0 Datapoints failed (last minute): 0 Datapoints overwritten (total): 0 Events Sent (last minute): 0 Trace Spans Sent (last minute): 0 Trace Spans overwritten (total): 0 Step 4: Update the Application instance to accept traces and to send traces to the SmartGateway \u00b6 Remaining in the Application instance, edit sudo vi /etc/signalfx/cluster with the cluster name used in the SmartGateway configuration from Step #1 e.g. YOUR_INITIALS-sg-cluster Edit /etc/signalfx/agent.yaml and add traceEndpointUrl parameter and value just before intervalSeconds parameter. Please use the IP address from Step #1.7 . traceEndpointUrl : http://SMART_GATEWAY_IP_ADDRESSS:8080/v1/trace Under the monitors section of the agent.yaml add the following (best placed at the end of the list of monitors) - type : trace-forwarder listenAddress : 127.0.0.1:9080 Check the trace-forwarder is responding curl -d'[]' -H'Content-Type:application/json' 127.0.0.1:9080/v1/trace If result is \"OK\" we can continue, else validate the steps above. Step 5: Confirm the SignalFx Agents have been installed correctly and are sending data back to our platform \u00b6 Navigate to the Infrastructure Tab within the SignalFx UI, and then select Hosts (Smart Agent / collectd) from the navigation pane on the left In the Filter at the top of the main page, enter host: * (notice the * at the end), to only display your VMs which should have a hostname starting with your initials. Select the System Metrics option You should now have a heat map with two squares representing your two hosts, plus a selection of charts showing their metrics. This confirms the SignalFx Agent is installed correctly on each VM. Step 6: Confirm the Smart Gateway has been installed correctly and is sending data back to our platform \u00b6 Navigate to the Dashboards tab within the SignalFx UI, and then enter smart into the search box to quickly find the Smart Gateway Dashboard Group. Select the Cluster(s) dashboard to open it. Select your cluster name from the Cluster Override dropdown in the tool bar. You should now see a display similar to below showing your Smart Gateway Heat Map, and its Activity, which should be minimal at this time. Once you finish, please proceed to Lab 2: Traced Python Application Example","title":"Apm initial"},{"location":"archive/apm-initial/#before-we-start-signalfx-org-access","text":"An organisation needs to be pre-provisioned as a \u00b5APM entitlement is required for the purposes of this module. Please contact someone from SignalFx to get a trial instance with \u00b5APM enabled if you don\u2019t have one already. To check if you have an organisation with \u00b5APM enabled, just login to SignalFx and check that you have the \u00b5APM tab on the top navbar next to Dashboards.","title":"Before We Start - SignalFx Org Access"},{"location":"archive/apm-initial/#step-1-create-an-instance-with-multipass-and-deploy-the-smartgateway","text":"If you have executed Module 1 of this workshop, then skip the multipass installation and zip download as you already have this, and go straight to Step#1.5 Install Multipass for your OS - https://multipass.run/. On a Mac you can also install via brew, e.g. brew cask install multipass Obtain your Access Token (and take note of your Realm from under My Profile) in the SignalFx UI Download the App Dev Workshop master zip file and unzip it curl -LO https://github.com/signalfx/app-dev-workshop/archive/master.zip unzip master.zip Change into the app-dev-workshop-master directory cd app-dev-workshop-master Edit cloud-init/smart-gateway.yaml and on line #30 replace ACCESS_TOKEN with your SignalFx token, REALM with the SignalFx realm you are running in, HOSTNAME with YOUR_INITIALS-sg and CLUSTER_NAME with YOUR_INITIALS-sg-cluster. NOTE: The hostname defined here will be the same hostname that we will use to launch the instance in Step #1.7 #cloud-config package_update : true package_upgrade : true write_files : - content : | [Unit] Description=SignalFx Smart Gateway After=network.target [Service] ExecStart=/usr/local/bin/smart-gateway --configfile /var/lib/gateway/etc/gateway.conf KillMode=mixed Restart=on-failure Type=simple User=root Group=root [Install] WantedBy=multi-user.target path : /lib/systemd/system/smart-gateway.service permissons : '0644' runcmd : - 'curl https://raw.githubusercontent.com/signalfx/app-dev-workshop/master/etc/motd -o /etc/motd' - 'curl https://raw.githubusercontent.com/signalfx/app-dev-workshop/master/smart-gateway/install.sh -o /home/ubuntu/smartgateway-install.sh' - chown ubuntu:ubuntu /home/ubuntu/smartgateway-install.sh - chmod 755 /home/ubuntu/smartgateway-install.sh # Replace ACCESS_TOKEN, REALM, HOSTNAME & CLUSTER_NAME accordingly - ./home/ubuntu/smartgateway-install.sh ACCESS_TOKEN REALM HOSTNAME CLUSTER_NAME - systemctl enable smart-gateway.service - systemctl daemon-reload - systemctl restart smart-gateway Now we can start up the SmartGateway instance, replacing YOUR_INITIALS accordingly. multipass launch --name YOUR_INITIALS-sg --cloud-init cloud-init/smart-gateway.yaml Find out which IP address has been assigned for the newly created instance and make a note of the IPv4 address that has been assigned. multipass list Name State IPv4 Image rwc-sg Running 192.168.64.30 Ubuntu 18.04 LTS Shell into the newly created Smart-Gateway instance. Please use your initials to prefix sg for the name of the instance. multipass shell YOUR_INITIALS-sg Test the gateway is running and working with the following curl command curl -d'[]' -H'Content-Type:application/json' 127.0.0.1:8080/v1/trace If result is \"OK\" we can continue, else validate the steps above.","title":"Step 1: Create an instance with Multipass and deploy the SmartGateway"},{"location":"archive/apm-initial/#step-2-deploy-the-smartagent-in-the-smartgateway-instance-to-monitor-the-smartgateway-now-thats-a-really-smart-instance","text":"Remaining in the shell for the SmartGateway instance, next we need to install a SmartAgent to monitor SmartGateway. Using the same ACCESS_TOKEN that was used in Step #1 above. curl -sSL https://dl.signalfx.com/signalfx-agent.sh > /tmp/signalfx-agent.sh sudo sh /tmp/signalfx-agent.sh --realm YOUR_REALM YOUR_ACCESS_TOKEN Once the Agent has installed edit sudo vi /etc/signalfx/agent.yaml and add the extraDimensions under the signalfx-metadata plugin. For the cluster parameter you will need to set it to exactly what was used for the SmartGateway installation above e.g. YOUR_INITIALS-sg-cluster . You do not need to restart the agent for this change to take effect. - type : collectd/signalfx-metadata extraDimensions : source : gateway cluster : YOUR_INITIALS-sg-cluster Once the installation and configuration is complete, validate the agent is running. signalfx-agent status SignalFx Agent version: 4.18.3 Agent uptime: 3s Observers active: host Active Monitors: 10 Configured Monitors: 10 Discovered Endpoint Count: 6 Bad Monitor Config: None Global Dimensions: {host: rwc} Datapoints sent (last minute): 0 Datapoints failed (last minute): 0 Datapoints overwritten (total): 0 Events Sent (last minute): 0 Trace Spans Sent (last minute): 0 Trace Spans overwritten (total): 0","title":"Step 2: Deploy the SmartAgent in the SmartGateway instance to monitor the SmartGateway (now that\u2019s a really smart instance!)"},{"location":"archive/apm-initial/#step-3-create-the-application-instance-with-multipass-and-deploy-the-smartagent","text":"Open a new terminal and create a Multipass instance to host the application and the SmartAgent. We shall refer to this as the Application instance. Please use your initials to prefix app for the name of the instance. multipass launch --name YOUR_INITIALS-app --cloud-init cloud-init/application.yaml Find out which IP address has been assigned for the newly created instance and make a note of the IPv4 address that has been assigned. multipass list Name State IPv4 Image rwc-app Running 192.168.64.31 Ubuntu 18.04 LTS rwc-sg Running 192.168.64.30 Ubuntu 18.04 LTS Once the instance has been successfully created shell into it. multipass shell YOUR_INITIALS-app Next we need to install the SmartAgent itself using the same ACCESS_TOKEN that was used in Step #1 above. curl -sSL https://dl.signalfx.com/signalfx-agent.sh > /tmp/signalfx-agent.sh sudo sh /tmp/signalfx-agent.sh --realm YOUR_REALM YOUR_ACCESS_TOKEN Once the installation is complete, validate the agent is running. signalfx-agent status SignalFx Agent version: 4.18.3 Agent uptime: 3s Observers active: host Active Monitors: 10 Configured Monitors: 10 Discovered Endpoint Count: 6 Bad Monitor Config: None Global Dimensions: {host: rwc} Datapoints sent (last minute): 0 Datapoints failed (last minute): 0 Datapoints overwritten (total): 0 Events Sent (last minute): 0 Trace Spans Sent (last minute): 0 Trace Spans overwritten (total): 0","title":"Step 3: Create the Application instance with Multipass and deploy the SmartAgent"},{"location":"archive/apm-initial/#step-4-update-the-application-instance-to-accept-traces-and-to-send-traces-to-the-smartgateway","text":"Remaining in the Application instance, edit sudo vi /etc/signalfx/cluster with the cluster name used in the SmartGateway configuration from Step #1 e.g. YOUR_INITIALS-sg-cluster Edit /etc/signalfx/agent.yaml and add traceEndpointUrl parameter and value just before intervalSeconds parameter. Please use the IP address from Step #1.7 . traceEndpointUrl : http://SMART_GATEWAY_IP_ADDRESSS:8080/v1/trace Under the monitors section of the agent.yaml add the following (best placed at the end of the list of monitors) - type : trace-forwarder listenAddress : 127.0.0.1:9080 Check the trace-forwarder is responding curl -d'[]' -H'Content-Type:application/json' 127.0.0.1:9080/v1/trace If result is \"OK\" we can continue, else validate the steps above.","title":"Step 4: Update the Application instance to accept traces and to send traces to the SmartGateway"},{"location":"archive/apm-initial/#step-5-confirm-the-signalfx-agents-have-been-installed-correctly-and-are-sending-data-back-to-our-platform","text":"Navigate to the Infrastructure Tab within the SignalFx UI, and then select Hosts (Smart Agent / collectd) from the navigation pane on the left In the Filter at the top of the main page, enter host: * (notice the * at the end), to only display your VMs which should have a hostname starting with your initials. Select the System Metrics option You should now have a heat map with two squares representing your two hosts, plus a selection of charts showing their metrics. This confirms the SignalFx Agent is installed correctly on each VM.","title":"Step 5: Confirm the SignalFx Agents have been installed correctly and are sending data back to our platform"},{"location":"archive/apm-initial/#step-6-confirm-the-smart-gateway-has-been-installed-correctly-and-is-sending-data-back-to-our-platform","text":"Navigate to the Dashboards tab within the SignalFx UI, and then enter smart into the search box to quickly find the Smart Gateway Dashboard Group. Select the Cluster(s) dashboard to open it. Select your cluster name from the Cluster Override dropdown in the tool bar. You should now see a display similar to below showing your Smart Gateway Heat Map, and its Activity, which should be minimal at this time. Once you finish, please proceed to Lab 2: Traced Python Application Example","title":"Step 6: Confirm the Smart Gateway has been installed correctly and is sending data back to our platform"},{"location":"archive/apm-java/","text":"Back on your instance, extract the package, download our Java Agent and run the Echo server: cd ~/java-app curl -qsOL https://github.com/signalfx/signalfx-java-tracing/releases/download/v0.28.0-sfx8/signalfx-tracing.jar ./run-server.sh Make a simple request: curl -XPOST -d'Hello, world' -H'Content-Type:text/plain' http://localhost:5000/echo Because we're not doing anything specific to instruct the Smart Gateway to retain this trace, you might want to make this request a few times to make sure at least one of those traces will be sampled. You can confirm that this is happening after a few minutes by comparing the Traces Analyzed and Traces Retained charts on the Smart Gateway dashboard (filtered for your cluster).","title":"Apm java"},{"location":"archive/apm-python/","text":"Step 1: Infrastructure setup complete, now let\u2019s run our first fully monitored application! \u00b6 Switch to the Application instance (the one created in Lab #1) and change to the mypythonapp directory cd ~/mypythonapp In order to see how the demonstration Python application has been instrumented using https://github.com/signalfx/signalfx-python-tracing type more demo.py #!/usr/bin/env python from flask import Flask , make_response , request from signalfx_tracing import trace import opentracing app = Flask ( __name__ ) @trace def convert_response ( message ): # In this example we want to force this trace to be retained opentracing . tracer . active_span . set_tag ( 'sampling.priority' , 1 ) opentracing . tracer . active_span . set_tag ( 'message' , message ) print ( opentracing . tracer . active_span ) return 'You said: {} ' . format ( message ) @app . route ( '/echo' , methods = [ 'POST' ]) def echo (): message = request . data . decode ( 'utf-8' ) return make_response ( convert_response ( message )) if __name__ == '__main__' : app . run () Start the Python application by running the following command, replace [YOUR_INITIALS] to make your application unique. SIGNALFX_SERVICE_NAME =[ YOUR_INITIALS ] -app-dev-python-app sfx-py-trace ./demo.py & disown IMPORTANT: After running this code, hit the enter key in your keyboard to get out of the process and continue with the following steps. Don't worry, your python app will continue running in the background. Step 2: Generate some Traces \u00b6 We will be using a really practical tool to simulate requests called Apache Benchmark or ab. But first let's make sure that the service we started before can actually accept requests, by running the following command: curl -XPOST -d 'Hello, world' -H 'Content-Type:text/plain' http://localhost:5000/echo You should get something like: 795cf220f0ee0afa:7a1f10140ad14024:4a81cc4098335da:3 rwc-app-dev-python-app.convert_response 127 .0.0.1 - - [ 04 /Nov/2019 15 :07:24 ] \"POST /echo HTTP/1.1\" 200 - If you don't get this response, make sure the Step #1.2 (above) was executed properly and that you have a service running called ./demo.py executed by python. On the Application instance itself you can confirm this by running ps -ef | grep demo.py Now that we know we can call our service, let's run ab to simulate load and start generating traces that our Smart Gateway can capture and send to the SignalFx platform. Confirm a file named ~/mypythonapp/post_data.json exists and has the following inside: \"Hello from the App Dev Workshop!\" Save the file, and in the same directory, execute the following: ab -p post_data.json -T application/json -c20 -n1000 http://localhost:5000/echo This will create 20 concurrent connections to our localhost python app, and it will post the data 1000 times. Step 3: Visualizing the Data \u00b6 Over in SignalFx, under the Built-In Dashboard Groups, you will see a Smart Gateway Dashboard group. Go to the Cluster(s) Dashboard: Over there you will see information about the host running the Smart Gateway, and a few other numbers that are important. But the most important of all, are the 3 big number group of charts, showing TAPM, Retained TPM and APM Identities. TAPM are the Traces Analysed Per Minute, which is the amount of traces that the Smart Gateway is ingesting and processing. Retained TPM are the traces that the Smart Gateway, after processing them, think are important to keep, and send to SignalFx for further analysis by the users. APM Identities are each unique span and initiating span/endpoint tracked by the Smart Gateway and sent to SignalFx. To explain this a little better please see the following image: If you want to know more about Traces, Spans, Metrics and Metadata, please follow this link. If everything goes according to plan, you should see in that dashboard, some numbers that represent the test we just did. Step 4: Analyzing Traces \u00b6 Navigate to uAPM \u2192 Traces on the main toolbar, then ensure you have selected your cluster from the Cluster dropdown at the top left, you should see something like this: Feel free to investigate our built-in Outlier Analysis, showing the potential source of our problems in our application, or navigate to some of the traces, and inspect the payload we sent in our test. You go to a trace by clicking on it: Then click on the span that handled the response, and see the message: Feel free to continue navigating uAPM features now that we have traces and spans going in. Also, you can try sending more tests or changing the payload of the tests to see how fast the new tests are ingested and analyzed in SignalFx. Once you finish, please proceed to Lab 3: Simple Java auto-instrumentation","title":"Apm python"},{"location":"archive/apm-python/#step-1-infrastructure-setup-complete-now-lets-run-our-first-fully-monitored-application","text":"Switch to the Application instance (the one created in Lab #1) and change to the mypythonapp directory cd ~/mypythonapp In order to see how the demonstration Python application has been instrumented using https://github.com/signalfx/signalfx-python-tracing type more demo.py #!/usr/bin/env python from flask import Flask , make_response , request from signalfx_tracing import trace import opentracing app = Flask ( __name__ ) @trace def convert_response ( message ): # In this example we want to force this trace to be retained opentracing . tracer . active_span . set_tag ( 'sampling.priority' , 1 ) opentracing . tracer . active_span . set_tag ( 'message' , message ) print ( opentracing . tracer . active_span ) return 'You said: {} ' . format ( message ) @app . route ( '/echo' , methods = [ 'POST' ]) def echo (): message = request . data . decode ( 'utf-8' ) return make_response ( convert_response ( message )) if __name__ == '__main__' : app . run () Start the Python application by running the following command, replace [YOUR_INITIALS] to make your application unique. SIGNALFX_SERVICE_NAME =[ YOUR_INITIALS ] -app-dev-python-app sfx-py-trace ./demo.py & disown IMPORTANT: After running this code, hit the enter key in your keyboard to get out of the process and continue with the following steps. Don't worry, your python app will continue running in the background.","title":"Step 1: Infrastructure setup complete, now let\u2019s run our first fully monitored application!"},{"location":"archive/apm-python/#step-2-generate-some-traces","text":"We will be using a really practical tool to simulate requests called Apache Benchmark or ab. But first let's make sure that the service we started before can actually accept requests, by running the following command: curl -XPOST -d 'Hello, world' -H 'Content-Type:text/plain' http://localhost:5000/echo You should get something like: 795cf220f0ee0afa:7a1f10140ad14024:4a81cc4098335da:3 rwc-app-dev-python-app.convert_response 127 .0.0.1 - - [ 04 /Nov/2019 15 :07:24 ] \"POST /echo HTTP/1.1\" 200 - If you don't get this response, make sure the Step #1.2 (above) was executed properly and that you have a service running called ./demo.py executed by python. On the Application instance itself you can confirm this by running ps -ef | grep demo.py Now that we know we can call our service, let's run ab to simulate load and start generating traces that our Smart Gateway can capture and send to the SignalFx platform. Confirm a file named ~/mypythonapp/post_data.json exists and has the following inside: \"Hello from the App Dev Workshop!\" Save the file, and in the same directory, execute the following: ab -p post_data.json -T application/json -c20 -n1000 http://localhost:5000/echo This will create 20 concurrent connections to our localhost python app, and it will post the data 1000 times.","title":"Step 2: Generate some Traces"},{"location":"archive/apm-python/#step-3-visualizing-the-data","text":"Over in SignalFx, under the Built-In Dashboard Groups, you will see a Smart Gateway Dashboard group. Go to the Cluster(s) Dashboard: Over there you will see information about the host running the Smart Gateway, and a few other numbers that are important. But the most important of all, are the 3 big number group of charts, showing TAPM, Retained TPM and APM Identities. TAPM are the Traces Analysed Per Minute, which is the amount of traces that the Smart Gateway is ingesting and processing. Retained TPM are the traces that the Smart Gateway, after processing them, think are important to keep, and send to SignalFx for further analysis by the users. APM Identities are each unique span and initiating span/endpoint tracked by the Smart Gateway and sent to SignalFx. To explain this a little better please see the following image: If you want to know more about Traces, Spans, Metrics and Metadata, please follow this link. If everything goes according to plan, you should see in that dashboard, some numbers that represent the test we just did.","title":"Step 3: Visualizing the Data"},{"location":"archive/apm-python/#step-4-analyzing-traces","text":"Navigate to uAPM \u2192 Traces on the main toolbar, then ensure you have selected your cluster from the Cluster dropdown at the top left, you should see something like this: Feel free to investigate our built-in Outlier Analysis, showing the potential source of our problems in our application, or navigate to some of the traces, and inspect the payload we sent in our test. You go to a trace by clicking on it: Then click on the span that handled the response, and see the message: Feel free to continue navigating uAPM features now that we have traces and spans going in. Also, you can try sending more tests or changing the payload of the tests to see how fast the new tests are ingested and analyzed in SignalFx. Once you finish, please proceed to Lab 3: Simple Java auto-instrumentation","title":"Step 4: Analyzing Traces"},{"location":"archive/apm2/","text":"\u00b5APM Workshop on K8S \u00b6 In this module we will instrument a Node.js and a Python application that run on Kubernetes. Step 1: Explore the sample Node.js app \u00b6 We are using a slightly modified version of knote from a Node.js on K8S Tutorial . It is located in the apm/js directory. The app itself is in app/index.js . It also has configuration for running on kubernetes in the folder k8s and a Dockerfile for building the image. Step 2: Instrument the Node.js app \u00b6 The app is instrumented as per our Node.js instrumentation guide : Dockerfile installs the required package dependency as part of the docker image build: npm i -S signalfx-tracing Sets up the OpenTracing instrumentation in app/index.js before requiring any other packages: const tracer = require ( 'signalfx-tracing' ). init ({ service : process . env . SIGNALFX_SERVICE_NAME || 'knote-js' , url : ` ${ process . env . SIGNALFX_AGENT_HOST } :9080/v1/trace` }) Review the K8S configuration in k8s/knote.yaml and observe the environment variables used in index.js are set there. Step 3: Build the Docker image for the Node.js app \u00b6 The workshop multipass instance comes with a local docker registry running on registry.local:5000 . Docker is pre-configured to obtain images from this registry. Let's build the images for our app: docker build . -t registry.local:5000/knote-js:3.0.0 Then transfer them to the registry with: docker push registry.local:5000/knote-js:3.0.0 Step 4: Deploy the Node.js app on K8S \u00b6 From the workshop/apm/js directory, review from k8s/knote.yaml again and replace [INITIALS] with your actual initials. Then apply the configuration: kubectl apply -f k8s Observe as pods are being created: ```bash kubectl get pods -l app=knote --watch ``` When this shows a running pod for knote, interrupt with Ctrl-C and obtain the service ip: IP = $( kc get svc knote -o jsonpath = '{.spec.clusterIP}' ) echo $IP Validate that the app is running: curl -L http:// $IP / It should serve some HTML markup similar to: < html >< head >< title ></ title >< link rel = \"stylesheet\" href = \"tachyons.min.css\" /></ head >< body class = \"ph3 pt0 pb4 mw7 center sans-serif\" >< h1 class = \"f2 mb0\" >< span class = \"gold\" > k </ span > note </ h1 >< p class = \"f5 mt1 mb4 lh-copy\" > A simple note-taking app. </ p >< form action = \"/note\" method = \"POST\" enctype = \"multipart/form-data\" >< ol class = \"list pl0\" >< li class = \"mv3\" >< label class = \"f6 b db mb2\" for = \"image\" > Upload an image </ label >< input class = \"f6 link dim br1 ba b--black-20 ph3 pv2 mb2 dib black bg-white pointer\" type = \"file\" name = \"image\" />< input class = \"f6 link dim br1 ba bw1 ph3 pv2 mb2 dib black bg-white pointer ml2\" type = \"submit\" value = \"Upload\" name = \"upload\" /></ li >< li class = \"mv3\" >< label class = \"f6 b db mb2\" for = \"description\" > Write your content here </ label >< textarea class = \"f4 db border-box hover-black w-100 measure ba b--black-20 pa2 br2 mb2\" rows = \"5\" name = \"description\" ></ textarea >< input class = \"f6 link dim br1 ba bw1 ph3 pv2 mb2 dib black bg-white pointer\" type = \"submit\" value = \"Publish\" name = \"publish\" /></ li ></ ol ></ form >< p class = \"lh-copy f6\" > You don't have any notes yet. </ p ></ body ></ html > Step 5: Test the running Node.js app \u00b6 This is a simple note taking app, so let's make some notes by adding random words: for i in { 1 ..10 } ; do curl -L -F \"image=\" -F \"description= $( shuf -n1 /usr/share/dict/words ) \" http:// $IP /note ; done If you curl the app again you should now see a list of notes after the above markup: \u2026 </ p ></ li >< li class = \"mv3 bb bw2 b--light-yellow bg-washed-yellow ph4 pv2\" >< p class = \"measure\" >< p > semiretired </ p > </ p ></ li >< li class = \"mv3 bb bw2 b--light-yellow bg-washed-yellow ph4 pv2\" >< p class = \"measure\" >< p > streakier </ p > </ p ></ li >< li class = \"mv3 bb bw2 b--light-yellow bg-washed-yellow ph4 pv2\" >< p class = \"measure\" >< p > relay &#39; s </ p > </ p ></ li >< li class = \"mv3 bb bw2 b--light-yellow bg-washed-yellow ph4 pv2\" >< p class = \"measure\" >< p > seconding </ p > </ p ></ li >< li class = \"mv3 bb bw2 b--light-yellow bg-washed-yellow ph4 pv2\" >< p class = \"measure\" >< p > rouged </ p > </ p ></ li >< li class = \"mv3 bb bw2 b--light-yellow bg-washed-yellow ph4 pv2\" >< p class = \"measure\" >< p > pours </ p > </ p ></ li >< li class = \"mv3 bb bw2 b--light-yellow bg-washed-yellow ph4 pv2\" >< p class = \"measure\" >< p > disproof </ p > </ p ></ li >< li class = \"mv3 bb bw2 b--light-yellow bg-washed-yellow ph4 pv2\" >< p class = \"measure\" >< p > exhortation </ p > </ p ></ li >< li class = \"mv3 bb bw2 b--light-yellow bg-washed-yellow ph4 pv2\" >< p class = \"measure\" >< p > sprigs </ p > </ p ></ li >< li class = \"mv3 bb bw2 b--light-yellow bg-washed-yellow ph4 pv2\" >< p class = \"measure\" >< p > tramped </ p > Let's simulate load for the app: ab -n 1000 -c 20 http:// $IP / At this point you should see traffic in your \u00b5APM view. Step 6: Explore the sample python app \u00b6 Step 7: Instrument the python app \u00b6 Step 8: Build the Docker image for the Python app \u00b6 Step 9: Deploy the Python app on K8S \u00b6 Step 10: Test the running Python app \u00b6","title":"\u00b5APM Workshop on K8S"},{"location":"archive/apm2/#apm-workshop-on-k8s","text":"In this module we will instrument a Node.js and a Python application that run on Kubernetes.","title":"\u00b5APM Workshop on K8S"},{"location":"archive/apm2/#step-1-explore-the-sample-nodejs-app","text":"We are using a slightly modified version of knote from a Node.js on K8S Tutorial . It is located in the apm/js directory. The app itself is in app/index.js . It also has configuration for running on kubernetes in the folder k8s and a Dockerfile for building the image.","title":"Step 1: Explore the sample Node.js app"},{"location":"archive/apm2/#step-2-instrument-the-nodejs-app","text":"The app is instrumented as per our Node.js instrumentation guide : Dockerfile installs the required package dependency as part of the docker image build: npm i -S signalfx-tracing Sets up the OpenTracing instrumentation in app/index.js before requiring any other packages: const tracer = require ( 'signalfx-tracing' ). init ({ service : process . env . SIGNALFX_SERVICE_NAME || 'knote-js' , url : ` ${ process . env . SIGNALFX_AGENT_HOST } :9080/v1/trace` }) Review the K8S configuration in k8s/knote.yaml and observe the environment variables used in index.js are set there.","title":"Step 2: Instrument the Node.js app"},{"location":"archive/apm2/#step-3-build-the-docker-image-for-the-nodejs-app","text":"The workshop multipass instance comes with a local docker registry running on registry.local:5000 . Docker is pre-configured to obtain images from this registry. Let's build the images for our app: docker build . -t registry.local:5000/knote-js:3.0.0 Then transfer them to the registry with: docker push registry.local:5000/knote-js:3.0.0","title":"Step 3: Build the Docker image for the Node.js app"},{"location":"archive/apm2/#step-4-deploy-the-nodejs-app-on-k8s","text":"From the workshop/apm/js directory, review from k8s/knote.yaml again and replace [INITIALS] with your actual initials. Then apply the configuration: kubectl apply -f k8s Observe as pods are being created: ```bash kubectl get pods -l app=knote --watch ``` When this shows a running pod for knote, interrupt with Ctrl-C and obtain the service ip: IP = $( kc get svc knote -o jsonpath = '{.spec.clusterIP}' ) echo $IP Validate that the app is running: curl -L http:// $IP / It should serve some HTML markup similar to: < html >< head >< title ></ title >< link rel = \"stylesheet\" href = \"tachyons.min.css\" /></ head >< body class = \"ph3 pt0 pb4 mw7 center sans-serif\" >< h1 class = \"f2 mb0\" >< span class = \"gold\" > k </ span > note </ h1 >< p class = \"f5 mt1 mb4 lh-copy\" > A simple note-taking app. </ p >< form action = \"/note\" method = \"POST\" enctype = \"multipart/form-data\" >< ol class = \"list pl0\" >< li class = \"mv3\" >< label class = \"f6 b db mb2\" for = \"image\" > Upload an image </ label >< input class = \"f6 link dim br1 ba b--black-20 ph3 pv2 mb2 dib black bg-white pointer\" type = \"file\" name = \"image\" />< input class = \"f6 link dim br1 ba bw1 ph3 pv2 mb2 dib black bg-white pointer ml2\" type = \"submit\" value = \"Upload\" name = \"upload\" /></ li >< li class = \"mv3\" >< label class = \"f6 b db mb2\" for = \"description\" > Write your content here </ label >< textarea class = \"f4 db border-box hover-black w-100 measure ba b--black-20 pa2 br2 mb2\" rows = \"5\" name = \"description\" ></ textarea >< input class = \"f6 link dim br1 ba bw1 ph3 pv2 mb2 dib black bg-white pointer\" type = \"submit\" value = \"Publish\" name = \"publish\" /></ li ></ ol ></ form >< p class = \"lh-copy f6\" > You don't have any notes yet. </ p ></ body ></ html >","title":"Step 4: Deploy the Node.js app on K8S"},{"location":"archive/apm2/#step-5-test-the-running-nodejs-app","text":"This is a simple note taking app, so let's make some notes by adding random words: for i in { 1 ..10 } ; do curl -L -F \"image=\" -F \"description= $( shuf -n1 /usr/share/dict/words ) \" http:// $IP /note ; done If you curl the app again you should now see a list of notes after the above markup: \u2026 </ p ></ li >< li class = \"mv3 bb bw2 b--light-yellow bg-washed-yellow ph4 pv2\" >< p class = \"measure\" >< p > semiretired </ p > </ p ></ li >< li class = \"mv3 bb bw2 b--light-yellow bg-washed-yellow ph4 pv2\" >< p class = \"measure\" >< p > streakier </ p > </ p ></ li >< li class = \"mv3 bb bw2 b--light-yellow bg-washed-yellow ph4 pv2\" >< p class = \"measure\" >< p > relay &#39; s </ p > </ p ></ li >< li class = \"mv3 bb bw2 b--light-yellow bg-washed-yellow ph4 pv2\" >< p class = \"measure\" >< p > seconding </ p > </ p ></ li >< li class = \"mv3 bb bw2 b--light-yellow bg-washed-yellow ph4 pv2\" >< p class = \"measure\" >< p > rouged </ p > </ p ></ li >< li class = \"mv3 bb bw2 b--light-yellow bg-washed-yellow ph4 pv2\" >< p class = \"measure\" >< p > pours </ p > </ p ></ li >< li class = \"mv3 bb bw2 b--light-yellow bg-washed-yellow ph4 pv2\" >< p class = \"measure\" >< p > disproof </ p > </ p ></ li >< li class = \"mv3 bb bw2 b--light-yellow bg-washed-yellow ph4 pv2\" >< p class = \"measure\" >< p > exhortation </ p > </ p ></ li >< li class = \"mv3 bb bw2 b--light-yellow bg-washed-yellow ph4 pv2\" >< p class = \"measure\" >< p > sprigs </ p > </ p ></ li >< li class = \"mv3 bb bw2 b--light-yellow bg-washed-yellow ph4 pv2\" >< p class = \"measure\" >< p > tramped </ p > Let's simulate load for the app: ab -n 1000 -c 20 http:// $IP / At this point you should see traffic in your \u00b5APM view.","title":"Step 5: Test the running Node.js app"},{"location":"archive/apm2/#step-6-explore-the-sample-python-app","text":"","title":"Step 6: Explore the sample python app"},{"location":"archive/apm2/#step-7-instrument-the-python-app","text":"","title":"Step 7: Instrument the python app"},{"location":"archive/apm2/#step-8-build-the-docker-image-for-the-python-app","text":"","title":"Step 8: Build the Docker image for the Python app"},{"location":"archive/apm2/#step-9-deploy-the-python-app-on-k8s","text":"","title":"Step 9: Deploy the Python app on K8S"},{"location":"archive/apm2/#step-10-test-the-running-python-app","text":"","title":"Step 10: Test the running Python app"},{"location":"archive/central-se-lab/","text":"Goals \u00b6 Set up the workshop environment Obtain Credentials Deploy SignalFx Smart Agent via install script on a VM Confirm the Smart Agent is working and sending data Use the SignalFx Helm chart to install the Smart Agent in K3s. Deploy a NGINX ReplicaSet into K3s and confirm the auto discovery of your NGINX deployment. Run a benchmark test to create metrics and confirm them streaming into SignalFx! Step 1: Let\u2019s bake some K8s \u00b6 Install Multipass for your OS - On a Mac you can install via brew , e.g. brew cask install multipass Clone the workshop repo: git clone https://github.com/signalfx/app-dev-workshop Change into the app-dev-workshop-master directory cd app-dev-workshop Launch the Multipass instance which will run Kubernetes. Note: Use [YOUR-INITIALS]-k3s this is so the value of the instance hostname is unique e.g. rwc-k3s multipass launch --name [ YOUR-INITIALS ] -k3s --cloud-init cloud-init/k3s.yaml --cpus = 2 --mem = 4G --disk = 12G Once the instance has been successfully created shell into it. multipass shell [ YOUR-INITIALS ] -k3s Step 2: I\u2019ve got the key, I\u2019ve got the secret! \u00b6 You will need to obtain your Access Token from the SignalFx UI once Kubernetes is running. You can find your Access Token by clicking on your profile icon on the top right of the SignalFx UI. Then select Organisation Settings \u2192 Access Tokens . Expand the Default token, then click on Show Token to expose your token. Later in the lab you can come back here and click the Copy button which will copy it to your clipboard so you can paste it when you need to provide an access token in the lab. You will also need to obtain the name of the Realm for your SignalFx account. Click on the profile icon again, but this time select 'My Profile'. The Ream can be found in the middle of the page within the Organizations section. In this example it is us1 . Adjust and set the following env vars in the multipass shell. We will refer to them at various stages during the workshop. ACCESS_TOKEN = <token from Step 2 > REALM = <realm from Step 2 > INITIALS = <your initials e.g. GH> VERSION = <Smart Agent version e.g. 5 .0.4> export ACCESS_TOKEN REALM INITIALS VERSION alias kc = kubectl Finally, change into the workshop directory: cd workshop Step 3: Deploy SignalFx Smart Agent via install script on a VM \u00b6 SignalFx maintains a shell script to install on supported distributions: curl -sSL https://dl.signalfx.com/signalfx-agent.sh > /tmp/signalfx-agent.sh sudo sh /tmp/signalfx-agent.sh --realm $REALM $ACCESS_TOKEN Once the installation is complete, validate the agent is running. signalfx-agent status SignalFx Agent version: 5.0.4 Agent uptime: 9m34s Observers active: k8s-api Active Monitors: 13 Configured Monitors: 13 Discovered Endpoint Count: 15 Bad Monitor Config: None Global Dimensions: {kubernetes_cluster: AS-SFX-WORKSHOP, host: as-k3s, kubernetes_node_uid: a58cf908-0536-478d-aa63-8ba381ef2c33} GlobalSpanTags: map[] Datapoints sent (last minute): 726 Datapoints failed (last minute): 0 Datapoints overwritten (total): 0 Events Sent (last minute): 6 Trace Spans Sent (last minute): 0 Trace Spans overwritten (total): 0 Kubernetes Leader Node: as-k3s Additional status commands: signalfx-agent status config - show resolved config in use by agent signalfx-agent status endpoints - show discovered endpoints signalfx-agent status monitors - show active monitors signalfx-agent status all - show everything Step 4: Confirm the Smart Agent is working and sending data \u00b6 In the SignalFX UI, go to Infrastructure, Hosts and make sure you see your multipass instance in the list of hosts. You can also set a filter for just your instance. Step 5: Take the Helm! \u00b6 Stop the agent running on the host sudo service signalfx-agent stop Install the agent using the SignalFx Helm chart. Firstly, add the SignalFx Helm chart repository to Helm. helm repo add signalfx https://dl.signalfx.com/helm-repo Ensure the latest state of the repository helm repo update Install the Smart Agent chart with the following configuration values for the chart. sed -i -e 's/\\[INITIALS\\]/'\"$INITIALS\"'/' k3s/values.yaml helm install --set signalFxAccessToken=$ACCESS_TOKEN --set clusterName=SFX-WORKSHOP --set kubernetesClusterName=$INITIALS-SFX-WORKSHOP --set kubeletAPI.url=https://localhost:10250 --set signalFxRealm=$REALM --set agentVersion=5.0.4 --set traceEndpointUrl=https://ingest.$REALM.signalfx.com/v2/trace --set gatherDockerMetrics=false signalfx-agent signalfx/signalfx-agent -f k3s/values.yaml You can monitor the progress of the deployment by running kubectl get pods which should typically report a new pod is up and running after about 30 seconds. Ensure the status is reported as Running before continuing. Input: kubectl get pods Output: NAME READY STATUS RESTARTS AGE signalfx-agent-66tvr 1/1 Running 0 7s Ensure there are no errors by tailing the logs from the Smart Agent Pod. Output should look similar to the log output shown below. Use the label set by the helm install to tail logs (You will need to press Ctrl-C to exit). Or use the installed k9s terminal UI for bonus points! Input: kubectl logs -l app=signalfx-agent -f Output: time=\"2020-03-15T11:30:28Z\" level=info msg=\"Starting up agent version 5.0.0\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Watching for config file changes\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"New config loaded\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Using log level info\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Fetching host id dimensions\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Trying to get fully qualified hostname\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Using hostname PH-k3s\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Using host id dimensions map[host:PH-k3s kubernetes_node_uid:05ba9d7b-89d4-4c70-a3e9-4dc72923423a]\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Sending datapoints to https://ingest.us1.signalfx.com/v2/datapoint\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Sending events to https://ingest.us1.signalfx.com/v2/event\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Sending trace spans to https://ingest.us1.signalfx.com/v1/trace\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Setting cluster:SFX-WORKSHOP property on host:PH-k3s dimension\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=1 monitorType=cpu time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=2 monitorType=filesystems time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=3 monitorType=disk-io time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=4 monitorType=net-io time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=5 monitorType=load time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=6 monitorType=memory time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=7 monitorType=host-metadata time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=8 monitorType=processlist time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=9 monitorType=vmem time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=10 monitorType=kubelet-stats time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=11 monitorType=kubernetes-cluster time=\"2020-03-15T11:30:29Z\" level=info msg=\"Done configuring agent\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Serving internal metrics at localhost:8095\" I0315 11:30:29.922577 1 leaderelection.go:242] attempting to acquire leader lease default/signalfx-agent-leader... I0315 11:30:29.950448 1 leaderelection.go:252] successfully acquired lease default/signalfx-agent-leader time=\"2020-03-15T11:30:29Z\" level=info msg=\"K8s leader is now node ph-k3s\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Starting K8s API resource sync\" In the SignalFx UI, goto INFRASTRUCTURE \u2192 Kubernetes Navigator \u2192 Cluster Map and open the Kubernetes Navigator Cluster Map to ensure metrics are being sent. Validate that your cluster is discovered and shown (In a workshop you can see many more clusters) by searching for [YOUR-INITIALS]-SFX-WORKSHOP : If there are many clusters you can use the dashboard filter to narrow down to your K8s cluster e.g. kubernetes_cluster: [YOUR-INITIALS]-SFX-WORKSHOP or do this by clicking on the blue cross after selecting your cluster with your mouse. To examine the health of your cluster, open the side bar by clicking on the button to open the Metrics side bar. Once it is open, you can use the slider on the side to explore the various charts relevant to your cluster/node: Cpu%, Mem%, Network in & out. Events and Container list. Step 6: Start your NGINX! \u00b6 Still within the k3s shell session, change into the nginx directory cd ~/workshop/k3s/nginx Create the NGINX configmap using the nginx.conf file kubectl create configmap nginxconfig --from-file=nginx.conf Create the NGINX deployment kubectl create -f nginx-deployment.yaml Validate the deployment has been successful and that the NGINX pods are running, it should only take around 20 seconds for the pods to transition into a Running state. More bonus points for using the k9s terminal UI! Input: kubectl get pods Output: NAME READY STATUS RESTARTS AGE signalfx-agent-n7nz2 1/1 Running 0 11m nginx-deployment-f96cf6966-jhmjp 1/1 Running 0 21s nginx-deployment-f96cf6966-459vf 1/1 Running 0 21s nginx-deployment-f96cf6966-vrnfc 1/1 Running 0 21s nginx-deployment-f96cf6966-7z4tm 1/1 Running 0 21s Next we need to expose port 80 (HTTP) Input: kubectl create service nodeport nginx --tcp=80:80 Output: service/nginx created Run kubectl get svc then make a note of the IP address allocated to the NGINX service. Input: kubectl get svc Output: NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.96.0.1 <none> 443/TCP 9m3s nginx NodePort 10.110.36.62 <none> 80:30995/TCP 8s Step 7: Run a benchmark test to create metrics and confirm them streaming into SignalFx! \u00b6 Using the NGINX Cluster-IP address reported from Step #6 above, use Apache Benchmark ( ab ) to create some traffic to light up your SignalFx NGINX dashboard. Run this a couple of times to generate some metrics! Input: NGX_ENDPOINT=$(kubectl get svc nginx -o jsonpath='{.spec.clusterIP}') ab -n1000 -c20 http://${NGX_ENDPOINT}/ Output: This is ApacheBench, Version 2.3 <$Revision: 1826891 $> Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking localhost (be patient) Completed 100 requests ... Completed 1000 requests Finished 1000 requests Server Software: nginx/1.17.5 Server Hostname: localhost Server Port: 30995... Validate you are seeing metrics in the UI by going to Dashboards \u2192 NGINX \u2192 NGINX Servers Tip: you can again apply the filter kubernetes_cluster: [YOUR-INITIALS]-SFX-WORKSHOP to focus on only your containers. Cleaning up \u00b6 Once you are done with all modules of the workshop and no longer need your instance exit from the Multipass instance you are in and get back to your system command prompt and enter the following to delete the Multipass instance (replace [YOUR-INITIALS] with the ones you used in Step #1.3 ): multipass delete --purge [YOUR-INITIALS]-k3s","title":"Goals"},{"location":"archive/central-se-lab/#goals","text":"Set up the workshop environment Obtain Credentials Deploy SignalFx Smart Agent via install script on a VM Confirm the Smart Agent is working and sending data Use the SignalFx Helm chart to install the Smart Agent in K3s. Deploy a NGINX ReplicaSet into K3s and confirm the auto discovery of your NGINX deployment. Run a benchmark test to create metrics and confirm them streaming into SignalFx!","title":"Goals"},{"location":"archive/central-se-lab/#step-1-lets-bake-some-k8s","text":"Install Multipass for your OS - On a Mac you can install via brew , e.g. brew cask install multipass Clone the workshop repo: git clone https://github.com/signalfx/app-dev-workshop Change into the app-dev-workshop-master directory cd app-dev-workshop Launch the Multipass instance which will run Kubernetes. Note: Use [YOUR-INITIALS]-k3s this is so the value of the instance hostname is unique e.g. rwc-k3s multipass launch --name [ YOUR-INITIALS ] -k3s --cloud-init cloud-init/k3s.yaml --cpus = 2 --mem = 4G --disk = 12G Once the instance has been successfully created shell into it. multipass shell [ YOUR-INITIALS ] -k3s","title":"Step 1: Let\u2019s bake some K8s"},{"location":"archive/central-se-lab/#step-2-ive-got-the-key-ive-got-the-secret","text":"You will need to obtain your Access Token from the SignalFx UI once Kubernetes is running. You can find your Access Token by clicking on your profile icon on the top right of the SignalFx UI. Then select Organisation Settings \u2192 Access Tokens . Expand the Default token, then click on Show Token to expose your token. Later in the lab you can come back here and click the Copy button which will copy it to your clipboard so you can paste it when you need to provide an access token in the lab. You will also need to obtain the name of the Realm for your SignalFx account. Click on the profile icon again, but this time select 'My Profile'. The Ream can be found in the middle of the page within the Organizations section. In this example it is us1 . Adjust and set the following env vars in the multipass shell. We will refer to them at various stages during the workshop. ACCESS_TOKEN = <token from Step 2 > REALM = <realm from Step 2 > INITIALS = <your initials e.g. GH> VERSION = <Smart Agent version e.g. 5 .0.4> export ACCESS_TOKEN REALM INITIALS VERSION alias kc = kubectl Finally, change into the workshop directory: cd workshop","title":"Step 2: I\u2019ve got the key, I\u2019ve got the secret!"},{"location":"archive/central-se-lab/#step-3-deploy-signalfx-smart-agent-via-install-script-on-a-vm","text":"SignalFx maintains a shell script to install on supported distributions: curl -sSL https://dl.signalfx.com/signalfx-agent.sh > /tmp/signalfx-agent.sh sudo sh /tmp/signalfx-agent.sh --realm $REALM $ACCESS_TOKEN Once the installation is complete, validate the agent is running. signalfx-agent status SignalFx Agent version: 5.0.4 Agent uptime: 9m34s Observers active: k8s-api Active Monitors: 13 Configured Monitors: 13 Discovered Endpoint Count: 15 Bad Monitor Config: None Global Dimensions: {kubernetes_cluster: AS-SFX-WORKSHOP, host: as-k3s, kubernetes_node_uid: a58cf908-0536-478d-aa63-8ba381ef2c33} GlobalSpanTags: map[] Datapoints sent (last minute): 726 Datapoints failed (last minute): 0 Datapoints overwritten (total): 0 Events Sent (last minute): 6 Trace Spans Sent (last minute): 0 Trace Spans overwritten (total): 0 Kubernetes Leader Node: as-k3s Additional status commands: signalfx-agent status config - show resolved config in use by agent signalfx-agent status endpoints - show discovered endpoints signalfx-agent status monitors - show active monitors signalfx-agent status all - show everything","title":"Step 3: Deploy SignalFx Smart Agent via install script on a VM"},{"location":"archive/central-se-lab/#step-4-confirm-the-smart-agent-is-working-and-sending-data","text":"In the SignalFX UI, go to Infrastructure, Hosts and make sure you see your multipass instance in the list of hosts. You can also set a filter for just your instance.","title":"Step 4: Confirm the Smart Agent is working and sending data"},{"location":"archive/central-se-lab/#step-5-take-the-helm","text":"Stop the agent running on the host sudo service signalfx-agent stop Install the agent using the SignalFx Helm chart. Firstly, add the SignalFx Helm chart repository to Helm. helm repo add signalfx https://dl.signalfx.com/helm-repo Ensure the latest state of the repository helm repo update Install the Smart Agent chart with the following configuration values for the chart. sed -i -e 's/\\[INITIALS\\]/'\"$INITIALS\"'/' k3s/values.yaml helm install --set signalFxAccessToken=$ACCESS_TOKEN --set clusterName=SFX-WORKSHOP --set kubernetesClusterName=$INITIALS-SFX-WORKSHOP --set kubeletAPI.url=https://localhost:10250 --set signalFxRealm=$REALM --set agentVersion=5.0.4 --set traceEndpointUrl=https://ingest.$REALM.signalfx.com/v2/trace --set gatherDockerMetrics=false signalfx-agent signalfx/signalfx-agent -f k3s/values.yaml You can monitor the progress of the deployment by running kubectl get pods which should typically report a new pod is up and running after about 30 seconds. Ensure the status is reported as Running before continuing. Input: kubectl get pods Output: NAME READY STATUS RESTARTS AGE signalfx-agent-66tvr 1/1 Running 0 7s Ensure there are no errors by tailing the logs from the Smart Agent Pod. Output should look similar to the log output shown below. Use the label set by the helm install to tail logs (You will need to press Ctrl-C to exit). Or use the installed k9s terminal UI for bonus points! Input: kubectl logs -l app=signalfx-agent -f Output: time=\"2020-03-15T11:30:28Z\" level=info msg=\"Starting up agent version 5.0.0\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Watching for config file changes\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"New config loaded\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Using log level info\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Fetching host id dimensions\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Trying to get fully qualified hostname\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Using hostname PH-k3s\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Using host id dimensions map[host:PH-k3s kubernetes_node_uid:05ba9d7b-89d4-4c70-a3e9-4dc72923423a]\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Sending datapoints to https://ingest.us1.signalfx.com/v2/datapoint\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Sending events to https://ingest.us1.signalfx.com/v2/event\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Sending trace spans to https://ingest.us1.signalfx.com/v1/trace\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Setting cluster:SFX-WORKSHOP property on host:PH-k3s dimension\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=1 monitorType=cpu time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=2 monitorType=filesystems time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=3 monitorType=disk-io time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=4 monitorType=net-io time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=5 monitorType=load time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=6 monitorType=memory time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=7 monitorType=host-metadata time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=8 monitorType=processlist time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=9 monitorType=vmem time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=10 monitorType=kubelet-stats time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=11 monitorType=kubernetes-cluster time=\"2020-03-15T11:30:29Z\" level=info msg=\"Done configuring agent\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Serving internal metrics at localhost:8095\" I0315 11:30:29.922577 1 leaderelection.go:242] attempting to acquire leader lease default/signalfx-agent-leader... I0315 11:30:29.950448 1 leaderelection.go:252] successfully acquired lease default/signalfx-agent-leader time=\"2020-03-15T11:30:29Z\" level=info msg=\"K8s leader is now node ph-k3s\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Starting K8s API resource sync\" In the SignalFx UI, goto INFRASTRUCTURE \u2192 Kubernetes Navigator \u2192 Cluster Map and open the Kubernetes Navigator Cluster Map to ensure metrics are being sent. Validate that your cluster is discovered and shown (In a workshop you can see many more clusters) by searching for [YOUR-INITIALS]-SFX-WORKSHOP : If there are many clusters you can use the dashboard filter to narrow down to your K8s cluster e.g. kubernetes_cluster: [YOUR-INITIALS]-SFX-WORKSHOP or do this by clicking on the blue cross after selecting your cluster with your mouse. To examine the health of your cluster, open the side bar by clicking on the button to open the Metrics side bar. Once it is open, you can use the slider on the side to explore the various charts relevant to your cluster/node: Cpu%, Mem%, Network in & out. Events and Container list.","title":"Step 5: Take the Helm!"},{"location":"archive/central-se-lab/#step-6-start-your-nginx","text":"Still within the k3s shell session, change into the nginx directory cd ~/workshop/k3s/nginx Create the NGINX configmap using the nginx.conf file kubectl create configmap nginxconfig --from-file=nginx.conf Create the NGINX deployment kubectl create -f nginx-deployment.yaml Validate the deployment has been successful and that the NGINX pods are running, it should only take around 20 seconds for the pods to transition into a Running state. More bonus points for using the k9s terminal UI! Input: kubectl get pods Output: NAME READY STATUS RESTARTS AGE signalfx-agent-n7nz2 1/1 Running 0 11m nginx-deployment-f96cf6966-jhmjp 1/1 Running 0 21s nginx-deployment-f96cf6966-459vf 1/1 Running 0 21s nginx-deployment-f96cf6966-vrnfc 1/1 Running 0 21s nginx-deployment-f96cf6966-7z4tm 1/1 Running 0 21s Next we need to expose port 80 (HTTP) Input: kubectl create service nodeport nginx --tcp=80:80 Output: service/nginx created Run kubectl get svc then make a note of the IP address allocated to the NGINX service. Input: kubectl get svc Output: NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.96.0.1 <none> 443/TCP 9m3s nginx NodePort 10.110.36.62 <none> 80:30995/TCP 8s","title":"Step 6: Start your NGINX!"},{"location":"archive/central-se-lab/#step-7-run-a-benchmark-test-to-create-metrics-and-confirm-them-streaming-into-signalfx","text":"Using the NGINX Cluster-IP address reported from Step #6 above, use Apache Benchmark ( ab ) to create some traffic to light up your SignalFx NGINX dashboard. Run this a couple of times to generate some metrics! Input: NGX_ENDPOINT=$(kubectl get svc nginx -o jsonpath='{.spec.clusterIP}') ab -n1000 -c20 http://${NGX_ENDPOINT}/ Output: This is ApacheBench, Version 2.3 <$Revision: 1826891 $> Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking localhost (be patient) Completed 100 requests ... Completed 1000 requests Finished 1000 requests Server Software: nginx/1.17.5 Server Hostname: localhost Server Port: 30995... Validate you are seeing metrics in the UI by going to Dashboards \u2192 NGINX \u2192 NGINX Servers Tip: you can again apply the filter kubernetes_cluster: [YOUR-INITIALS]-SFX-WORKSHOP to focus on only your containers.","title":"Step 7: Run a benchmark test to create metrics and confirm them streaming into SignalFx!"},{"location":"archive/central-se-lab/#cleaning-up","text":"Once you are done with all modules of the workshop and no longer need your instance exit from the Multipass instance you are in and get back to your system command prompt and enter the following to delete the Multipass instance (replace [YOUR-INITIALS] with the ones you used in Step #1.3 ): multipass delete --purge [YOUR-INITIALS]-k3s","title":"Cleaning up"},{"location":"archive/microk8s/","text":"__## Summary of this lab: * Download the workshop and configure Kubernetes ( MicroK8s ) environment. \u2028 * Use the SignalFx Helm chart to install the Smart Agent in MicroK8s. * Deploy a NGINX ReplicaSet into MicroK8s and confirm the auto discovery of your NGINX deployment. * Run a benchmark test to create metrics and confirm them streaming into SignalFX! Step 1: Let\u2019s bake some K8s \u00b6 Install Multipass for your OS - https://multipass.run/. On a Mac you can also install via brew e.g. brew cask install multipass Download the App Dev Workshop master zip file, unzip the file and change into the app-dev-workshop-master directory curl -LO https://github.com/signalfx/app-dev-workshop/archive/master.zip unzip master.zip cd app-dev-workshop-master Launch the Multipass instance which will run Kubernetes. Note: Use [YOUR-INITIALS]-microk8s this is so the value of the instance hostname is unique e.g. rwc-microk8s multipass launch --name [ YOUR-INITIALS ] -microk8s --cloud-init cloud-init/microk8s.yaml --cpus = 4 --mem = 2G Once the instance has been successfully created shell into it. multipass shell [ YOUR-INITIALS ] -microk8s Step 2: I\u2019ve got the key, I\u2019ve got the secret! \u00b6 You will need to obtain your Access Token from the SignalFx UI once Kubernetes is running. You can find your Access Token by clicking on your profile icon on the top right of the SignalFx UI. Then select Organisation Settings \u2192 Access Tokens . Expand the Default token, then click on Show Token to expose your token. Later in the lab you can come back here and click the Copy button which will copy it to your clipboard so you can paste it when you need to provide an access token in the lab. You will also need to obtain the name of the Realm for your SignalFx account. Click on the profile icon again, but this time select 'My Profile'. The Ream can be found in the middle of the page within the Organizations section. In this example it is us1. Step 3: Take the Helm! \u00b6 Install the agent using the SignalFx Helm chart. Firstly, add the SignalFx Helm chart repository to Helm. helm repo add signalfx https://dl.signalfx.com/helm-repo Ensure the latest state of the repository helm repo update Create the following variables to use in the proceeding helm install command: export ACCESS_TOKEN=<token from Step 2> export REALM=<realm from Step 2> export INITIALS=<your initials e.g. GH> export VERSION=<latest Smart Agent version e.g. 5.0.4> Install the Smart Agent chart with the following configuration values for the chart. helm install --set signalFxAccessToken=$ACCESS_TOKEN --set clusterName=APP-DEV-WORKSHOP --set kubernetesClusterName=$INITIALS-AD-WORKSHOP --set agentVersion=$VERSION --set signalFxRealm=$REALM --set traceEndpointUrl=https://ingest.$REALM.signalfx.com/v2/trace signalfx-agent signalfx/signalfx-agent -f workshop/microk8s/values.yaml You can monitor the progress of the deployment by running kubectl get pods which should typically report a new pod is up and running after about 30 seconds. Ensure the status is reported as Running before continuing. Input: kubectl get pods Output: NAME READY STATUS RESTARTS AGE signalfx-agent-66tvr 1/1 Running 0 7s Ensure there are no errors by tailing the logs from the Smart Agent Pod. Output should look similar to the log output shown below. Use the label set by the helm install to tail logs (You will need to press Ctrl-C to exit). Or use the installed k9s terminal UI for bonus points! Input: kubectl logs -l app=signalfx-agent -f Output: time=\"2020-03-20T11:53:33Z\" level=info msg=\"Starting up agent version 5.0.0\" time=\"2020-03-20T11:53:33Z\" level=info msg=\"Watching for config file changes\" time=\"2020-03-20T11:53:33Z\" level=info msg=\"New config loaded\" time=\"2020-03-20T11:53:33Z\" level=info msg=\"Using log level info\" time=\"2020-03-20T11:53:33Z\" level=info msg=\"Fetching host id dimensions\" time=\"2020-03-20T11:53:33Z\" level=info msg=\"Trying to get fully qualified hostname\" time=\"2020-03-20T11:53:33Z\" level=info msg=\"Using hostname rwc-microk8s\" time=\"2020-03-20T11:53:34Z\" level=info msg=\"Using host id dimensions map[host:rwc-microk8s kubernetes_node_uid:4350df0d-1849-45ce-b805-d04089f36dd1]\" time=\"2020-03-20T11:53:34Z\" level=info msg=\"Sending datapoints to https://ingest.us0.signalfx.com/v2/datapoint\" time=\"2020-03-20T11:53:34Z\" level=info msg=\"Sending events to https://ingest.us0.signalfx.com/v2/event\" time=\"2020-03-20T11:53:34Z\" level=info msg=\"Sending trace spans to https://ingest.us0.signalfx.com/v1/trace\" time=\"2020-03-20T11:53:34Z\" level=info msg=\"Setting cluster:APP-DEV-WORKSHOP property on host:rwc-microk8s dimension\" In the SignalFx UI, got to Dashboards \u2192 Kubernetes and open the K8s Clusters dashboard to ensure metrics are being sent. (Might take up to 5 minutes for these charts to update as they are 5 minute resolution charts). Use the dashboard filter to narrow down to your K8s cluster e.g. kubernetes_cluster: [YOUR-INITIALS]-SFX-WORKSHOP Step 4: Start your NGINX! \u00b6 Still within the Microk8s shell session, change into the nginx directory cd ~/workshop/k3s/nginx Create the NGINX configmap using the nginx.conf file kubectl create configmap nginxconfig --from-file=nginx.conf Create the NGINX deployment kubectl create -f nginx-deployment.yaml Validate the deployment has been successful and that the NGINX pods are running, it should only take around 20 seconds for the pods to transition into a Running state. More bonus points for using the k9s terminal UI! Input: kubectl get pods Output: NAME READY STATUS RESTARTS AGE signalfx-agent-n7nz2 1/1 Running 0 11m nginx-deployment-f96cf6966-jhmjp 1/1 Running 0 21s nginx-deployment-f96cf6966-459vf 1/1 Running 0 21s nginx-deployment-f96cf6966-vrnfc 1/1 Running 0 21s nginx-deployment-f96cf6966-7z4tm 1/1 Running 0 21s Next we need to expose port 80 (HTTP) Input: kubectl create service nodeport nginx --tcp=80:80 Output: service/nginx created Run kubectl get svc then make a note of the IP address allocated to NGINX. Input: kubectl get svc Output: NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.96.0.1 <none> 443/TCP 9m3s nginx NodePort 10.110.36.62 <none> 80:30995/TCP 8s Using the IP address reported from Step #7 above, use Apache Benchmark (ab) to create some traffic to light up your SignalFx NGINX dashboard. Run this a couple of times! Input: ab -n1000 -c20 http://10.110.36.62/ Output: This is ApacheBench, Version 2.3 <$Revision: 1826891 $> Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking localhost (be patient) Completed 100 requests ... Completed 1000 requests Finished 1000 requests Server Software: nginx/1.17.5 Server Hostname: localhost Server Port: 30995... Validate you are seeing metrics in the UI by going to Dashboards \u2192 NGINX \u2192 NGINX Servers Tip: you can again apply the filter kubernetes_cluster: [YOUR-INITIALS]-SFX-WORKSHOP to focus on only your containers. Once you are finished please proceed to Lab 5: Monitoring as Code with Detectors","title":"Microk8s"},{"location":"archive/microk8s/#step-1-lets-bake-some-k8s","text":"Install Multipass for your OS - https://multipass.run/. On a Mac you can also install via brew e.g. brew cask install multipass Download the App Dev Workshop master zip file, unzip the file and change into the app-dev-workshop-master directory curl -LO https://github.com/signalfx/app-dev-workshop/archive/master.zip unzip master.zip cd app-dev-workshop-master Launch the Multipass instance which will run Kubernetes. Note: Use [YOUR-INITIALS]-microk8s this is so the value of the instance hostname is unique e.g. rwc-microk8s multipass launch --name [ YOUR-INITIALS ] -microk8s --cloud-init cloud-init/microk8s.yaml --cpus = 4 --mem = 2G Once the instance has been successfully created shell into it. multipass shell [ YOUR-INITIALS ] -microk8s","title":"Step 1: Let\u2019s bake some K8s"},{"location":"archive/microk8s/#step-2-ive-got-the-key-ive-got-the-secret","text":"You will need to obtain your Access Token from the SignalFx UI once Kubernetes is running. You can find your Access Token by clicking on your profile icon on the top right of the SignalFx UI. Then select Organisation Settings \u2192 Access Tokens . Expand the Default token, then click on Show Token to expose your token. Later in the lab you can come back here and click the Copy button which will copy it to your clipboard so you can paste it when you need to provide an access token in the lab. You will also need to obtain the name of the Realm for your SignalFx account. Click on the profile icon again, but this time select 'My Profile'. The Ream can be found in the middle of the page within the Organizations section. In this example it is us1.","title":"Step 2: I\u2019ve got the key, I\u2019ve got the secret!"},{"location":"archive/microk8s/#step-3-take-the-helm","text":"Install the agent using the SignalFx Helm chart. Firstly, add the SignalFx Helm chart repository to Helm. helm repo add signalfx https://dl.signalfx.com/helm-repo Ensure the latest state of the repository helm repo update Create the following variables to use in the proceeding helm install command: export ACCESS_TOKEN=<token from Step 2> export REALM=<realm from Step 2> export INITIALS=<your initials e.g. GH> export VERSION=<latest Smart Agent version e.g. 5.0.4> Install the Smart Agent chart with the following configuration values for the chart. helm install --set signalFxAccessToken=$ACCESS_TOKEN --set clusterName=APP-DEV-WORKSHOP --set kubernetesClusterName=$INITIALS-AD-WORKSHOP --set agentVersion=$VERSION --set signalFxRealm=$REALM --set traceEndpointUrl=https://ingest.$REALM.signalfx.com/v2/trace signalfx-agent signalfx/signalfx-agent -f workshop/microk8s/values.yaml You can monitor the progress of the deployment by running kubectl get pods which should typically report a new pod is up and running after about 30 seconds. Ensure the status is reported as Running before continuing. Input: kubectl get pods Output: NAME READY STATUS RESTARTS AGE signalfx-agent-66tvr 1/1 Running 0 7s Ensure there are no errors by tailing the logs from the Smart Agent Pod. Output should look similar to the log output shown below. Use the label set by the helm install to tail logs (You will need to press Ctrl-C to exit). Or use the installed k9s terminal UI for bonus points! Input: kubectl logs -l app=signalfx-agent -f Output: time=\"2020-03-20T11:53:33Z\" level=info msg=\"Starting up agent version 5.0.0\" time=\"2020-03-20T11:53:33Z\" level=info msg=\"Watching for config file changes\" time=\"2020-03-20T11:53:33Z\" level=info msg=\"New config loaded\" time=\"2020-03-20T11:53:33Z\" level=info msg=\"Using log level info\" time=\"2020-03-20T11:53:33Z\" level=info msg=\"Fetching host id dimensions\" time=\"2020-03-20T11:53:33Z\" level=info msg=\"Trying to get fully qualified hostname\" time=\"2020-03-20T11:53:33Z\" level=info msg=\"Using hostname rwc-microk8s\" time=\"2020-03-20T11:53:34Z\" level=info msg=\"Using host id dimensions map[host:rwc-microk8s kubernetes_node_uid:4350df0d-1849-45ce-b805-d04089f36dd1]\" time=\"2020-03-20T11:53:34Z\" level=info msg=\"Sending datapoints to https://ingest.us0.signalfx.com/v2/datapoint\" time=\"2020-03-20T11:53:34Z\" level=info msg=\"Sending events to https://ingest.us0.signalfx.com/v2/event\" time=\"2020-03-20T11:53:34Z\" level=info msg=\"Sending trace spans to https://ingest.us0.signalfx.com/v1/trace\" time=\"2020-03-20T11:53:34Z\" level=info msg=\"Setting cluster:APP-DEV-WORKSHOP property on host:rwc-microk8s dimension\" In the SignalFx UI, got to Dashboards \u2192 Kubernetes and open the K8s Clusters dashboard to ensure metrics are being sent. (Might take up to 5 minutes for these charts to update as they are 5 minute resolution charts). Use the dashboard filter to narrow down to your K8s cluster e.g. kubernetes_cluster: [YOUR-INITIALS]-SFX-WORKSHOP","title":"Step 3: Take the Helm!"},{"location":"archive/microk8s/#step-4-start-your-nginx","text":"Still within the Microk8s shell session, change into the nginx directory cd ~/workshop/k3s/nginx Create the NGINX configmap using the nginx.conf file kubectl create configmap nginxconfig --from-file=nginx.conf Create the NGINX deployment kubectl create -f nginx-deployment.yaml Validate the deployment has been successful and that the NGINX pods are running, it should only take around 20 seconds for the pods to transition into a Running state. More bonus points for using the k9s terminal UI! Input: kubectl get pods Output: NAME READY STATUS RESTARTS AGE signalfx-agent-n7nz2 1/1 Running 0 11m nginx-deployment-f96cf6966-jhmjp 1/1 Running 0 21s nginx-deployment-f96cf6966-459vf 1/1 Running 0 21s nginx-deployment-f96cf6966-vrnfc 1/1 Running 0 21s nginx-deployment-f96cf6966-7z4tm 1/1 Running 0 21s Next we need to expose port 80 (HTTP) Input: kubectl create service nodeport nginx --tcp=80:80 Output: service/nginx created Run kubectl get svc then make a note of the IP address allocated to NGINX. Input: kubectl get svc Output: NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.96.0.1 <none> 443/TCP 9m3s nginx NodePort 10.110.36.62 <none> 80:30995/TCP 8s Using the IP address reported from Step #7 above, use Apache Benchmark (ab) to create some traffic to light up your SignalFx NGINX dashboard. Run this a couple of times! Input: ab -n1000 -c20 http://10.110.36.62/ Output: This is ApacheBench, Version 2.3 <$Revision: 1826891 $> Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking localhost (be patient) Completed 100 requests ... Completed 1000 requests Finished 1000 requests Server Software: nginx/1.17.5 Server Hostname: localhost Server Port: 30995... Validate you are seeing metrics in the UI by going to Dashboards \u2192 NGINX \u2192 NGINX Servers Tip: you can again apply the filter kubernetes_cluster: [YOUR-INITIALS]-SFX-WORKSHOP to focus on only your containers. Once you are finished please proceed to Lab 5: Monitoring as Code with Detectors","title":"Step 4: Start your NGINX!"},{"location":"module-support/cleanup/","text":"1. Removing the Multipass instance \u00b6 Once you have finished with this workshop exit from the Multipass instance you are in and get back to your system command prompt and enter the following to delete the Multipass instance, replace {YOUR_INITIALS} with the ones you used in 4. Running the Smart Agent in Kubernetes (K3s) : multipass delete --purge {YOUR_INITIALS}-k3s Note If you are using a workshop instance on EC2 please ignore this and just terminate your instance.","title":"<b>Post Workshop Clean Up!</b>"},{"location":"module-support/cleanup/#1-removing-the-multipass-instance","text":"Once you have finished with this workshop exit from the Multipass instance you are in and get back to your system command prompt and enter the following to delete the Multipass instance, replace {YOUR_INITIALS} with the ones you used in 4. Running the Smart Agent in Kubernetes (K3s) : multipass delete --purge {YOUR_INITIALS}-k3s Note If you are using a workshop instance on EC2 please ignore this and just terminate your instance.","title":"1. Removing the Multipass instance"},{"location":"module-support/ecs-setup/","text":"Summary of this wiki page: \u00b6 Use AWS EC2 to deploy a Ubuntu server prebuild for the work shop. Explain the extra steps needed to run the workshop on this instance 1. Starting the workshop instance \u00b6 Login into your AWS account using the AWS console and go to the EC2 service page. As the Workshop Instance currently only resides in AWS Frankfurt please change your region to Frankfurt by changing the drop-down list at the top of the screen Click the blue launch instance button to go to the instance selection page and search for the workshop by typing the name App-Dev-Workshop into the search box. You should find get 1 result in the Community AMI's, and click on the on the Result link: This should bring you to the choose and instance type screen. Here you can select the type of machine you wish to run the workshop on, we do recommend to use at least a t2 medium with at least two cpu and 4 GB of memory. Once you made your selection press Review and Launch button. Validate that the information on the review page looks like what is shown below and hit the Launch button to start the workshop instance. You will be presented with a dialog box asking to provide credentials, there is no need to provide ssh keys so you can select the option Proceed without a key pair , then tick the acknowledge box to confirm you willing to pay AWS for this then hit the blue LAUNCH INSTANCE button On the left side of you screen click under the INSTANCES heading on the instances link to see your instance being deployed. Once the deployment is complete, copy the Public IP address from the Description panel at the bottom. 2. Connecting to your workshop instance \u00b6 Start a command line session on your PC (terminal on a Mac, or putty on Windows for example) Login to your instance by starting an ssh session. (replace [IP-ADRESS] with the IP address copied at step 6 from the previous section: ssh ubuntu@[IP-ADRESS] You will usually be asked to confirm that you wish to connect via ssh to the server, type yes to confirm, followed by a query for a password. The password will be provided by the facilitator of the workshop . Once your logged in successfully you should see the APP-DEV logo confirming that you are indeed using a workshop instance. To make sure you can run the instruction as described in the Workshop pages please enter the command sudo -s to elevate your permissions, your prompt should change from ubuntu@[Servername] to root@[Servername] Next type ls to confirm there is a workshop folder available to you on the machine. If everything matches the screen shot above, your ready to begin your workshop","title":"Ecs setup"},{"location":"module-support/ecs-setup/#summary-of-this-wiki-page","text":"Use AWS EC2 to deploy a Ubuntu server prebuild for the work shop. Explain the extra steps needed to run the workshop on this instance","title":"Summary of this wiki page:"},{"location":"module-support/ecs-setup/#1-starting-the-workshop-instance","text":"Login into your AWS account using the AWS console and go to the EC2 service page. As the Workshop Instance currently only resides in AWS Frankfurt please change your region to Frankfurt by changing the drop-down list at the top of the screen Click the blue launch instance button to go to the instance selection page and search for the workshop by typing the name App-Dev-Workshop into the search box. You should find get 1 result in the Community AMI's, and click on the on the Result link: This should bring you to the choose and instance type screen. Here you can select the type of machine you wish to run the workshop on, we do recommend to use at least a t2 medium with at least two cpu and 4 GB of memory. Once you made your selection press Review and Launch button. Validate that the information on the review page looks like what is shown below and hit the Launch button to start the workshop instance. You will be presented with a dialog box asking to provide credentials, there is no need to provide ssh keys so you can select the option Proceed without a key pair , then tick the acknowledge box to confirm you willing to pay AWS for this then hit the blue LAUNCH INSTANCE button On the left side of you screen click under the INSTANCES heading on the instances link to see your instance being deployed. Once the deployment is complete, copy the Public IP address from the Description panel at the bottom.","title":"1. Starting the workshop instance"},{"location":"module-support/ecs-setup/#2-connecting-to-your-workshop-instance","text":"Start a command line session on your PC (terminal on a Mac, or putty on Windows for example) Login to your instance by starting an ssh session. (replace [IP-ADRESS] with the IP address copied at step 6 from the previous section: ssh ubuntu@[IP-ADRESS] You will usually be asked to confirm that you wish to connect via ssh to the server, type yes to confirm, followed by a query for a password. The password will be provided by the facilitator of the workshop . Once your logged in successfully you should see the APP-DEV logo confirming that you are indeed using a workshop instance. To make sure you can run the instruction as described in the Workshop pages please enter the command sudo -s to elevate your permissions, your prompt should change from ubuntu@[Servername] to root@[Servername] Next type ls to confirm there is a workshop folder available to you on the machine. If everything matches the screen shot above, your ready to begin your workshop","title":"2. Connecting to your workshop instance"},{"location":"module1/dashboards/","text":"Lab Summary \u00b6 Introduction to the SignalFx Dashboards and charts Editing and creating charts Filtering and analytical functions Using formulas Introduction to SignalFlow 1. Introduction to the SignalFx environment \u00b6 Logon to the SignalFx organization you have been invited to Hover over DASHBOARDS in the top menu, and then click on All Dashboards at the bottom and you will see a number of prebuilt dashboards If you are getting metrics already through cloud API integration or the Smart Agent you will see relevant dashboards for the services you are getting metrics for in SignalFx. Among the dashboards there you will see a Dashboard group called Sample Data. This group exists by default in all SignalFx accounts. Let's take a closer look at it. 2. Inspecting the Sample Data \u00b6 In the All Dashboards window expand the Sample Data dashboard group by clicking on it, and then click on Intro to SignalFx dashboard You will see a selection of sample charts. To learn more about charts you can click on the Intro to SignalFx, Part 1, 2 and Part 3 dashboards and read the description of the charts and its metrics. Let's take a look at the Sample charts. Click on the Sample charts dashboard name: In the SAMPLE CHARTS dashboard you see a selection of charts that shows the different styles, colours and formats you can apply to the different visualisations available. 3. Editing charts \u00b6 Click on the three dots (...) on the Latency histogram chart (circled in the screenshot above) and then on Open. You will see the plot options, current plot and signal (metric) for the Latency histogram chart. Click on the different chart type icons to explore each of the visualizations See how the chart changes. You can use different ways to visualize your metrics - you choose which chart type fits best for the visualization you want to have. For more info on the different chart types see: Choosing a chart type Click on Line chart type and you will see the line plot. In the PLOT EDITOR tab under Signal you see the metric demo.trans.latency we are currently plotting. 4. Creating a new chart \u00b6 Let's now create a new chart and save it in a new dashboard! Click on the plus icon and from the drop down, click on Chart You will now see a chart template like the following. Let's enter a metric to plot. We are going to use the metric demo.trans.latency In the PLOT EDITOR tab under Signal enter demo.trans.latency You will instantly see a number of Line plots, like below. The number 18 ts indicates that we are plotting 18 metric time series in the chart. Click on the *DATA TABLE tab You see now 18 rows, each representing a metics time series with a number of columns. If you swipe over the plot horizontally you will see the metrics in these columns at different times. In the demo_datacenter column you see that there are two data centers, Paris and Tokyo, for which we are getting metrics. 5. Filtering and Analytics \u00b6 Let's now select the Paris datacenter to do some analytics - for that we will use a filter. Let's go back to the PLOT EDITOR tab Click on Add filter, wait until it automatically populates, choose demo_datacenter , and then Paris In the F(x) column, add the analytic function Percentile:Aggregation, and leave the value to 95 (click outside to confirm) For info on the Percentile function and the other functions see Analytics reference 6. Using Timeshift analytical function \u00b6 Let's now compare with older metrics. Click on ... and then on Clone in the dropdown to clone that Signal You will see a new row identical to A, called B, both visible and plotted For the B Signal, In F(x) add the analytic function Timeshift and enter 7d (7 days = 1 week), and click outside to confirm Click on the cogwheel on the far right, and choose a color, say pink, from Plot Color, to change color for the plot of B Click on Close Click on the field next to Time and choose Past Day from the dropdown We now see datapoint for A for the last day (rolling) as a blue plot, and 7 days ago in pink Click on Area chart icon We now have a better view of our two plots 7. Using formulas \u00b6 Let's now plot the difference of all metric values for a day with 7 days between Click on Enter Formula then enter A-B (A minus B) and hide (deselect) all Signals using the eye, except C We now see only the difference of all metric values of A and B being plotted. We see that we have some negative values on the plot because a metric value of B has some times larger value than the metric value of A at that time. If you click on DATA TABLE you can swipe horizontally along the X axis to see the metric values at different times. Let's apply another function to get the values of C to positive values. By doing so we will the difference between the metric values for a period of 24 hours with 7 days between. This difference can be used to see an alarming trend if we consider last week to be a baseline (the bigger the number - the more we deviate from the baseline) - but mainly we do this for you to get a bit more training on using functions... In the PLOT EDITOR for C click on Add Analytics and choose Absolute Value You will see the C plot now having only positive values 8. Overlaying metrics and events \u00b6 Let's now overlay metrics and events to our initial plot to see if there is any correlation with high latency To discover and add new metrics to the chart from the ones that are being sent to SignalFx already, click on Browse on the bottom of the screen Then, in the Metrics sidebar on the right, enter \"demo\" and click on the search icon to search. Observe that the Find Metrics option is pre selected The metrics search is showing 3 metrics with demo in the name Select demo.trans.count and click on the Add Plot green button Click on the blue eye icon next to C to hide that Signal, and on the greyed eye icon for Signal A to show it Filter the Paris datacenter (see step 12 above if you need help with this) and function percentile 95 (see step 13 above) and enter 1h in the Time frame for the entire chart We see that there is a correlation between latency and number of transactions! Hooray! Likewise we could check Find Events and find events like deployment events etc. to correlate with. Click on the icon to collapse the Metrics sidebar 9. Introduction to SignalFlow \u00b6 Let's take a look at SignalFlow - the analytics language of SignalFx that can be used to setup monitoring as code. Click on View SignalFlow You will see the SignalFlow code that composes the chart we were working on SignalFlow is the analytics language of SignalFx. Between the many benefits it provides, it can be used to setup monitoring as code. In the next lab we will see it being used in action. For more info on SignalFlow see Getting started with SignalFlow Click on View Builder to go back to the UI Signal builder 10. Adding charts to dashboards \u00b6 Let's now save our chart. Click on Save as... and enter a name for your chart, use your initials like <your initials>'s Latency Chart and click OK In the next window, find your email address in the list and select it, then click Ok You will immediately be transported to the dashboard created under your selected group (make sure the group name on the top left is your email) Last but not least, change the dashboard's name, by clicking the ... icon on the top right and selecting Dashboard Info Enter a new name for your dashboard and click on Done Congratulations! You have created your first chart and dashboard! Use the Next link in the footer below to continue the workshop","title":"Working with Dashboards, Charts and Metrics"},{"location":"module1/dashboards/#lab-summary","text":"Introduction to the SignalFx Dashboards and charts Editing and creating charts Filtering and analytical functions Using formulas Introduction to SignalFlow","title":"Lab Summary"},{"location":"module1/dashboards/#1-introduction-to-the-signalfx-environment","text":"Logon to the SignalFx organization you have been invited to Hover over DASHBOARDS in the top menu, and then click on All Dashboards at the bottom and you will see a number of prebuilt dashboards If you are getting metrics already through cloud API integration or the Smart Agent you will see relevant dashboards for the services you are getting metrics for in SignalFx. Among the dashboards there you will see a Dashboard group called Sample Data. This group exists by default in all SignalFx accounts. Let's take a closer look at it.","title":"1. Introduction to the SignalFx environment"},{"location":"module1/dashboards/#2-inspecting-the-sample-data","text":"In the All Dashboards window expand the Sample Data dashboard group by clicking on it, and then click on Intro to SignalFx dashboard You will see a selection of sample charts. To learn more about charts you can click on the Intro to SignalFx, Part 1, 2 and Part 3 dashboards and read the description of the charts and its metrics. Let's take a look at the Sample charts. Click on the Sample charts dashboard name: In the SAMPLE CHARTS dashboard you see a selection of charts that shows the different styles, colours and formats you can apply to the different visualisations available.","title":"2. Inspecting the Sample Data"},{"location":"module1/dashboards/#3-editing-charts","text":"Click on the three dots (...) on the Latency histogram chart (circled in the screenshot above) and then on Open. You will see the plot options, current plot and signal (metric) for the Latency histogram chart. Click on the different chart type icons to explore each of the visualizations See how the chart changes. You can use different ways to visualize your metrics - you choose which chart type fits best for the visualization you want to have. For more info on the different chart types see: Choosing a chart type Click on Line chart type and you will see the line plot. In the PLOT EDITOR tab under Signal you see the metric demo.trans.latency we are currently plotting.","title":"3. Editing charts"},{"location":"module1/dashboards/#4-creating-a-new-chart","text":"Let's now create a new chart and save it in a new dashboard! Click on the plus icon and from the drop down, click on Chart You will now see a chart template like the following. Let's enter a metric to plot. We are going to use the metric demo.trans.latency In the PLOT EDITOR tab under Signal enter demo.trans.latency You will instantly see a number of Line plots, like below. The number 18 ts indicates that we are plotting 18 metric time series in the chart. Click on the *DATA TABLE tab You see now 18 rows, each representing a metics time series with a number of columns. If you swipe over the plot horizontally you will see the metrics in these columns at different times. In the demo_datacenter column you see that there are two data centers, Paris and Tokyo, for which we are getting metrics.","title":"4. Creating a new chart"},{"location":"module1/dashboards/#5-filtering-and-analytics","text":"Let's now select the Paris datacenter to do some analytics - for that we will use a filter. Let's go back to the PLOT EDITOR tab Click on Add filter, wait until it automatically populates, choose demo_datacenter , and then Paris In the F(x) column, add the analytic function Percentile:Aggregation, and leave the value to 95 (click outside to confirm) For info on the Percentile function and the other functions see Analytics reference","title":"5. Filtering and Analytics"},{"location":"module1/dashboards/#6-using-timeshift-analytical-function","text":"Let's now compare with older metrics. Click on ... and then on Clone in the dropdown to clone that Signal You will see a new row identical to A, called B, both visible and plotted For the B Signal, In F(x) add the analytic function Timeshift and enter 7d (7 days = 1 week), and click outside to confirm Click on the cogwheel on the far right, and choose a color, say pink, from Plot Color, to change color for the plot of B Click on Close Click on the field next to Time and choose Past Day from the dropdown We now see datapoint for A for the last day (rolling) as a blue plot, and 7 days ago in pink Click on Area chart icon We now have a better view of our two plots","title":"6. Using Timeshift analytical function"},{"location":"module1/dashboards/#7-using-formulas","text":"Let's now plot the difference of all metric values for a day with 7 days between Click on Enter Formula then enter A-B (A minus B) and hide (deselect) all Signals using the eye, except C We now see only the difference of all metric values of A and B being plotted. We see that we have some negative values on the plot because a metric value of B has some times larger value than the metric value of A at that time. If you click on DATA TABLE you can swipe horizontally along the X axis to see the metric values at different times. Let's apply another function to get the values of C to positive values. By doing so we will the difference between the metric values for a period of 24 hours with 7 days between. This difference can be used to see an alarming trend if we consider last week to be a baseline (the bigger the number - the more we deviate from the baseline) - but mainly we do this for you to get a bit more training on using functions... In the PLOT EDITOR for C click on Add Analytics and choose Absolute Value You will see the C plot now having only positive values","title":"7. Using formulas"},{"location":"module1/dashboards/#8-overlaying-metrics-and-events","text":"Let's now overlay metrics and events to our initial plot to see if there is any correlation with high latency To discover and add new metrics to the chart from the ones that are being sent to SignalFx already, click on Browse on the bottom of the screen Then, in the Metrics sidebar on the right, enter \"demo\" and click on the search icon to search. Observe that the Find Metrics option is pre selected The metrics search is showing 3 metrics with demo in the name Select demo.trans.count and click on the Add Plot green button Click on the blue eye icon next to C to hide that Signal, and on the greyed eye icon for Signal A to show it Filter the Paris datacenter (see step 12 above if you need help with this) and function percentile 95 (see step 13 above) and enter 1h in the Time frame for the entire chart We see that there is a correlation between latency and number of transactions! Hooray! Likewise we could check Find Events and find events like deployment events etc. to correlate with. Click on the icon to collapse the Metrics sidebar","title":"8. Overlaying metrics and events"},{"location":"module1/dashboards/#9-introduction-to-signalflow","text":"Let's take a look at SignalFlow - the analytics language of SignalFx that can be used to setup monitoring as code. Click on View SignalFlow You will see the SignalFlow code that composes the chart we were working on SignalFlow is the analytics language of SignalFx. Between the many benefits it provides, it can be used to setup monitoring as code. In the next lab we will see it being used in action. For more info on SignalFlow see Getting started with SignalFlow Click on View Builder to go back to the UI Signal builder","title":"9. Introduction to SignalFlow"},{"location":"module1/dashboards/#10-adding-charts-to-dashboards","text":"Let's now save our chart. Click on Save as... and enter a name for your chart, use your initials like <your initials>'s Latency Chart and click OK In the next window, find your email address in the list and select it, then click Ok You will immediately be transported to the dashboard created under your selected group (make sure the group name on the top left is your email) Last but not least, change the dashboard's name, by clicking the ... icon on the top right and selecting Dashboard Info Enter a new name for your dashboard and click on Done Congratulations! You have created your first chart and dashboard! Use the Next link in the footer below to continue the workshop","title":"10. Adding charts to dashboards"},{"location":"module2/detectors/","text":"Lab Summary \u00b6 Create a Detector from one of you charts 1. Create a Detector from one of your charts \u00b6 In DASHBOARDS click on your dashboard group (the one with your email address) and then on the dashboard name where the chart you created in the previous lab resides. OR Search for your previously created dashboard's name, and click on that dashboard's name in the results. Once you see the chart... Click on the bell icon on your chart and on New Detector From Chart - ADD YOUR INITIALS TO THE NAME (see next step). We are going to create a new alert detector from the chart. Important In the window that opens, add your initials in front of the proposed text, and click on Create Alert Rule. It should be something like this: LI's Latency Chart Detector. In the detector window, inside Alert signal, the signal we will alert on is marked with a bell. The bell in the 'Alert on' column indicates which Signal is being used to generate the alert. Click on Proceed to Alert Condition. 2. Setting Alert condition \u00b6 In Alert Condition, click on Static Threshold and then on Proceed to Alert Settings. In Alert Settings, enter the value \"290\" in the Threshold box and change Time on top right to past day. 3. Alert pre-flight check \u00b6 Once you set an alert condition, SignalFx shows how many alerts you would get based on the current settings, and in the timeframe set on the upper right corner - in this case, the past day. Immediately, the platform will start analyzing the signals with the current settings, and perform something we call a Pre-flight Check, This enables me to test the alert conditions using the historical data in the platform, to ensure the settings are logical and will not inadvertently generate an alert storm, removing the guess work from configuring alerts in a simple but very powerful way, only available using SignalFx. We can see that based on the current settings, the amount of alerts we would\u2019ve received in 1 day would've been around 18. To read more about Detector Previews, please visit this link Setting up detectors 4. Configuring the alert message \u00b6 Click on Proceed to Alert Message. In Severity choose Major Click on Proceed to Alert Recipients Click on Add Recipient and then on your email displayed as the first option That's the same as entering that email address OR you can enter another email address by clicking on E-mail... That's just one example of the many Notification Services SignalFx has available You can check this out by going to the INTEGRATIONS tab of the top menu, and see Notification Services 5. Activating the alert \u00b6 Click on Proceed to Alert Activation In Activate...click on Activate Alert Rule If you want to get alerts quicker you can click back on Alert Settings and lower the value from 290 to say 280. If you change the Time to 1h you can see how many alerts you will be getting with the threshold you have chosen based on the metics from the last 1 hour. Hover over ALERTS in the top menu and then click on Detectors You will see you alert detector listed here. Congrats! You have created your first alert detector and activated it! Use the Next link in the footer below to continue the workshop","title":"Working with Detectors"},{"location":"module2/detectors/#lab-summary","text":"Create a Detector from one of you charts","title":"Lab Summary"},{"location":"module2/detectors/#1-create-a-detector-from-one-of-your-charts","text":"In DASHBOARDS click on your dashboard group (the one with your email address) and then on the dashboard name where the chart you created in the previous lab resides. OR Search for your previously created dashboard's name, and click on that dashboard's name in the results. Once you see the chart... Click on the bell icon on your chart and on New Detector From Chart - ADD YOUR INITIALS TO THE NAME (see next step). We are going to create a new alert detector from the chart. Important In the window that opens, add your initials in front of the proposed text, and click on Create Alert Rule. It should be something like this: LI's Latency Chart Detector. In the detector window, inside Alert signal, the signal we will alert on is marked with a bell. The bell in the 'Alert on' column indicates which Signal is being used to generate the alert. Click on Proceed to Alert Condition.","title":"1. Create a Detector from one of your charts"},{"location":"module2/detectors/#2-setting-alert-condition","text":"In Alert Condition, click on Static Threshold and then on Proceed to Alert Settings. In Alert Settings, enter the value \"290\" in the Threshold box and change Time on top right to past day.","title":"2. Setting Alert condition"},{"location":"module2/detectors/#3-alert-pre-flight-check","text":"Once you set an alert condition, SignalFx shows how many alerts you would get based on the current settings, and in the timeframe set on the upper right corner - in this case, the past day. Immediately, the platform will start analyzing the signals with the current settings, and perform something we call a Pre-flight Check, This enables me to test the alert conditions using the historical data in the platform, to ensure the settings are logical and will not inadvertently generate an alert storm, removing the guess work from configuring alerts in a simple but very powerful way, only available using SignalFx. We can see that based on the current settings, the amount of alerts we would\u2019ve received in 1 day would've been around 18. To read more about Detector Previews, please visit this link Setting up detectors","title":"3. Alert pre-flight check"},{"location":"module2/detectors/#4-configuring-the-alert-message","text":"Click on Proceed to Alert Message. In Severity choose Major Click on Proceed to Alert Recipients Click on Add Recipient and then on your email displayed as the first option That's the same as entering that email address OR you can enter another email address by clicking on E-mail... That's just one example of the many Notification Services SignalFx has available You can check this out by going to the INTEGRATIONS tab of the top menu, and see Notification Services","title":"4. Configuring the alert message"},{"location":"module2/detectors/#5-activating-the-alert","text":"Click on Proceed to Alert Activation In Activate...click on Activate Alert Rule If you want to get alerts quicker you can click back on Alert Settings and lower the value from 290 to say 280. If you change the Time to 1h you can see how many alerts you will be getting with the threshold you have chosen based on the metics from the last 1 hour. Hover over ALERTS in the top menu and then click on Detectors You will see you alert detector listed here. Congrats! You have created your first alert detector and activated it! Use the Next link in the footer below to continue the workshop","title":"5. Activating the alert"},{"location":"module2/muting/","text":"Lab Summary \u00b6 Learn how to configure how to mute Alerts 1. Learn how to configure muting your alerts \u00b6 There are times when you, for a period of time, don't want to be disturbed by notifications for some non critical alerts. For that you can use muting rules in SignalFx. Let's create one! Hover over ALERTS in the menu and click on Detectors If you created an alert detector in \"Working with Detectors\" you can click on the three dots ... on the far right and click on Create Muting Rule... In the Muting Rule window check Mute Indefinitely and enter a reason. This will mute the rule permanently until you come back here and uncheck this box. Click Next and in the new modal window confirm the muting rule setup Click on Mute Indefinitely to confirm. You won't be receiving any email notifications from you alert detector until you resume notifications again. 2. Resuming notifications \u00b6 To Resume notifications, hover over ALERTS in the top menu and click on Muting Rules. You will see the name of the detector you muted notifications for under Detector. Click on the thee dots ... on the far right Click on Resume Notifications Click on Resume to confirm and resume notifications for this detector Congratulations! You have now resumed your alert notifications! Use the Next link in the footer below to continue the workshop","title":"Working with Muting Rules"},{"location":"module2/muting/#lab-summary","text":"Learn how to configure how to mute Alerts","title":"Lab Summary"},{"location":"module2/muting/#1-learn-how-to-configure-muting-your-alerts","text":"There are times when you, for a period of time, don't want to be disturbed by notifications for some non critical alerts. For that you can use muting rules in SignalFx. Let's create one! Hover over ALERTS in the menu and click on Detectors If you created an alert detector in \"Working with Detectors\" you can click on the three dots ... on the far right and click on Create Muting Rule... In the Muting Rule window check Mute Indefinitely and enter a reason. This will mute the rule permanently until you come back here and uncheck this box. Click Next and in the new modal window confirm the muting rule setup Click on Mute Indefinitely to confirm. You won't be receiving any email notifications from you alert detector until you resume notifications again.","title":"1. Learn how to configure muting your alerts"},{"location":"module2/muting/#2-resuming-notifications","text":"To Resume notifications, hover over ALERTS in the top menu and click on Muting Rules. You will see the name of the detector you muted notifications for under Detector. Click on the thee dots ... on the far right Click on Resume Notifications Click on Resume to confirm and resume notifications for this detector Congratulations! You have now resumed your alert notifications! Use the Next link in the footer below to continue the workshop","title":"2. Resuming notifications"},{"location":"module3/k3s/","text":"Lab Summary \u00b6 Download the workshop and configure Kubernetes ( K3s ) environment. Use the SignalFx Helm chart to install the Smart Agent in K3s. Explore Your cluster in the Kubernetes Navigator If you have chosen to run the workshop on a AWS/EC2 instance, please follow instructions given and go to Step 2 . 1. Let\u2019s bake some K8s \u00b6 If you are going to run this localy please install Multipass for your OS. On a Mac you can also install via brew e.g. brew cask install multipass Regardless if you are running this lab locally or use an EC2 instance, download the App Dev Workshop Master Zip file locally or on to the EC2 instance.then proceed to unzip the file, rename it, and change into the workshop directory curl -LO https://github.com/signalfx/app-dev-workshop/archive/master.zip unzip master.zip mv app-dev-workshop-master workshop cd workshop When using an EC2 instance you can now skip to Step 2 Launch the Multipass instance which will run Kubernetes (K3s) Note Use {YOUR_INITIALS}-k3s so that the value of the instance hostname is unique e.g. rwc-k3s multipass launch --name { YOUR_INITIALS } -k3s --cloud-init cloud-init/k3s.yaml --cpus = 2 --disk = 10G --mem = 4G Once the instance has been successfully created shell into it. multipass shell { YOUR_INITIALS } -k3s 2. I\u2019ve got the key, I\u2019ve got the secret! \u00b6 You will need to obtain your Access Token from the SignalFx UI once Kubernetes is running. You can find your Access Token by clicking on your profile icon on the top right of the SignalFx UI. Then select Organisation Settings \u2192 Access Tokens . Expand the Default token, then click on Show Token to expose your token. Later in the lab you can come back here and click the Copy button which will copy it to your clipboard so you can paste it when you need to provide an access token in the lab. You will also need to obtain the name of the Realm for your SignalFx account. Click on the profile icon again, but this time select 'My Profile'. The Ream can be found in the middle of the page within the Organizations section. In this example it is us1 . 3. Take the Helm! \u00b6 Create the following variables to use in the proceeding helm install command: export ACCESS_TOKEN=<token from Step 2> export REALM=<realm from Step 2> export INITIALS=<your initials e.g. GXH> export VERSION=<Smart Agent version e.g. 5.1.0> Note The latest version of the Smart Agent can be found on GitHub Install the agent using the SignalFx Helm chart. Firstly, add the SignalFx Helm chart repository to Helm. helm repo add signalfx https://dl.signalfx.com/helm-repo Ensure the latest state of the SignalFx Helm repository helm repo update Install the Smart Agent Helmchart with the following commands: sed -i -e 's/\\[INITIALS\\]/'\"$INITIALS\"'/' workshop/k3s/values.yaml helm install --set signalFxAccessToken=$ACCESS_TOKEN --set clusterName=$INITIALS-SFX-WORKSHOP --set kubeletAPI.url=https://localhost:10250 --set signalFxRealm=$REALM --set agentVersion=$VERSION --set traceEndpointUrl=https://ingest.$REALM.signalfx.com/v2/trace --set gatherDockerMetrics=false signalfx-agent signalfx/signalfx-agent -f workshop/k3s/values.yaml You can monitor the progress of the deployment by running kubectl get pods which should typically report a new pod is up and running after about 30 seconds. Ensure the status is reported as Running before continuing. Input kubectl get pods Output NAME READY STATUS RESTARTS AGE signalfx-agent-66tvr 1/1 Running 0 7s Ensure there are no errors by tailing the logs from the Smart Agent Pod. Output should look similar to the log output shown below. Use the label set by the helm install to tail logs (You will need to press Ctrl-C to exit). Or use the installed k9s terminal UI for bonus points! Input kubectl logs -l app = signalfx-agent -f Output time=\"2020-03-15T11:30:28Z\" level=info msg=\"Starting up agent version 5.0.0\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Watching for config file changes\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"New config loaded\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Using log level info\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Fetching host id dimensions\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Trying to get fully qualified hostname\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Using hostname PH-k3s\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Using host id dimensions map[host:PH-k3s kubernetes_node_uid:05ba9d7b-89d4-4c70-a3e9-4dc72923423a]\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Sending datapoints to https://ingest.us1.signalfx.com/v2/datapoint\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Sending events to https://ingest.us1.signalfx.com/v2/event\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=10 monitorType=kubelet-stats time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=11 monitorType=kubernetes-cluster time=\"2020-03-15T11:30:29Z\" level=info msg=\"Done configuring agent\" ... time=\"2020-03-15T11:30:29Z\" level=info msg=\"Serving internal metrics at localhost:8095\" I0315 11:30:29.922577 1 leaderelection.go:242] attempting to acquire leader lease default/signalfx-agent-leader... I0315 11:30:29.950448 1 leaderelection.go:252] successfully acquired lease default/signalfx-agent-leader time=\"2020-03-15T11:30:29Z\" level=info msg=\"K8s leader is now node ph-k3s\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Starting K8s API resource sync\" ... 4. Check all is well in the SignalFx UI! \u00b6 In the SignalFx UI, goto INFRASTRUCTURE \u2192 Kubernetes Navigator \u2192 Cluster Map and open the Kubernetes Navigator Cluster Map to ensure metrics are being sent. Validate that your cluster is discovered and shown (In a workshop you can see many more clusters) by finding your cluster by searching for {YOUR_INITIALS}-SFX-WORKSHOP : If there are many clusters you can use the dashboard filter to narrow down to your Kubernetes cluster e.g. kubernetes_cluster: {YOUR_INITIALS}-SFX-WORKSHOP or do this by clicking on the blue cross after selecting your cluster with your mouse. To examine the health of your cluster, open the side bar by clicking on the side bar button to open the Metrics side bar. Once it is open, you can use the slider on the side to explore the various charts relevant to your cluster/node: Cpu%, Mem%, Network in & out. Events and Container list. Take some time to explore the Kubernetes Navigator UI. Use the Next link in the footer below to continue the workshop","title":"Deploying the Smart Agent in Kubernetes (K3s)"},{"location":"module3/k3s/#lab-summary","text":"Download the workshop and configure Kubernetes ( K3s ) environment. Use the SignalFx Helm chart to install the Smart Agent in K3s. Explore Your cluster in the Kubernetes Navigator If you have chosen to run the workshop on a AWS/EC2 instance, please follow instructions given and go to Step 2 .","title":"Lab Summary"},{"location":"module3/k3s/#1-lets-bake-some-k8s","text":"If you are going to run this localy please install Multipass for your OS. On a Mac you can also install via brew e.g. brew cask install multipass Regardless if you are running this lab locally or use an EC2 instance, download the App Dev Workshop Master Zip file locally or on to the EC2 instance.then proceed to unzip the file, rename it, and change into the workshop directory curl -LO https://github.com/signalfx/app-dev-workshop/archive/master.zip unzip master.zip mv app-dev-workshop-master workshop cd workshop When using an EC2 instance you can now skip to Step 2 Launch the Multipass instance which will run Kubernetes (K3s) Note Use {YOUR_INITIALS}-k3s so that the value of the instance hostname is unique e.g. rwc-k3s multipass launch --name { YOUR_INITIALS } -k3s --cloud-init cloud-init/k3s.yaml --cpus = 2 --disk = 10G --mem = 4G Once the instance has been successfully created shell into it. multipass shell { YOUR_INITIALS } -k3s","title":"1. Let\u2019s bake some K8s"},{"location":"module3/k3s/#2-ive-got-the-key-ive-got-the-secret","text":"You will need to obtain your Access Token from the SignalFx UI once Kubernetes is running. You can find your Access Token by clicking on your profile icon on the top right of the SignalFx UI. Then select Organisation Settings \u2192 Access Tokens . Expand the Default token, then click on Show Token to expose your token. Later in the lab you can come back here and click the Copy button which will copy it to your clipboard so you can paste it when you need to provide an access token in the lab. You will also need to obtain the name of the Realm for your SignalFx account. Click on the profile icon again, but this time select 'My Profile'. The Ream can be found in the middle of the page within the Organizations section. In this example it is us1 .","title":"2. I\u2019ve got the key, I\u2019ve got the secret!"},{"location":"module3/k3s/#3-take-the-helm","text":"Create the following variables to use in the proceeding helm install command: export ACCESS_TOKEN=<token from Step 2> export REALM=<realm from Step 2> export INITIALS=<your initials e.g. GXH> export VERSION=<Smart Agent version e.g. 5.1.0> Note The latest version of the Smart Agent can be found on GitHub Install the agent using the SignalFx Helm chart. Firstly, add the SignalFx Helm chart repository to Helm. helm repo add signalfx https://dl.signalfx.com/helm-repo Ensure the latest state of the SignalFx Helm repository helm repo update Install the Smart Agent Helmchart with the following commands: sed -i -e 's/\\[INITIALS\\]/'\"$INITIALS\"'/' workshop/k3s/values.yaml helm install --set signalFxAccessToken=$ACCESS_TOKEN --set clusterName=$INITIALS-SFX-WORKSHOP --set kubeletAPI.url=https://localhost:10250 --set signalFxRealm=$REALM --set agentVersion=$VERSION --set traceEndpointUrl=https://ingest.$REALM.signalfx.com/v2/trace --set gatherDockerMetrics=false signalfx-agent signalfx/signalfx-agent -f workshop/k3s/values.yaml You can monitor the progress of the deployment by running kubectl get pods which should typically report a new pod is up and running after about 30 seconds. Ensure the status is reported as Running before continuing. Input kubectl get pods Output NAME READY STATUS RESTARTS AGE signalfx-agent-66tvr 1/1 Running 0 7s Ensure there are no errors by tailing the logs from the Smart Agent Pod. Output should look similar to the log output shown below. Use the label set by the helm install to tail logs (You will need to press Ctrl-C to exit). Or use the installed k9s terminal UI for bonus points! Input kubectl logs -l app = signalfx-agent -f Output time=\"2020-03-15T11:30:28Z\" level=info msg=\"Starting up agent version 5.0.0\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Watching for config file changes\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"New config loaded\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Using log level info\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Fetching host id dimensions\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Trying to get fully qualified hostname\" time=\"2020-03-15T11:30:28Z\" level=info msg=\"Using hostname PH-k3s\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Using host id dimensions map[host:PH-k3s kubernetes_node_uid:05ba9d7b-89d4-4c70-a3e9-4dc72923423a]\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Sending datapoints to https://ingest.us1.signalfx.com/v2/datapoint\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Sending events to https://ingest.us1.signalfx.com/v2/event\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=10 monitorType=kubelet-stats time=\"2020-03-15T11:30:29Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=11 monitorType=kubernetes-cluster time=\"2020-03-15T11:30:29Z\" level=info msg=\"Done configuring agent\" ... time=\"2020-03-15T11:30:29Z\" level=info msg=\"Serving internal metrics at localhost:8095\" I0315 11:30:29.922577 1 leaderelection.go:242] attempting to acquire leader lease default/signalfx-agent-leader... I0315 11:30:29.950448 1 leaderelection.go:252] successfully acquired lease default/signalfx-agent-leader time=\"2020-03-15T11:30:29Z\" level=info msg=\"K8s leader is now node ph-k3s\" time=\"2020-03-15T11:30:29Z\" level=info msg=\"Starting K8s API resource sync\" ...","title":"3. Take the Helm!"},{"location":"module3/k3s/#4-check-all-is-well-in-the-signalfx-ui","text":"In the SignalFx UI, goto INFRASTRUCTURE \u2192 Kubernetes Navigator \u2192 Cluster Map and open the Kubernetes Navigator Cluster Map to ensure metrics are being sent. Validate that your cluster is discovered and shown (In a workshop you can see many more clusters) by finding your cluster by searching for {YOUR_INITIALS}-SFX-WORKSHOP : If there are many clusters you can use the dashboard filter to narrow down to your Kubernetes cluster e.g. kubernetes_cluster: {YOUR_INITIALS}-SFX-WORKSHOP or do this by clicking on the blue cross after selecting your cluster with your mouse. To examine the health of your cluster, open the side bar by clicking on the side bar button to open the Metrics side bar. Once it is open, you can use the slider on the side to explore the various charts relevant to your cluster/node: Cpu%, Mem%, Network in & out. Events and Container list. Take some time to explore the Kubernetes Navigator UI. Use the Next link in the footer below to continue the workshop","title":"4. Check all is well in the SignalFx UI!"},{"location":"module3/nginx/","text":"Lab Summary \u00b6 Deploy a NGINX ReplicaSet into your K3s cluster and confirm the auto discovery of your NGINX deployment. Run a benchmark test to create metrics and confirm them streaming into SignalFX! 1. Start your NGINX! \u00b6 Remain in the Multipass or EC2 shell session and change into the nginx directory: cd ~/workshop/k3s/nginx Create the NGINX configmap using the nginx.conf file: kubectl create configmap nginxconfig --from-file=nginx.conf Verify the number of pods running in the SignalFx UI by selecting the WORKLOADS tab. This should give you an overview of the workloads on your cluster. Note the single agent container running per node among the default Kubernetes pods. This single container will monitor all the pods and services being deployed on this node! Now switch back to the default cluster node view by selecting the MAP tab and select your cluster again. 2. Create NGINX deployment! \u00b6 kubectl create -f nginx-deployment.yaml Validate the deployment has been successful and that the NGINX pods are running. If you have the SignalFx UI open you should see new Pods being started and containers being deployed. It should only take around 20 seconds for the pods to transition into a Running state. In the SignalFx UI you should have a cluster that looks like below: If you select the WORKLOADS tab again you should now see that there is a new replica set and a deployment added for the NGINX deployment: Let's validate this in your shell as well, before creating load on your system: Input kubectl get pods Output NAME READY STATUS RESTARTS AGE signalfx-agent-n7nz2 1/1 Running 0 11m nginx-deployment-f96cf6966-jhmjp 1/1 Running 0 21s nginx-deployment-f96cf6966-459vf 1/1 Running 0 21s nginx-deployment-f96cf6966-vrnfc 1/1 Running 0 21s nginx-deployment-f96cf6966-7z4tm 1/1 Running 0 21s Next we need to expose port 80 (HTTP) Input kubectl create service nodeport nginx --tcp=80:80 Output service/nginx created Run kubectl get svc then make a note of the CLUSTER-IP address allocated to the NGINX service. Input kubectl get svc Output NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.96.0.1 <none> 443/TCP 9m3s nginx NodePort 10.110.36.62 <none> 80:30995/TCP 8s 3. Run a benchmark \u00b6 Using the NGINX CLUSTER-IP address reported from above, use Apache Benchmark ( ab ) to create some traffic to light up your SignalFx NGINX dashboard. Run this a couple of times to generate some metrics! Input ab -n1000 -c20 http://{INSERT_NGINX_IP_ADDRESS}/ Output This is ApacheBench, Version 2.3 <$Revision: 1826891 $> Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking localhost (be patient) Completed 100 requests ... Completed 1000 requests Finished 1000 requests Server Software: nginx/1.17.5 Server Hostname: localhost Server Port: 30995 ... Validate you are seeing metrics in the UI by going to Dashboards \u2192 NGINX \u2192 NGINX Servers Tip: you can again apply the filter kubernetes_cluster: {YOUR_INITIALS}-SFX-WORKSHOP to focus on only your metrics. Use the Next link in the footer below to continue the workshop","title":"Deploying NGINX in K3s"},{"location":"module3/nginx/#lab-summary","text":"Deploy a NGINX ReplicaSet into your K3s cluster and confirm the auto discovery of your NGINX deployment. Run a benchmark test to create metrics and confirm them streaming into SignalFX!","title":"Lab Summary"},{"location":"module3/nginx/#1-start-your-nginx","text":"Remain in the Multipass or EC2 shell session and change into the nginx directory: cd ~/workshop/k3s/nginx Create the NGINX configmap using the nginx.conf file: kubectl create configmap nginxconfig --from-file=nginx.conf Verify the number of pods running in the SignalFx UI by selecting the WORKLOADS tab. This should give you an overview of the workloads on your cluster. Note the single agent container running per node among the default Kubernetes pods. This single container will monitor all the pods and services being deployed on this node! Now switch back to the default cluster node view by selecting the MAP tab and select your cluster again.","title":"1. Start your NGINX!"},{"location":"module3/nginx/#2-create-nginx-deployment","text":"kubectl create -f nginx-deployment.yaml Validate the deployment has been successful and that the NGINX pods are running. If you have the SignalFx UI open you should see new Pods being started and containers being deployed. It should only take around 20 seconds for the pods to transition into a Running state. In the SignalFx UI you should have a cluster that looks like below: If you select the WORKLOADS tab again you should now see that there is a new replica set and a deployment added for the NGINX deployment: Let's validate this in your shell as well, before creating load on your system: Input kubectl get pods Output NAME READY STATUS RESTARTS AGE signalfx-agent-n7nz2 1/1 Running 0 11m nginx-deployment-f96cf6966-jhmjp 1/1 Running 0 21s nginx-deployment-f96cf6966-459vf 1/1 Running 0 21s nginx-deployment-f96cf6966-vrnfc 1/1 Running 0 21s nginx-deployment-f96cf6966-7z4tm 1/1 Running 0 21s Next we need to expose port 80 (HTTP) Input kubectl create service nodeport nginx --tcp=80:80 Output service/nginx created Run kubectl get svc then make a note of the CLUSTER-IP address allocated to the NGINX service. Input kubectl get svc Output NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.96.0.1 <none> 443/TCP 9m3s nginx NodePort 10.110.36.62 <none> 80:30995/TCP 8s","title":"2. Create NGINX deployment!"},{"location":"module3/nginx/#3-run-a-benchmark","text":"Using the NGINX CLUSTER-IP address reported from above, use Apache Benchmark ( ab ) to create some traffic to light up your SignalFx NGINX dashboard. Run this a couple of times to generate some metrics! Input ab -n1000 -c20 http://{INSERT_NGINX_IP_ADDRESS}/ Output This is ApacheBench, Version 2.3 <$Revision: 1826891 $> Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking localhost (be patient) Completed 100 requests ... Completed 1000 requests Finished 1000 requests Server Software: nginx/1.17.5 Server Hostname: localhost Server Port: 30995 ... Validate you are seeing metrics in the UI by going to Dashboards \u2192 NGINX \u2192 NGINX Servers Tip: you can again apply the filter kubernetes_cluster: {YOUR_INITIALS}-SFX-WORKSHOP to focus on only your metrics. Use the Next link in the footer below to continue the workshop","title":"3. Run a benchmark"},{"location":"module4/terraform/","text":"Lab Summary \u00b6 Install Terraform and initialise the SignalFx Provider. Run Terraform to create SignalFx detectors and dashboards from code using our Terraform provider. See how Terraform can also delete detectors and dashboards. 1. Initial setup \u00b6 Download and install Terraform for your platform - https://www.terraform.io/downloads.html (min. requirement v. 0.12.18) Download the SignalFx Jumpstart Terraform master zip file, unzip the file and change into the signalfx-jumpstart-master directory curl -LO https://github.com/signalfx/signalfx-jumpstart/archive/master.zip unzip master.zip cd signalfx-jumpstart-master Create the following environment variables to use in the Terraform steps below export ACCESS_TOKEN=<token from Module 3> export REALM=<realm from Module 3> export INITIALS=<your initials e.g. RWC> Initialise Terraform. Note: You will need to run this command each time a new version of the Terraform Provider is released. You can track the releases on GitHub . Input terraform init -upgrade Output Upgrading modules... - aws in modules/aws - azure in modules/azure - docker in modules/docker - gcp in modules/gcp - host in modules/host - kubernetes in modules/kubernetes - parent_child_dashboard in modules/dashboards/parent - pivotal in modules/pivotal - usage_dashboard in modules/dashboards/usage Initializing the backend... Initializing provider plugins... - Checking for available provider plugins... - Downloading plugin for provider \"signalfx\" (terraform-providers/signalfx) 4.18.6... The following providers do not have any version constraints in configuration, so the latest version was installed. To prevent automatic upgrades to new major versions that may contain breaking changes, it is recommended to add version = \"...\" constraints to the corresponding provider blocks in configuration, with the constraint strings suggested below. * provider.signalfx: version = \"~> 4.18\" Terraform has been successfully initialized! You may now begin working with Terraform. Try running \"terraform plan\" to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary. Create a new workspace, replace {WORKSPACE_NAME} with what you want your workspace to be called: Input terraform workspace new { WORKSPACE_NAME } Output Created and switched to workspace \"my_workspace\"! You're now on a new, empty workspace. Workspaces isolate their state, so if you run \"terraform plan\" Terraform will not see any existing state for this configuration. 2. Create an execution plan \u00b6 Review the execution plan. terraform plan -var = \"access_token= $ACCESS_TOKEN \" -var = \"realm= $REALM \" -var = \"sfx_prefix= $INITIALS \" If the plan executes successfully, we can go ahead and apply: 3. Apply actions from execution plan \u00b6 terraform apply -var = \"access_token= $ACCESS_TOKEN \" -var = \"realm= $REALM \" -var = \"sfx_prefix= $INITIALS \" Validate that the detectors were created, under the ALERTS \u2192 Detectors , you should see a list of new detectors with the a prefix of your initials: 4. Destroy all your hard work \u00b6 You will first need to ensure you are in the correct workspace, replace {WORKSPACE_NAME} with the name created in the initial setup) terraform workspace select {WORKSPACE_NAME} Destroy all Detectors and Dashboards that were previously applied. Note The var=\u201dsfx_prefix=$INITIALS\u201d is not required! terraform destroy -var = \"access_token= $ACCESS_TOKEN \" -var = \"realm= $REALM \" Validate all the detectors have been removed by navigating to ALERTS \u2192 Detectors Use the Next link in the footer below to continue the workshop","title":"Using Terraform for charts and dashboards"},{"location":"module4/terraform/#lab-summary","text":"Install Terraform and initialise the SignalFx Provider. Run Terraform to create SignalFx detectors and dashboards from code using our Terraform provider. See how Terraform can also delete detectors and dashboards.","title":"Lab Summary"},{"location":"module4/terraform/#1-initial-setup","text":"Download and install Terraform for your platform - https://www.terraform.io/downloads.html (min. requirement v. 0.12.18) Download the SignalFx Jumpstart Terraform master zip file, unzip the file and change into the signalfx-jumpstart-master directory curl -LO https://github.com/signalfx/signalfx-jumpstart/archive/master.zip unzip master.zip cd signalfx-jumpstart-master Create the following environment variables to use in the Terraform steps below export ACCESS_TOKEN=<token from Module 3> export REALM=<realm from Module 3> export INITIALS=<your initials e.g. RWC> Initialise Terraform. Note: You will need to run this command each time a new version of the Terraform Provider is released. You can track the releases on GitHub . Input terraform init -upgrade Output Upgrading modules... - aws in modules/aws - azure in modules/azure - docker in modules/docker - gcp in modules/gcp - host in modules/host - kubernetes in modules/kubernetes - parent_child_dashboard in modules/dashboards/parent - pivotal in modules/pivotal - usage_dashboard in modules/dashboards/usage Initializing the backend... Initializing provider plugins... - Checking for available provider plugins... - Downloading plugin for provider \"signalfx\" (terraform-providers/signalfx) 4.18.6... The following providers do not have any version constraints in configuration, so the latest version was installed. To prevent automatic upgrades to new major versions that may contain breaking changes, it is recommended to add version = \"...\" constraints to the corresponding provider blocks in configuration, with the constraint strings suggested below. * provider.signalfx: version = \"~> 4.18\" Terraform has been successfully initialized! You may now begin working with Terraform. Try running \"terraform plan\" to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary. Create a new workspace, replace {WORKSPACE_NAME} with what you want your workspace to be called: Input terraform workspace new { WORKSPACE_NAME } Output Created and switched to workspace \"my_workspace\"! You're now on a new, empty workspace. Workspaces isolate their state, so if you run \"terraform plan\" Terraform will not see any existing state for this configuration.","title":"1. Initial setup"},{"location":"module4/terraform/#2-create-an-execution-plan","text":"Review the execution plan. terraform plan -var = \"access_token= $ACCESS_TOKEN \" -var = \"realm= $REALM \" -var = \"sfx_prefix= $INITIALS \" If the plan executes successfully, we can go ahead and apply:","title":"2. Create an execution plan"},{"location":"module4/terraform/#3-apply-actions-from-execution-plan","text":"terraform apply -var = \"access_token= $ACCESS_TOKEN \" -var = \"realm= $REALM \" -var = \"sfx_prefix= $INITIALS \" Validate that the detectors were created, under the ALERTS \u2192 Detectors , you should see a list of new detectors with the a prefix of your initials:","title":"3. Apply actions from execution plan"},{"location":"module4/terraform/#4-destroy-all-your-hard-work","text":"You will first need to ensure you are in the correct workspace, replace {WORKSPACE_NAME} with the name created in the initial setup) terraform workspace select {WORKSPACE_NAME} Destroy all Detectors and Dashboards that were previously applied. Note The var=\u201dsfx_prefix=$INITIALS\u201d is not required! terraform destroy -var = \"access_token= $ACCESS_TOKEN \" -var = \"realm= $REALM \" Validate all the detectors have been removed by navigating to ALERTS \u2192 Detectors Use the Next link in the footer below to continue the workshop","title":"4. Destroy all your hard work"},{"location":"module5/service_bureau/","text":"Lab Summary \u00b6 How to keep track of the usage of SignalFx in your organization. Learn how to keep track of spend by exploring the Billing and Usage interface. 1. Understanding SignalFx engagement \u00b6 To fully understand SignalFx adoption inside your organization, click on the Settings icon on the top right of the SignalFx UI, It may also look like this . From the drop down, select the Organizations Settings \u2192 Organization Overview menu item, this will provide you with the following dashboard that shows you how your SignalFx organization is being used: On the left, you will see a list of registered users (blurred for privacy in the above screenshot), and the various charts that show you the number of registered users, chart's and dashboards created and growth trends. The screenshot is taken from an actual organization, the workshop organization you're looking at may have less data to work with. Take a minute to explore the various charts in the Organization over view of the workshop instance. 2. Usage and Billing \u00b6 If you want to see what your spend is against your contract you can either select the Settings icon on the top right of the SignalFx UI again, but this time select the Organizations Settings \u2192 Billing and Usage tab, or the faster way, select the Usage and Billing tab from the left pane! This screen may take a few seconds to load whilst it calculates the usage. 3. Understanding usage \u00b6 You should see a screen similar like the one below that will give you an overview of the current usage, the average usage and your entitlement per category : Nodes, Containers, Customer Metrics and High Resolution Metrics. For more information on what these are please read Billing and Usage information Let's examine this page in more detail. \u00b6 The top chart shows you the current allotment per category, (shown at the red arrows at the top in the screenshot below), as wel as your current usage of the four catagories. (Shown at the red lines at the bottom of the chart, as you can see we consumed 18 hosts, 0 containers and 1038 custom metrics and 0 high resolution metrics) In the bottom chart, you can see the usage per category for the current period (shown in the drop-down box on the top right of the chart.) The blue line marked Average usage indicates what SignalFx will use to calculate your average usage for the current period. Info As you can see from the screenshot, SignalFx does not use High water mark or p95% for cost calculation but the actual average usage, allowing you do performance testing or Blue/Green style deployments etc. without risk of overage charges. In the pane on the right shows you information about your organizations and contract end date. To get a feel of the options you can change the category type by the drop down on the left or the time period with the right drop box. Please take a minute to explore the different time periods & categories and their views. Use the Next link in the footer below to continue the workshop","title":"Billing and Usage"},{"location":"module5/service_bureau/#lab-summary","text":"How to keep track of the usage of SignalFx in your organization. Learn how to keep track of spend by exploring the Billing and Usage interface.","title":"Lab Summary"},{"location":"module5/service_bureau/#1-understanding-signalfx-engagement","text":"To fully understand SignalFx adoption inside your organization, click on the Settings icon on the top right of the SignalFx UI, It may also look like this . From the drop down, select the Organizations Settings \u2192 Organization Overview menu item, this will provide you with the following dashboard that shows you how your SignalFx organization is being used: On the left, you will see a list of registered users (blurred for privacy in the above screenshot), and the various charts that show you the number of registered users, chart's and dashboards created and growth trends. The screenshot is taken from an actual organization, the workshop organization you're looking at may have less data to work with. Take a minute to explore the various charts in the Organization over view of the workshop instance.","title":"1. Understanding SignalFx engagement"},{"location":"module5/service_bureau/#2-usage-and-billing","text":"If you want to see what your spend is against your contract you can either select the Settings icon on the top right of the SignalFx UI again, but this time select the Organizations Settings \u2192 Billing and Usage tab, or the faster way, select the Usage and Billing tab from the left pane! This screen may take a few seconds to load whilst it calculates the usage.","title":"2. Usage and Billing"},{"location":"module5/service_bureau/#3-understanding-usage","text":"You should see a screen similar like the one below that will give you an overview of the current usage, the average usage and your entitlement per category : Nodes, Containers, Customer Metrics and High Resolution Metrics. For more information on what these are please read Billing and Usage information","title":"3. Understanding usage"},{"location":"module5/service_bureau/#lets-examine-this-page-in-more-detail","text":"The top chart shows you the current allotment per category, (shown at the red arrows at the top in the screenshot below), as wel as your current usage of the four catagories. (Shown at the red lines at the bottom of the chart, as you can see we consumed 18 hosts, 0 containers and 1038 custom metrics and 0 high resolution metrics) In the bottom chart, you can see the usage per category for the current period (shown in the drop-down box on the top right of the chart.) The blue line marked Average usage indicates what SignalFx will use to calculate your average usage for the current period. Info As you can see from the screenshot, SignalFx does not use High water mark or p95% for cost calculation but the actual average usage, allowing you do performance testing or Blue/Green style deployments etc. without risk of overage charges. In the pane on the right shows you information about your organizations and contract end date. To get a feel of the options you can change the category type by the drop down on the left or the time period with the right drop box. Please take a minute to explore the different time periods & categories and their views. Use the Next link in the footer below to continue the workshop","title":"Let's examine this page in more detail."},{"location":"module5/teams/","text":"Lab Summary \u00b6 Create a team and add members to team Discover how you can restrict usage for teams by creating separate access token's and set limits. 1. Introduction to Teams \u00b6 To make sure that users directly see the dashboards and alerts that are relevant to them when they login to SignalFX, most organizations will use SignalFx's Teams mechanism to assign a user to a Team. Usually this matches work related roles, for example, members of a Dev-ops or Product Management group would be assigned to the corresponding Teams in SignalFx. Once an Team member is connected to SignalFx, they will be shown the Teams landing page, similar to the one shown below, In this case for the Product Management team. Here, members see all the Dashboard, alerts that are assigned the team and any other useful information so they can focus on what is relevant to their job. The above landing page has three Dashboard groups assigned, shows there is a critical alert that had this team as an addressee and some text and urls with other topics of interest. 2. Creating a new Team \u00b6 To work with to signalFx's Team UI cick on the Settings icon on the top right of the SignalFx UI, (t may also look like this ) and select the Organizations Settings \u2192 Teams tab, or select the Teams tab from the left pane. When the Team UI is selected you will be presented in the workshop with an empty Team's list To add a new Team click on the green button. This will present youy with the Create New Team Dialog. Create your own team by naming it [YOUR-INITIALS]-Team and add yourself by searching for your name and selecting the Add link behind your name. This should result in a dialog similar to the one below: You can remove selected users by pressing remove or the small x behind a name. Make sure you have your group created with your initials and with yourself added as a member, then press done. This will bring you back to the Teams list that now show your Team and the one's created by others. Note that the group(s) you are a member of has a gray Member icon in front of it. If no members are assigned to your group, you should see a blue Add members link instead of the member count, clicking on that link will get you to the Edit Team dialog where you can add yourself. This is the same dialog you get when pressing the 3 dots ... at the end of the Line with your team and select Edit Team . The 3 ... menu give you the option to Edit a Team, Join or leave a Team or Delete a team. 3. Adding Notification Rules to a Team \u00b6 You can set up specific Notification rules per team, click on the NOTIFICATION POLICY Button, this will open the notification edit menu. By default the system offers you the ability to set up a general notification rule for your team. Note the Email all members, This mean all members of this team will receive an email with the Alert information, regardless of the alert type. You can add other recipients, by clicking You can add a different email addresses to inform people outside SignalFx users like alerts@your-company.com if that is way to inform people outside SignalFx. AAdding groups you would use when you also want to send an alert to an other team, like sending an alert on the Database of your application to the general Database team along with one to your team. However if you click on the link Configure separate notification tiers for different severity alerts you can configure every alert level differently. As you can see in th above screenshot, you can set up different alert rules for the different alert level. We have different rules set up for all the various Error levels, Showing you how Splunk's VictorOps offering would integrate with SignalFx. Both at a Critical and Major alert, the alert gets forwarded to Splunk's VictorOps that will handle alerting the on call engineer and/or manager. For the Minor alerts we send it to the Teams slack channel and for warning and info messages we just use an email Below you see some of the Notification options you can install in your SignalFx Organization: Take a moment to create some notification rules for you Team. 4. Controlling a Team's usage! \u00b6 If you wish to make sure certain teams or users cannot use more then a certain allotment of you overall allotment of nodes, containers and Metrics' you can create multiple Access keys. To work with SignalFx's Access Tokens UI click on the settings ) icon on the right top of the page and select the Organizations Settings \u2192 Access tokens tab, or select the Access Tokens tab from the left pane. This will open up the Access Token Interface. It consist of a an overview of your Allotments for this organization and a list of Access Tokens that have been generated. Every Organization wil have a Default token that is generated when Organization is created. Each Token is unique and can be assigned limits for the amount of Nodes,containers Custom Metrics and High Resolution it can use. The Usage Status Column shows if a token is used above or below its assigned limits. Let create a new token by clicking on the button. This will provide you with the Name Your Access Token dialog. Enter the new name of the new Token by using your Initials ie. PH-Token After you press Ok, you will be taken back to the Access token UI, here your new token should be present, among the ones created by others. If you have made an error in your naming, want to disable/enable a token or set a Token limit, click on the 3 ... menu button behind a token limit to open the manage token menu. If you made a type you can use the Rename Token option to correct the name of your token. If you need to make sure a token cannot be used a to send Metrics in you can Disable a token. Click on the Disable button to Disable the token, this means the token cannot be used for sending in data to SignalFX. The line with Your Token should turn greyed out to indicate that is been Disabled as you can see in the screenshot below. Go ahead and click on the 3 ... menu button to Disable and Enable your token. Now Lets start limiting usage by clicking on Manage Token Limit in teh 3 ... menu. This will show the Manage Token Limit Dialog: In this Dialog you can set the limits per category. Please go ahead and specify the limits as shown above for each usage metric. For our lab use your own email address, and double check if you have the number in you dialog as shown above. Token limits are used to trigger an alert that notify one or more recipients when the usage has been above 90% of the limit for 5 minutes. To specify the recipients, click Add Recipient, then select the recipient or notification method you want to use. (Specifying recipients is optional but highly recommended.) The severity for token alerts is always Critical. Click on Update to save your Access Tokens limits and The Alert Settings. Note When a token is at or above its limit in a usage category, new metrics for that usage category will not be stored and processed by SignalFx. This will make sure you there will be no unexpected cost due to a team sending in data without restriction. In your company you would distribute these new Access Tokens to various teams, controlling how much information/data they can send to SignalFx. This will allow you to fine tune the way you consume your SignalFx allotment and stop expensive surprises from happening Congratulations! You have now have completed the Service Bureau module. Use the Next link in the footer below to continue the workshop","title":"Teams"},{"location":"module5/teams/#lab-summary","text":"Create a team and add members to team Discover how you can restrict usage for teams by creating separate access token's and set limits.","title":"Lab Summary"},{"location":"module5/teams/#1-introduction-to-teams","text":"To make sure that users directly see the dashboards and alerts that are relevant to them when they login to SignalFX, most organizations will use SignalFx's Teams mechanism to assign a user to a Team. Usually this matches work related roles, for example, members of a Dev-ops or Product Management group would be assigned to the corresponding Teams in SignalFx. Once an Team member is connected to SignalFx, they will be shown the Teams landing page, similar to the one shown below, In this case for the Product Management team. Here, members see all the Dashboard, alerts that are assigned the team and any other useful information so they can focus on what is relevant to their job. The above landing page has three Dashboard groups assigned, shows there is a critical alert that had this team as an addressee and some text and urls with other topics of interest.","title":"1. Introduction to Teams"},{"location":"module5/teams/#2-creating-a-new-team","text":"To work with to signalFx's Team UI cick on the Settings icon on the top right of the SignalFx UI, (t may also look like this ) and select the Organizations Settings \u2192 Teams tab, or select the Teams tab from the left pane. When the Team UI is selected you will be presented in the workshop with an empty Team's list To add a new Team click on the green button. This will present youy with the Create New Team Dialog. Create your own team by naming it [YOUR-INITIALS]-Team and add yourself by searching for your name and selecting the Add link behind your name. This should result in a dialog similar to the one below: You can remove selected users by pressing remove or the small x behind a name. Make sure you have your group created with your initials and with yourself added as a member, then press done. This will bring you back to the Teams list that now show your Team and the one's created by others. Note that the group(s) you are a member of has a gray Member icon in front of it. If no members are assigned to your group, you should see a blue Add members link instead of the member count, clicking on that link will get you to the Edit Team dialog where you can add yourself. This is the same dialog you get when pressing the 3 dots ... at the end of the Line with your team and select Edit Team . The 3 ... menu give you the option to Edit a Team, Join or leave a Team or Delete a team.","title":"2. Creating a new Team"},{"location":"module5/teams/#3-adding-notification-rules-to-a-team","text":"You can set up specific Notification rules per team, click on the NOTIFICATION POLICY Button, this will open the notification edit menu. By default the system offers you the ability to set up a general notification rule for your team. Note the Email all members, This mean all members of this team will receive an email with the Alert information, regardless of the alert type. You can add other recipients, by clicking You can add a different email addresses to inform people outside SignalFx users like alerts@your-company.com if that is way to inform people outside SignalFx. AAdding groups you would use when you also want to send an alert to an other team, like sending an alert on the Database of your application to the general Database team along with one to your team. However if you click on the link Configure separate notification tiers for different severity alerts you can configure every alert level differently. As you can see in th above screenshot, you can set up different alert rules for the different alert level. We have different rules set up for all the various Error levels, Showing you how Splunk's VictorOps offering would integrate with SignalFx. Both at a Critical and Major alert, the alert gets forwarded to Splunk's VictorOps that will handle alerting the on call engineer and/or manager. For the Minor alerts we send it to the Teams slack channel and for warning and info messages we just use an email Below you see some of the Notification options you can install in your SignalFx Organization: Take a moment to create some notification rules for you Team.","title":"3. Adding Notification Rules to a Team"},{"location":"module5/teams/#4-controlling-a-teams-usage","text":"If you wish to make sure certain teams or users cannot use more then a certain allotment of you overall allotment of nodes, containers and Metrics' you can create multiple Access keys. To work with SignalFx's Access Tokens UI click on the settings ) icon on the right top of the page and select the Organizations Settings \u2192 Access tokens tab, or select the Access Tokens tab from the left pane. This will open up the Access Token Interface. It consist of a an overview of your Allotments for this organization and a list of Access Tokens that have been generated. Every Organization wil have a Default token that is generated when Organization is created. Each Token is unique and can be assigned limits for the amount of Nodes,containers Custom Metrics and High Resolution it can use. The Usage Status Column shows if a token is used above or below its assigned limits. Let create a new token by clicking on the button. This will provide you with the Name Your Access Token dialog. Enter the new name of the new Token by using your Initials ie. PH-Token After you press Ok, you will be taken back to the Access token UI, here your new token should be present, among the ones created by others. If you have made an error in your naming, want to disable/enable a token or set a Token limit, click on the 3 ... menu button behind a token limit to open the manage token menu. If you made a type you can use the Rename Token option to correct the name of your token. If you need to make sure a token cannot be used a to send Metrics in you can Disable a token. Click on the Disable button to Disable the token, this means the token cannot be used for sending in data to SignalFX. The line with Your Token should turn greyed out to indicate that is been Disabled as you can see in the screenshot below. Go ahead and click on the 3 ... menu button to Disable and Enable your token. Now Lets start limiting usage by clicking on Manage Token Limit in teh 3 ... menu. This will show the Manage Token Limit Dialog: In this Dialog you can set the limits per category. Please go ahead and specify the limits as shown above for each usage metric. For our lab use your own email address, and double check if you have the number in you dialog as shown above. Token limits are used to trigger an alert that notify one or more recipients when the usage has been above 90% of the limit for 5 minutes. To specify the recipients, click Add Recipient, then select the recipient or notification method you want to use. (Specifying recipients is optional but highly recommended.) The severity for token alerts is always Critical. Click on Update to save your Access Tokens limits and The Alert Settings. Note When a token is at or above its limit in a usage category, new metrics for that usage category will not be stored and processed by SignalFx. This will make sure you there will be no unexpected cost due to a team sending in data without restriction. In your company you would distribute these new Access Tokens to various teams, controlling how much information/data they can send to SignalFx. This will allow you to fine tune the way you consume your SignalFx allotment and stop expensive surprises from happening Congratulations! You have now have completed the Service Bureau module. Use the Next link in the footer below to continue the workshop","title":"4. Controlling a Team's usage!"},{"location":"module6/","text":"\u00b5APM architecture \u00b6 SignalFx \u00b5APM captures end-to-end distributed transactions from your applications, with trace spans sent directly to SignalFx or via the SignalFx Smart Agent deployed on each host (recommended). Optionally, you can deploy an OpenTelemetry Collector to act as a central aggregation point prior to sending trace spans to SignalFx. In addition to proxying spans and infrastructure metrics, the OpenTelemetry Collector can also perform other functions, such as redacting sensitive tags prior to spans leaving your environment. The following illustrations show the recommended deployment model: SignalFx auto-instrumentation libraries send spans to the Smart Agent; the Smart Agent can send the spans to SignalFx directly or via an optional OpenTelemetry Collector. Use the Next link in the footer below to continue the workshop","title":"\u00b5APM Architecture Overview"},{"location":"module6/#apm-architecture","text":"SignalFx \u00b5APM captures end-to-end distributed transactions from your applications, with trace spans sent directly to SignalFx or via the SignalFx Smart Agent deployed on each host (recommended). Optionally, you can deploy an OpenTelemetry Collector to act as a central aggregation point prior to sending trace spans to SignalFx. In addition to proxying spans and infrastructure metrics, the OpenTelemetry Collector can also perform other functions, such as redacting sensitive tags prior to spans leaving your environment. The following illustrations show the recommended deployment model: SignalFx auto-instrumentation libraries send spans to the Smart Agent; the Smart Agent can send the spans to SignalFx directly or via an optional OpenTelemetry Collector. Use the Next link in the footer below to continue the workshop","title":"\u00b5APM architecture"},{"location":"module6/hotrod/","text":"Enabling \u00b5APM \u00b6 An organisation needs to be pre-provisioned as a \u00b5APM entitlement is required for the purposes of this module. Please contact someone from SignalFx to get a trial instance with \u00b5APM enabled if you don\u2019t have one already. To check if you have an organisation with \u00b5APM enabled, just login to SignalFx and check that you have the \u00b5APM tab on the top navbar next to Dashboards. 1. Create an instance running Kubernetes \u00b6 This is already documented in Deploying the Smart Agent in Kubernetes (K3s) . 2. Deploy the Hotrod application into K3s \u00b6 To deploy the Hotrod application into K3s apply the deployment Input kubectl apply -f ~/workshop/apm/hotrod/k8s/deployment.yaml Output deployment.apps/hotrod created service/hotrod created To ensure the Hotrod application is running: Input kubectl get pods Output NAME READY STATUS RESTARTS AGE signalfx-agent-mmzxk 1/1 Running 0 110s hotrod-7cc9fc85b7-n765r 1/1 Running 0 41s Create an environment variable for the IP address and port that the Hotrod application is exposed on: HOTROD_ENDPOINT=$(kubectl get svc hotrod -n default -o jsonpath='{.spec.clusterIP}:{.spec.ports[0].port}') 3. Generate some traffic to the application using Apache Benchmark \u00b6 ab -n10 -c10 \"http:// $HOTROD_ENDPOINT /dispatch?customer=392&nonse=0.17041229755366172\" Create some errors with an invalid customer number ab -n10 -c10 \"http:// $HOTROD_ENDPOINT /dispatch?customer=391&nonse=0.17041229755366172\" 4. Viewing the Hotrod application in your browser \u00b6 In order to view the application in your web browser we need to find the LoadBalancer IP address and the port the application is listening on. Input kubectl get svc Output NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.43.0.1 <none> 443/TCP 43m hotrod LoadBalancer 10.43.32.97 192.168.64.35 8080:31521/TCP 40m Make note of the EXTERNAL-IP (in the example above this is 192.168.64.35 ). Then head over to your web browser and type in http://{EXTERNAL-IP}:8080 , you should then be able to see the application running. Click on customer names to order a car: Use the Next link in the footer below to continue the workshop","title":"Running Hotrod in K3s"},{"location":"module6/hotrod/#enabling-apm","text":"An organisation needs to be pre-provisioned as a \u00b5APM entitlement is required for the purposes of this module. Please contact someone from SignalFx to get a trial instance with \u00b5APM enabled if you don\u2019t have one already. To check if you have an organisation with \u00b5APM enabled, just login to SignalFx and check that you have the \u00b5APM tab on the top navbar next to Dashboards.","title":"Enabling \u00b5APM"},{"location":"module6/hotrod/#1-create-an-instance-running-kubernetes","text":"This is already documented in Deploying the Smart Agent in Kubernetes (K3s) .","title":"1. Create an instance running Kubernetes"},{"location":"module6/hotrod/#2-deploy-the-hotrod-application-into-k3s","text":"To deploy the Hotrod application into K3s apply the deployment Input kubectl apply -f ~/workshop/apm/hotrod/k8s/deployment.yaml Output deployment.apps/hotrod created service/hotrod created To ensure the Hotrod application is running: Input kubectl get pods Output NAME READY STATUS RESTARTS AGE signalfx-agent-mmzxk 1/1 Running 0 110s hotrod-7cc9fc85b7-n765r 1/1 Running 0 41s Create an environment variable for the IP address and port that the Hotrod application is exposed on: HOTROD_ENDPOINT=$(kubectl get svc hotrod -n default -o jsonpath='{.spec.clusterIP}:{.spec.ports[0].port}')","title":"2. Deploy the Hotrod application into K3s"},{"location":"module6/hotrod/#3-generate-some-traffic-to-the-application-using-apache-benchmark","text":"ab -n10 -c10 \"http:// $HOTROD_ENDPOINT /dispatch?customer=392&nonse=0.17041229755366172\" Create some errors with an invalid customer number ab -n10 -c10 \"http:// $HOTROD_ENDPOINT /dispatch?customer=391&nonse=0.17041229755366172\"","title":"3. Generate some traffic to the application using Apache Benchmark"},{"location":"module6/hotrod/#4-viewing-the-hotrod-application-in-your-browser","text":"In order to view the application in your web browser we need to find the LoadBalancer IP address and the port the application is listening on. Input kubectl get svc Output NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.43.0.1 <none> 443/TCP 43m hotrod LoadBalancer 10.43.32.97 192.168.64.35 8080:31521/TCP 40m Make note of the EXTERNAL-IP (in the example above this is 192.168.64.35 ). Then head over to your web browser and type in http://{EXTERNAL-IP}:8080 , you should then be able to see the application running. Click on customer names to order a car: Use the Next link in the footer below to continue the workshop","title":"4. Viewing the Hotrod application in your browser"},{"location":"module6/sockshop/","text":"Enabling \u00b5APM \u00b6 An organisation needs to be pre-provisioned as a \u00b5APM entitlement is required for the purposes of this module. Please contact someone from SignalFx to get a trial instance with \u00b5APM enabled if you don\u2019t have one already. To check if you have an organisation with \u00b5APM enabled, just login to SignalFx and check that you have the \u00b5APM tab on the top navbar next to Dashboards. 1. Create an instance running Kubernetes \u00b6 This is already documented in Deploying the SmartAgent in Kubernetes using K3s . 2. Deploy the Sock Shop application into K3s \u00b6 To deploy the Sock Shop application into K3s apply the deployment Input cd apm/sockshop kubectl create ns sock-shop kubectl apply -f k8s/complete-demo.yaml Output namespace/sock-shop created deployment.apps/carts-db created service/carts-db created deployment.apps/carts created service/carts created deployment.apps/catalogue-db created service/catalogue-db created deployment.apps/catalogue created service/catalogue created deployment.apps/front-end created service/front-end created deployment.apps/orders-db created service/orders-db created deployment.apps/orders created service/orders created deployment.apps/payment created service/payment created deployment.apps/queue-master created service/queue-master created deployment.apps/rabbitmq created service/rabbitmq created deployment.apps/shipping created service/shipping created deployment.apps/user-db created service/user-db created deployment.apps/user created service/user created 3. Take Sock Shop for a test drive \u00b6 Sock Shop should be running in your cluster and exposes services via cluster IP and port. Obtain the ip address for the front-end service. SOCKS_ENDPOINT = $( kubectl get svc front-end -n sock-shop -o jsonpath = '{.spec.clusterIP}:{.spec.ports[0].port}' ) Then send a Input curl $SOCKS_ENDPOINT Input ... </ script > </ body > </ html > 4. Apply load on Sock Shop \u00b6 Use a load test for sock shop. kubectl run --generator = run-pod/v1 load-test --rm -i --tty --image weaveworksdemos/load-test -- -d 5 -h $SOCKS_ENDPOINT -c 15 -r 1000 The parameter -c controls the amount of concurrent clients and -r the amount of requests sent. To apply continuous load just set -r to some higher number. 5. Visualize and analyze trace data \u00b6 Navigate to \u00b5APM ( not \u00b5APM PG) and select Monitoring, then ensure you have selected your environment from the dropdown at the top, you should see something like this: Explore the User Interface: Review an automatically generated Service Dashboard. How do you correlate Service performance with Infrastructure? Troubleshoot a service. Let's stress the sock shop a bit. Increase the amount of clients running for the load test to something ludicrous (1000+ seems to do the trick). What happens with the services? Troubleshoot a service with a higher error rate. Also review the service dependencies. Look at individual traces and span performance. 6. Viewing the SockShop application in your browser \u00b6 In order to view the application in your web browser we need to find the LoadBalancer IP address and the port the application is listening on. Input kubectl get svc -n sockshop Output NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE carts-db ClusterIP 10.43.221.67 <none> 27017/TCP 34m carts ClusterIP 10.43.61.101 <none> 80/TCP 34m catalogue-db ClusterIP 10.43.57.198 <none> 3306/TCP 34m catalogue ClusterIP 10.43.216.173 <none> 80/TCP 34m orders-db ClusterIP 10.43.236.48 <none> 27017/TCP 34m orders ClusterIP 10.43.115.92 <none> 80/TCP 34m payment ClusterIP 10.43.242.227 <none> 80/TCP 34m queue-master ClusterIP 10.43.73.136 <none> 80/TCP 34m rabbitmq ClusterIP 10.43.113.211 <none> 5672/TCP 34m shipping ClusterIP 10.43.250.115 <none> 80/TCP 34m user-db ClusterIP 10.43.152.153 <none> 27017/TCP 34m user ClusterIP 10.43.45.155 <none> 80/TCP 34m front-end LoadBalancer 10.43.247.97 192.168.64.35 8082:30001/TCP 34m Make note of the EXTERNAL-IP (in the example above this is 192.168.64.35 ). Then head over to your web browser and type in http://{EXTERNAL-IP}:8081 , you should then be able to see the application running. Happy Shopping! Use the Next link in the footer below to continue the workshop","title":"Running Sock Shop in K3s"},{"location":"module6/sockshop/#enabling-apm","text":"An organisation needs to be pre-provisioned as a \u00b5APM entitlement is required for the purposes of this module. Please contact someone from SignalFx to get a trial instance with \u00b5APM enabled if you don\u2019t have one already. To check if you have an organisation with \u00b5APM enabled, just login to SignalFx and check that you have the \u00b5APM tab on the top navbar next to Dashboards.","title":"Enabling \u00b5APM"},{"location":"module6/sockshop/#1-create-an-instance-running-kubernetes","text":"This is already documented in Deploying the SmartAgent in Kubernetes using K3s .","title":"1. Create an instance running Kubernetes"},{"location":"module6/sockshop/#2-deploy-the-sock-shop-application-into-k3s","text":"To deploy the Sock Shop application into K3s apply the deployment Input cd apm/sockshop kubectl create ns sock-shop kubectl apply -f k8s/complete-demo.yaml Output namespace/sock-shop created deployment.apps/carts-db created service/carts-db created deployment.apps/carts created service/carts created deployment.apps/catalogue-db created service/catalogue-db created deployment.apps/catalogue created service/catalogue created deployment.apps/front-end created service/front-end created deployment.apps/orders-db created service/orders-db created deployment.apps/orders created service/orders created deployment.apps/payment created service/payment created deployment.apps/queue-master created service/queue-master created deployment.apps/rabbitmq created service/rabbitmq created deployment.apps/shipping created service/shipping created deployment.apps/user-db created service/user-db created deployment.apps/user created service/user created","title":"2. Deploy the Sock Shop application into K3s"},{"location":"module6/sockshop/#3-take-sock-shop-for-a-test-drive","text":"Sock Shop should be running in your cluster and exposes services via cluster IP and port. Obtain the ip address for the front-end service. SOCKS_ENDPOINT = $( kubectl get svc front-end -n sock-shop -o jsonpath = '{.spec.clusterIP}:{.spec.ports[0].port}' ) Then send a Input curl $SOCKS_ENDPOINT Input ... </ script > </ body > </ html >","title":"3. Take Sock Shop for a test drive"},{"location":"module6/sockshop/#4-apply-load-on-sock-shop","text":"Use a load test for sock shop. kubectl run --generator = run-pod/v1 load-test --rm -i --tty --image weaveworksdemos/load-test -- -d 5 -h $SOCKS_ENDPOINT -c 15 -r 1000 The parameter -c controls the amount of concurrent clients and -r the amount of requests sent. To apply continuous load just set -r to some higher number.","title":"4. Apply load on Sock Shop"},{"location":"module6/sockshop/#5-visualize-and-analyze-trace-data","text":"Navigate to \u00b5APM ( not \u00b5APM PG) and select Monitoring, then ensure you have selected your environment from the dropdown at the top, you should see something like this: Explore the User Interface: Review an automatically generated Service Dashboard. How do you correlate Service performance with Infrastructure? Troubleshoot a service. Let's stress the sock shop a bit. Increase the amount of clients running for the load test to something ludicrous (1000+ seems to do the trick). What happens with the services? Troubleshoot a service with a higher error rate. Also review the service dependencies. Look at individual traces and span performance.","title":"5. Visualize and analyze trace data"},{"location":"module6/sockshop/#6-viewing-the-sockshop-application-in-your-browser","text":"In order to view the application in your web browser we need to find the LoadBalancer IP address and the port the application is listening on. Input kubectl get svc -n sockshop Output NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE carts-db ClusterIP 10.43.221.67 <none> 27017/TCP 34m carts ClusterIP 10.43.61.101 <none> 80/TCP 34m catalogue-db ClusterIP 10.43.57.198 <none> 3306/TCP 34m catalogue ClusterIP 10.43.216.173 <none> 80/TCP 34m orders-db ClusterIP 10.43.236.48 <none> 27017/TCP 34m orders ClusterIP 10.43.115.92 <none> 80/TCP 34m payment ClusterIP 10.43.242.227 <none> 80/TCP 34m queue-master ClusterIP 10.43.73.136 <none> 80/TCP 34m rabbitmq ClusterIP 10.43.113.211 <none> 5672/TCP 34m shipping ClusterIP 10.43.250.115 <none> 80/TCP 34m user-db ClusterIP 10.43.152.153 <none> 27017/TCP 34m user ClusterIP 10.43.45.155 <none> 80/TCP 34m front-end LoadBalancer 10.43.247.97 192.168.64.35 8082:30001/TCP 34m Make note of the EXTERNAL-IP (in the example above this is 192.168.64.35 ). Then head over to your web browser and type in http://{EXTERNAL-IP}:8081 , you should then be able to see the application running. Happy Shopping! Use the Next link in the footer below to continue the workshop","title":"6. Viewing the SockShop application in your browser"},{"location":"module7/","text":"Coming Soon! \u00b6 Use the Next link in the footer below to continue the workshop","title":"Coming Soon!"},{"location":"module7/#coming-soon","text":"Use the Next link in the footer below to continue the workshop","title":"Coming Soon!"},{"location":"modules/module8/","text":"\u00b5APM architecture \u00b6 SignalFx \u00b5APM captures end-to-end distributed transactions from your applications, with trace spans sent directly to SignalFx or via the SignalFx Smart Agent deployed on each host (recommended). Optionally, you can deploy an OpenTelemetry Collector to act as a central aggregation point prior to sending trace spans to SignalFx. In addition to proxying spans and infrastructure metrics, the OpenTelemetry Collector can also perform other functions, such as redacting sensitive tags prior to spans leaving your environment. The following illustrations show the recommended deployment model: SignalFx auto-instrumentation libraries send spans to the Smart Agent; the Smart Agent can send the spans to SignalFx directly or via an optional OpenTelemetry Collector.","title":"Index"},{"location":"modules/module8/#apm-architecture","text":"SignalFx \u00b5APM captures end-to-end distributed transactions from your applications, with trace spans sent directly to SignalFx or via the SignalFx Smart Agent deployed on each host (recommended). Optionally, you can deploy an OpenTelemetry Collector to act as a central aggregation point prior to sending trace spans to SignalFx. In addition to proxying spans and infrastructure metrics, the OpenTelemetry Collector can also perform other functions, such as redacting sensitive tags prior to spans leaving your environment. The following illustrations show the recommended deployment model: SignalFx auto-instrumentation libraries send spans to the Smart Agent; the Smart Agent can send the spans to SignalFx directly or via an optional OpenTelemetry Collector.","title":"\u00b5APM architecture"},{"location":"modules/module8/hotrod/","text":"Enabling \u00b5APM on EKS \u00b6 An organisation needs to be pre-provisioned as a \u00b5APM entitlement is required for the purposes of this module. Please contact someone from SignalFx to get a trial instance with \u00b5APM enabled if you don\u2019t have one already. To check if you have an organisation with \u00b5APM enabled, just login to SignalFx and check that you have the \u00b5APM tab on the top navbar next to Dashboards. 1. Requirements and Document Conventions \u00b6 This workshop is tested on MacOS and Linux- it should work on Windows as well if requirements are met. Tips, references, and troubleshooting tips for these components are in the appendix. The previous workshops should have been completed such that you have the following variables at the ready: SignalFx token SignalFx realm Document Conventions \u00b6 Variables that require you to alter them based on information in your environment are displayed like this: YOURVARIABLEHERE. For example if you need to set your realm to us1 in a hostname you'd change api.YOURREALMHERE.signalfx.com to api.us1.signalfx.com Requirements \u00b6 For this workshop you must have the following installed: AWS CLI Helm eksctl kubectl Instructions are below- note that official instructions may change over time from this document. 1a Step 1: Install AWS CLI \u00b6 You should have basic familiary with AWS, your account especially access key/ID and default region, and associated administration. AWS CLI Official Instructions: https://docs.aws.amazon.com/cli/ Macos brew install awscli` Linux `curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\" ` `unzip awscliv2.zip` `sudo ./aws/install` Windows Download and execute: https://awscli.amazonaws.com/AWSCLIV2.msi 1a Step 2: Configure AWS CLI for your account: \u00b6 aws configure And enter the variables from your AWS account as shown below with sample values: AWS Access Key ID [None]: AKIAIOSFODNN7EXAMPLE AWS Secret Access Key [None]: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY Default region name [None]: us-west-2 Default output format [None]: json 1b Helm \u00b6 Helm Official Instructions: https://helm.sh/docs/intro/install/ Macos `brew install helm` Linux `sudo snap install helm --classic` Windows choco install kubernetes-helm` 1c eksctl \u00b6 eksctl Official Instructions: https://eksctl.io/introduction/installation/ Macos `brew tap weaveworks/tap` `brew install weaveworks/tap/eksctl` Linux `curl --silent --location \"https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz\" | tar xz -C /tmp` `sudo mv /tmp/eksctl /usr/local/bin` Windows `chocolatey install eksctl` 1d kubectl: \u00b6 Macos `brew install kubectl Linux ``text curl -LO https://storage.googleapis.com/kubernetes-release/release/curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt/bin/linux/amd64/kubectl` chmod +x ./kubectl sudo mv ./kubectl /usr/local/bin/kubectl Windows `curl -LO https://storage.googleapis.com/kubernetes-release/release/v1.18.0/bin/windows/amd64/kubectl.exe` 1. Create a cluster running Amazon Elastic Kubernetes (EKS) Service \u00b6 eksctl create cluster \\ --name YOUREKSCLUSTERNAMEHERE \\ --region YOURAWSREGIONHERE FOR EXAMPLE us-east-2 \\ --node-type t3.medium \\ --nodes-min 3 \\ --nodes-max 7 \\ --version=1.15 This may take some time- ensure you see your cluster live in AWS EKS console before proceeding. 2. Deploy SignalFx SmartAgent to your EKS Cluster \u00b6 Check release version: https://github.com/signalfx/signalfx-agent/releases i.e. 5.1.1 Input helm repo add signalfx https://dl.signalfx.com/helm-repo Output helm repo update helm install --set signalFxAccessToken=TOKENHERE --set clusterName=YOURK8SCLUSTERNAME --set signalFxRealm=YOUREALMHERE --set agentVersion=RELEASEVERSIONHERE --set kubeletAPI.url=https://localhost:10250 signalfx-agent signalfx/signalfx-agent Validate cluster looks healthy in SignalFx Kubernetes Navigator dashboard 3. Update SignalFX Agent Deployment in K8S for APM \u00b6 This repo file: /app-dev-workshop/apm/hotrod/eks/agent-apm.yaml has elements needed for APM. Substitute YOURAPMENVIRONMENTHERE with your chosen application environment name i.e. KarthikHotRodApp and YOUREALMHERE with your realm as identified in your SignalFx profile i.e. us1 . After udpating /app-dev-workshop/apm/hotrod/eks/agent-apm.yaml then from the directory above the repo: helm upgrade --reuse-values -f ./app-dev-workshop/apm/hotrod/eks/agent-apm.yaml signalfx-agent signalfx/signalfx-agent 4. Deploy Hotrod Application to EKS \u00b6 kubectl apply -f . /app-dev-workshop/apm/hotrod/eks/deployment.yaml To ensure the Hotrod application is running see examples below: Input kubectl get pods Output NAME READY STATUS RESTARTS AGE hotrod-7564774bf5-vjpfw 1/1 Running 0 47h signalfx-agent-jmq4f 1/1 Running 0 138m signalfx-agent-nk8p9 1/1 Running 0 138m signalfx-agent-q5tzh 1/1 Running 0 138m You then need find the IP address assigned to the Hotrod service: Input kubectl get svc Output NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE hotrod LoadBalancer 10.100.188.249 af26ce80ef2e14c9292ae5b4bc0d2dd0-1826890352.us-east-2.elb.amazonaws.com 8080:32521/TCP 47h kubernetes ClusterIP 10.100.0.1 <none> 443/TCP 3d1h Make note of the CLUSTER-IP address associated with Hotrod You can view / exercise Hotrod yourself in a browser by opening the IP:PORT as shown above i.e. https://af26ce80ef2e14c9292ae5b4bc0d2dd0-1826890352.us-east-2.elb.amazonaws.com:8080 5. Generate some traffic to the application using Apache Benchmark \u00b6 ab -n100 -c10 \"http://{CLUSTER-IP}:8080/dispatch?customer=392&nonse=0.17041229755366172\" & Create some errors with an invalid customer number ab -n100 -c10 \"http://{CLUSTER-IP}:8080/dispatch?customer=391&nonse=0.17041229755366172\" & You should now be able to exercise SignalFx APM dashboards. https://af26ce80ef2e14c9292ae5b4bc0d2dd0-1826890352.us-east-2.elb.amazonaws.com:8080 5. Deleting resources \u00b6 To delete entire EKS cluster: eksctl delete cluster YOURCLUSTERNAMEHERE Or to delete individual components: kubectl delete deploy/hotrod svc/hotrod helm delete signalfx-agent Appendix: Tips, Troubleshooting, and References \u00b6 Set AWS EKS context to your cluster (i.e. when switching machines) \u00b6 aws eks --region YOURAWSREGION update-kubeconfig --name YOURCLUSTERNAME Ensure kubectl context is correct \u00b6 kubectl config get-contexts Will display list of contexts kubectl config use-context YOURCLUSTERNAME Will set the default context to cluster with ARN: YOURCLUSTERNAME Set up kubectl for EKS \u00b6 aws eks --region YOURREGION update-kubeconfig --name YOURCLUSTERNAME kubectl get pods --kubeconfig ./.kube/config kubectl get svc Check SignalFx Agent Values \u00b6 helm get values signalfx-agent -a kubectl reference \u00b6 https://kubernetes.io/docs/reference/kubectl/cheatsheet/","title":"Hotrod"},{"location":"modules/module8/hotrod/#enabling-apm-on-eks","text":"An organisation needs to be pre-provisioned as a \u00b5APM entitlement is required for the purposes of this module. Please contact someone from SignalFx to get a trial instance with \u00b5APM enabled if you don\u2019t have one already. To check if you have an organisation with \u00b5APM enabled, just login to SignalFx and check that you have the \u00b5APM tab on the top navbar next to Dashboards.","title":"Enabling \u00b5APM on EKS"},{"location":"modules/module8/hotrod/#1-requirements-and-document-conventions","text":"This workshop is tested on MacOS and Linux- it should work on Windows as well if requirements are met. Tips, references, and troubleshooting tips for these components are in the appendix. The previous workshops should have been completed such that you have the following variables at the ready: SignalFx token SignalFx realm","title":"1. Requirements and Document Conventions"},{"location":"modules/module8/hotrod/#document-conventions","text":"Variables that require you to alter them based on information in your environment are displayed like this: YOURVARIABLEHERE. For example if you need to set your realm to us1 in a hostname you'd change api.YOURREALMHERE.signalfx.com to api.us1.signalfx.com","title":"Document Conventions"},{"location":"modules/module8/hotrod/#requirements","text":"For this workshop you must have the following installed: AWS CLI Helm eksctl kubectl Instructions are below- note that official instructions may change over time from this document.","title":"Requirements"},{"location":"modules/module8/hotrod/#1a-step-1-install-aws-cli","text":"You should have basic familiary with AWS, your account especially access key/ID and default region, and associated administration. AWS CLI Official Instructions: https://docs.aws.amazon.com/cli/ Macos brew install awscli` Linux `curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\" ` `unzip awscliv2.zip` `sudo ./aws/install` Windows Download and execute: https://awscli.amazonaws.com/AWSCLIV2.msi","title":"1a Step 1: Install AWS CLI"},{"location":"modules/module8/hotrod/#1a-step-2-configure-aws-cli-for-your-account","text":"aws configure And enter the variables from your AWS account as shown below with sample values: AWS Access Key ID [None]: AKIAIOSFODNN7EXAMPLE AWS Secret Access Key [None]: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY Default region name [None]: us-west-2 Default output format [None]: json","title":"1a Step 2: Configure AWS CLI for your account:"},{"location":"modules/module8/hotrod/#1b-helm","text":"Helm Official Instructions: https://helm.sh/docs/intro/install/ Macos `brew install helm` Linux `sudo snap install helm --classic` Windows choco install kubernetes-helm`","title":"1b Helm"},{"location":"modules/module8/hotrod/#1c-eksctl","text":"eksctl Official Instructions: https://eksctl.io/introduction/installation/ Macos `brew tap weaveworks/tap` `brew install weaveworks/tap/eksctl` Linux `curl --silent --location \"https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz\" | tar xz -C /tmp` `sudo mv /tmp/eksctl /usr/local/bin` Windows `chocolatey install eksctl`","title":"1c eksctl"},{"location":"modules/module8/hotrod/#1d-kubectl","text":"Macos `brew install kubectl Linux ``text curl -LO https://storage.googleapis.com/kubernetes-release/release/curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt/bin/linux/amd64/kubectl` chmod +x ./kubectl sudo mv ./kubectl /usr/local/bin/kubectl Windows `curl -LO https://storage.googleapis.com/kubernetes-release/release/v1.18.0/bin/windows/amd64/kubectl.exe`","title":"1d kubectl:"},{"location":"modules/module8/hotrod/#1-create-a-cluster-running-amazon-elastic-kubernetes-eks-service","text":"eksctl create cluster \\ --name YOUREKSCLUSTERNAMEHERE \\ --region YOURAWSREGIONHERE FOR EXAMPLE us-east-2 \\ --node-type t3.medium \\ --nodes-min 3 \\ --nodes-max 7 \\ --version=1.15 This may take some time- ensure you see your cluster live in AWS EKS console before proceeding.","title":"1. Create a cluster running Amazon Elastic Kubernetes (EKS) Service"},{"location":"modules/module8/hotrod/#2-deploy-signalfx-smartagent-to-your-eks-cluster","text":"Check release version: https://github.com/signalfx/signalfx-agent/releases i.e. 5.1.1 Input helm repo add signalfx https://dl.signalfx.com/helm-repo Output helm repo update helm install --set signalFxAccessToken=TOKENHERE --set clusterName=YOURK8SCLUSTERNAME --set signalFxRealm=YOUREALMHERE --set agentVersion=RELEASEVERSIONHERE --set kubeletAPI.url=https://localhost:10250 signalfx-agent signalfx/signalfx-agent Validate cluster looks healthy in SignalFx Kubernetes Navigator dashboard","title":"2. Deploy SignalFx SmartAgent to your EKS Cluster"},{"location":"modules/module8/hotrod/#3-update-signalfx-agent-deployment-in-k8s-for-apm","text":"This repo file: /app-dev-workshop/apm/hotrod/eks/agent-apm.yaml has elements needed for APM. Substitute YOURAPMENVIRONMENTHERE with your chosen application environment name i.e. KarthikHotRodApp and YOUREALMHERE with your realm as identified in your SignalFx profile i.e. us1 . After udpating /app-dev-workshop/apm/hotrod/eks/agent-apm.yaml then from the directory above the repo: helm upgrade --reuse-values -f ./app-dev-workshop/apm/hotrod/eks/agent-apm.yaml signalfx-agent signalfx/signalfx-agent","title":"3. Update SignalFX Agent Deployment in K8S for APM"},{"location":"modules/module8/hotrod/#4-deploy-hotrod-application-to-eks","text":"kubectl apply -f . /app-dev-workshop/apm/hotrod/eks/deployment.yaml To ensure the Hotrod application is running see examples below: Input kubectl get pods Output NAME READY STATUS RESTARTS AGE hotrod-7564774bf5-vjpfw 1/1 Running 0 47h signalfx-agent-jmq4f 1/1 Running 0 138m signalfx-agent-nk8p9 1/1 Running 0 138m signalfx-agent-q5tzh 1/1 Running 0 138m You then need find the IP address assigned to the Hotrod service: Input kubectl get svc Output NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE hotrod LoadBalancer 10.100.188.249 af26ce80ef2e14c9292ae5b4bc0d2dd0-1826890352.us-east-2.elb.amazonaws.com 8080:32521/TCP 47h kubernetes ClusterIP 10.100.0.1 <none> 443/TCP 3d1h Make note of the CLUSTER-IP address associated with Hotrod You can view / exercise Hotrod yourself in a browser by opening the IP:PORT as shown above i.e. https://af26ce80ef2e14c9292ae5b4bc0d2dd0-1826890352.us-east-2.elb.amazonaws.com:8080","title":"4. Deploy Hotrod Application to EKS"},{"location":"modules/module8/hotrod/#5-generate-some-traffic-to-the-application-using-apache-benchmark","text":"ab -n100 -c10 \"http://{CLUSTER-IP}:8080/dispatch?customer=392&nonse=0.17041229755366172\" & Create some errors with an invalid customer number ab -n100 -c10 \"http://{CLUSTER-IP}:8080/dispatch?customer=391&nonse=0.17041229755366172\" & You should now be able to exercise SignalFx APM dashboards. https://af26ce80ef2e14c9292ae5b4bc0d2dd0-1826890352.us-east-2.elb.amazonaws.com:8080","title":"5. Generate some traffic to the application using Apache Benchmark"},{"location":"modules/module8/hotrod/#5-deleting-resources","text":"To delete entire EKS cluster: eksctl delete cluster YOURCLUSTERNAMEHERE Or to delete individual components: kubectl delete deploy/hotrod svc/hotrod helm delete signalfx-agent","title":"5. Deleting resources"},{"location":"modules/module8/hotrod/#appendix-tips-troubleshooting-and-references","text":"","title":"Appendix: Tips, Troubleshooting, and References"},{"location":"modules/module8/hotrod/#set-aws-eks-context-to-your-cluster-ie-when-switching-machines","text":"aws eks --region YOURAWSREGION update-kubeconfig --name YOURCLUSTERNAME","title":"Set AWS EKS context to your cluster (i.e. when switching machines)"},{"location":"modules/module8/hotrod/#ensure-kubectl-context-is-correct","text":"kubectl config get-contexts Will display list of contexts kubectl config use-context YOURCLUSTERNAME Will set the default context to cluster with ARN: YOURCLUSTERNAME","title":"Ensure kubectl context is correct"},{"location":"modules/module8/hotrod/#set-up-kubectl-for-eks","text":"aws eks --region YOURREGION update-kubeconfig --name YOURCLUSTERNAME kubectl get pods --kubeconfig ./.kube/config kubectl get svc","title":"Set up kubectl for EKS"},{"location":"modules/module8/hotrod/#check-signalfx-agent-values","text":"helm get values signalfx-agent -a","title":"Check SignalFx Agent Values"},{"location":"modules/module8/hotrod/#kubectl-reference","text":"https://kubernetes.io/docs/reference/kubectl/cheatsheet/","title":"kubectl reference"}]}