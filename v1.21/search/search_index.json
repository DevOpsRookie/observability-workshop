{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"","title":"Home"},{"location":"apm/","text":"\u00b5APM Architecture Overview \u00b6 Enabling \u00b5APM An Organization needs to be pre-provisioned as a \u00b5APM entitlement is required for the purposes of this module. Please contact someone from SignalFx to get a trial instance with \u00b5APM enabled if you don\u2019t have one already. To check if you have an Organization with \u00b5APM enabled, just login to SignalFx and check that you have the \u00b5APM tab on the top navbar next to Dashboards. SignalFx \u00b5APM captures end-to-end distributed transactions from your applications, with trace spans sent directly to SignalFx or via the SignalFx Smart Agent deployed on each host (recommended). Optionally, you can deploy an OpenTelemetry Collector to act as a central aggregation point prior to sending trace spans to SignalFx. In addition to proxying spans and infrastructure metrics, the OpenTelemetry Collector can also perform other functions, such as redacting sensitive tags prior to spans leaving your environment. The following illustration shows the recommended deployment model: SignalFx auto-instrumentation libraries send spans to the Smart Agent; the Smart Agent can send the spans to SignalFx directly or via an optional OpenTelemetry Collector.","title":"\u00b5APM Architecture Overview"},{"location":"apm/#apm-architecture-overview","text":"Enabling \u00b5APM An Organization needs to be pre-provisioned as a \u00b5APM entitlement is required for the purposes of this module. Please contact someone from SignalFx to get a trial instance with \u00b5APM enabled if you don\u2019t have one already. To check if you have an Organization with \u00b5APM enabled, just login to SignalFx and check that you have the \u00b5APM tab on the top navbar next to Dashboards. SignalFx \u00b5APM captures end-to-end distributed transactions from your applications, with trace spans sent directly to SignalFx or via the SignalFx Smart Agent deployed on each host (recommended). Optionally, you can deploy an OpenTelemetry Collector to act as a central aggregation point prior to sending trace spans to SignalFx. In addition to proxying spans and infrastructure metrics, the OpenTelemetry Collector can also perform other functions, such as redacting sensitive tags prior to spans leaving your environment. The following illustration shows the recommended deployment model: SignalFx auto-instrumentation libraries send spans to the Smart Agent; the Smart Agent can send the spans to SignalFx directly or via an optional OpenTelemetry Collector.","title":"\u00b5APM Architecture Overview"},{"location":"apm/hotrod-trouble-depend/","text":"uAPM troubleshooting - Hot R.O.D.- Lab Summary \u00b6 Explore troubleshooting and dependencies interface in uAPM Use the Breakdown feature to enrich the troubleshooting info Examine a trace in waterfall mode Ensure you have a running instance that has the hot R.O.D app running The setup part is already documented in the Preparation , Deploy the Smart Agent in K3s and Deploying hot-rod in K3s steps. If you are using an AWS/EC2 instance, make sure it is available and skip to Step 1 , otherwise ensure your Multipass instance is available and running before continuing. Input multipass list Example Output Name State IPv4 Image vmpe-k3s Running 192.168.64.17 Ubuntu 18.04 LTS 1. Find a specific trace using time slots and/or tags \u00b6 For this use case we assume there is a problem reported with a clear time frame for an error. This is the case when a customer reports problems, for example at 15:05 yesterday, or when a log reports an issue at an exact time. Using the All Traces functionality, combined with using tags and/or services selections, we can find relevant traces, and dive into them to explore. 1.1 Select Application Environment \u00b6 First, we need to know the name of your application environment. In this workshop all the environments use your hostname -apm-env To find the hostname, check the prompt of you instance, please go to your instance (Multipass or EC2) and run the following command. Input echo \"Your \u00b5APM environment is: $( hostname ) -apm-env\" Example Multipass Output Your \u00b5APM environment is: vmpe-apm-env Example AWS/EC2 Output Your \u00b5APM environment is: ip-172-31-30-133-apm-env Open SignalFx in your browser and select the \u00b5APM tab. Select the Troubleshooting tab, and select your environment you found and set the time to 15 minutes. This will show you the automatically generated Dependency Map for the Hot R.O.D. application. Please note the Show Traces button at the bottom of the page: 1.2 View traces in the Trace List \u00b6 Now click the Show Traces button at the bottom of the page. this will start loading all the traces view, and if there are more then 25 it will show a selection. You can always hit the Search all traces link at the bottom of the page to fetch all traces for the time period. In the scenario we are working with, the reported error that we are looking for is seen in the frontend service, when trying to call to the customer service to update customer details. So the first activity for identifying the issue, is to pre-select both those services as a filter for the trace list. This will just show the traces that have both these services in the trace. 1.3 Filtering traces in the Trace List \u00b6 To do this, click on the services drop down at the top of the page and first select the frontend service. Then click on the button to add a new line, then select the customer service. On first review this step has not brought any visual changes, but there was a 3rd item we can use, we can filter on a specific time frame. In the previous lab, you should have noted down a time, we are going to use that to filter the traces to that specific time slot. 1.4 Filtering traces in the Trace List \u00b6 To do this, click on the duration drop down, (It should show -15m) and create a custom time slot. You can set the current time by clicking on the little clock icon behind the time entry slot. Make sure the time you noted down is in the range you set in the FROM and TO boxes. Keep the range as short as possible for the best result. then hot the apply button to search for traces matching the filter in this time frame. If you have set your time range correctly you should now see a change, an extra column appears called Root Error . indicating that the trace contains the original error. To see the actual trace with the error, click on the blue linked TraceID in the TraceID column This will bring you to the Trace Waterfall view, allowing you to inspect the trace in detail. 2. Examine traces in the waterfall view \u00b6 3. Explore the troubleshooting and dependencies view \u00b6 4. Use the breakdown feature to enrich troubleshooting info \u00b6","title":"uAPm Troubleshooting - dependencies based"},{"location":"apm/hotrod-trouble-depend/#uapm-troubleshooting-hot-rod-lab-summary","text":"Explore troubleshooting and dependencies interface in uAPM Use the Breakdown feature to enrich the troubleshooting info Examine a trace in waterfall mode Ensure you have a running instance that has the hot R.O.D app running The setup part is already documented in the Preparation , Deploy the Smart Agent in K3s and Deploying hot-rod in K3s steps. If you are using an AWS/EC2 instance, make sure it is available and skip to Step 1 , otherwise ensure your Multipass instance is available and running before continuing. Input multipass list Example Output Name State IPv4 Image vmpe-k3s Running 192.168.64.17 Ubuntu 18.04 LTS","title":"uAPM troubleshooting - Hot R.O.D.- Lab Summary"},{"location":"apm/hotrod-trouble-depend/#1-find-a-specific-trace-using-time-slots-andor-tags","text":"For this use case we assume there is a problem reported with a clear time frame for an error. This is the case when a customer reports problems, for example at 15:05 yesterday, or when a log reports an issue at an exact time. Using the All Traces functionality, combined with using tags and/or services selections, we can find relevant traces, and dive into them to explore.","title":"1. Find a specific trace using time slots and/or tags"},{"location":"apm/hotrod-trouble-depend/#11-select-application-environment","text":"First, we need to know the name of your application environment. In this workshop all the environments use your hostname -apm-env To find the hostname, check the prompt of you instance, please go to your instance (Multipass or EC2) and run the following command. Input echo \"Your \u00b5APM environment is: $( hostname ) -apm-env\" Example Multipass Output Your \u00b5APM environment is: vmpe-apm-env Example AWS/EC2 Output Your \u00b5APM environment is: ip-172-31-30-133-apm-env Open SignalFx in your browser and select the \u00b5APM tab. Select the Troubleshooting tab, and select your environment you found and set the time to 15 minutes. This will show you the automatically generated Dependency Map for the Hot R.O.D. application. Please note the Show Traces button at the bottom of the page:","title":"1.1 Select Application Environment"},{"location":"apm/hotrod-trouble-depend/#12-view-traces-in-the-trace-list","text":"Now click the Show Traces button at the bottom of the page. this will start loading all the traces view, and if there are more then 25 it will show a selection. You can always hit the Search all traces link at the bottom of the page to fetch all traces for the time period. In the scenario we are working with, the reported error that we are looking for is seen in the frontend service, when trying to call to the customer service to update customer details. So the first activity for identifying the issue, is to pre-select both those services as a filter for the trace list. This will just show the traces that have both these services in the trace.","title":"1.2 View traces in the Trace List"},{"location":"apm/hotrod-trouble-depend/#13-filtering-traces-in-the-trace-list","text":"To do this, click on the services drop down at the top of the page and first select the frontend service. Then click on the button to add a new line, then select the customer service. On first review this step has not brought any visual changes, but there was a 3rd item we can use, we can filter on a specific time frame. In the previous lab, you should have noted down a time, we are going to use that to filter the traces to that specific time slot.","title":"1.3 Filtering traces in the Trace List"},{"location":"apm/hotrod-trouble-depend/#14-filtering-traces-in-the-trace-list","text":"To do this, click on the duration drop down, (It should show -15m) and create a custom time slot. You can set the current time by clicking on the little clock icon behind the time entry slot. Make sure the time you noted down is in the range you set in the FROM and TO boxes. Keep the range as short as possible for the best result. then hot the apply button to search for traces matching the filter in this time frame. If you have set your time range correctly you should now see a change, an extra column appears called Root Error . indicating that the trace contains the original error. To see the actual trace with the error, click on the blue linked TraceID in the TraceID column This will bring you to the Trace Waterfall view, allowing you to inspect the trace in detail.","title":"1.4 Filtering traces in the Trace List"},{"location":"apm/hotrod-trouble-depend/#2-examine-traces-in-the-waterfall-view","text":"","title":"2. Examine traces in the waterfall view"},{"location":"apm/hotrod-trouble-depend/#3-explore-the-troubleshooting-and-dependencies-view","text":"","title":"3. Explore the troubleshooting and dependencies view"},{"location":"apm/hotrod-trouble-depend/#4-use-the-breakdown-feature-to-enrich-troubleshooting-info","text":"","title":"4. Use the breakdown feature to enrich troubleshooting info"},{"location":"apm/hotrod-trouble-timebased/","text":"Troubleshooting Hot R.O.D. - Lab Summary \u00b6 Find APM Traces for a specific time period or by service Examine traces in the waterfall Discover the cause of the errors Ensure you have a running instance that has the Hot R.O.D. app running The setup part is already documented in the Preparation , Deploy the Smart Agent in K3s and Deploying Hot R.O.D. in K3s steps. If you are using an AWS/EC2 instance, make sure it is available and skip to Step 1 , otherwise ensure your Multipass instance is available and running before continuing. Input multipass list Example Output Name State IPv4 Image vmpe-k3s Running 192.168.64.17 Ubuntu 18.04 LTS 1. Traces and Spans explained \u00b6 A trace is a collection of spans that share the same trace ID, representing a unique transaction handled by your application and its constituent services. Each span has a name, representing the operation captured by this span, and a service name, representing within which service the operation took place. Additionally, spans may reference another span as their parent, defining the relationships between the operations captured in the trace that were performed to process that transaction. Each span contains a lot of information about the method, operation, or block of code that it captures, including: the operation name the start time of the operation with microsecond precision how long the operation took to execute, also with microsecond precision the logical name of the service on which the operation took place the IP address of the service instance on which the operation took place 2. Find a specific trace using time slots and/or tags \u00b6 For this use case we assume there is a problem reported with a clear time frame for an error. This is the case when a customer reports problems, for example at 15:05 yesterday, or when a log reports an issue at an exact time. Using the All Traces functionality, combined with using tags and/or services selections, we can find relevant traces, and dive into them to explore. 2.1 Select Application Environment \u00b6 First, we need to know the name of your application environment. In this workshop all the environments use your hostname -apm-env To find the hostname, check the prompt of you instance, please go to your instance (Multipass or EC2) and run the following command. Input echo \"Your \u00b5APM environment is: $( hostname ) -apm-env\" Example Multipass Output Your \u00b5APM environment is: vmpe-apm-env Example AWS/EC2 Output Your \u00b5APM environment is: ip-172-31-30-133-apm-env Open SignalFx in your browser and select the \u00b5APM tab. Select the Troubleshooting tab, and select your environment you found and set the time to 15 minutes. This will show you the automatically generated Dependency Map for the Hot R.O.D. application. Please note the Show Traces button at the bottom of the page: 2.2 View traces in the Trace List \u00b6 Now click the Show Traces button at the bottom of the page. This will start loading all the traces view, and if there are more then 25 it will show a selection. You can always hit the Search all traces link at the bottom of the page to fetch all traces for the time period. In the scenario we are working with, the reported error that we are looking for is seen in the frontend service, when trying to call to the customer service to update customer details. So the first activity for identifying the issue, is to pre-select both those services as a filter for the trace list. This will just show the traces that have both these services in the trace. 2.3 Filtering traces in the Trace List \u00b6 To do this, click on the services drop down at the top of the page and first select the frontend service. Then click on the button to add a new line, then select the customer service. On first review this step has not brought any visual changes, but there was a 3rd item we can use, we can filter on a specific time frame. In the previous lab, you should have noted down a time, we are going to use that to filter the traces to that specific time slot. 2.4 Filtering traces in the Trace List \u00b6 To do this, click on the duration drop down, (It should show -15m) and create a custom time slot. You can set the current time by clicking on the little clock icon behind the time entry slot. Make sure the time you noted down is in the range you set in the FROM and TO boxes. Keep the range as short as possible for the best result then hot the apply button to search for traces matching the filter in this time frame. If you have set your time range correctly you should now see a change, an extra column appears called Root Error . indicating that the trace contains the original error. To see the actual trace with the error, click on the blue linked TraceID in the TraceID column This will bring you to the Trace Waterfall view, allowing you to inspect the trace in detail. 3. Examine traces in the waterfall view \u00b6 You should now be in the Trace Waterfall view and your screen should like the view below: The waterfall shows you the trace or route a request/interaction has taken though your application. 4. Exploring the waterfall view \u00b6 As you can see from this trace, we have 3 front end spans, a customer span and a mysql span. The top frontend service has a deep red icon , this indicates that this service has returned with an error. The light red icon on the last frontend span, indicates that the it has received an error from an underlying service. The deep red icon on the customer service indicates that an error originates from that service. Now lets explore the waterfall view. First open the mysql span by clicking on the operation in the span label (SQL SELECT) to see what information is available in the tags that are part of this span. The TAGS section will help you to identify or search further for specific problems. There is information on your environment, your host and kubernetes related information, you can use to validate the health of theses platforms. You can also see information about the actual SQL query being performed. In this case \"SELECT * FROM customer WHERE customer_id=391\" Close the mysql span by clicking on the Operation in the span label again. Now click on the customer span, this is the span with a deep red icon and lets see if we can find the core of the problem. This will open the span info and look like this: You can see the various actions that are done by this service in the LOGS section. It is trying to load customer 391, and as we can see the request failed due an invalid customer ID.","title":"Troubleshooting Hot R.O.D."},{"location":"apm/hotrod-trouble-timebased/#troubleshooting-hot-rod-lab-summary","text":"Find APM Traces for a specific time period or by service Examine traces in the waterfall Discover the cause of the errors Ensure you have a running instance that has the Hot R.O.D. app running The setup part is already documented in the Preparation , Deploy the Smart Agent in K3s and Deploying Hot R.O.D. in K3s steps. If you are using an AWS/EC2 instance, make sure it is available and skip to Step 1 , otherwise ensure your Multipass instance is available and running before continuing. Input multipass list Example Output Name State IPv4 Image vmpe-k3s Running 192.168.64.17 Ubuntu 18.04 LTS","title":"Troubleshooting Hot R.O.D. - Lab Summary"},{"location":"apm/hotrod-trouble-timebased/#1-traces-and-spans-explained","text":"A trace is a collection of spans that share the same trace ID, representing a unique transaction handled by your application and its constituent services. Each span has a name, representing the operation captured by this span, and a service name, representing within which service the operation took place. Additionally, spans may reference another span as their parent, defining the relationships between the operations captured in the trace that were performed to process that transaction. Each span contains a lot of information about the method, operation, or block of code that it captures, including: the operation name the start time of the operation with microsecond precision how long the operation took to execute, also with microsecond precision the logical name of the service on which the operation took place the IP address of the service instance on which the operation took place","title":"1. Traces and Spans explained"},{"location":"apm/hotrod-trouble-timebased/#2-find-a-specific-trace-using-time-slots-andor-tags","text":"For this use case we assume there is a problem reported with a clear time frame for an error. This is the case when a customer reports problems, for example at 15:05 yesterday, or when a log reports an issue at an exact time. Using the All Traces functionality, combined with using tags and/or services selections, we can find relevant traces, and dive into them to explore.","title":"2. Find a specific trace using time slots and/or tags"},{"location":"apm/hotrod-trouble-timebased/#21-select-application-environment","text":"First, we need to know the name of your application environment. In this workshop all the environments use your hostname -apm-env To find the hostname, check the prompt of you instance, please go to your instance (Multipass or EC2) and run the following command. Input echo \"Your \u00b5APM environment is: $( hostname ) -apm-env\" Example Multipass Output Your \u00b5APM environment is: vmpe-apm-env Example AWS/EC2 Output Your \u00b5APM environment is: ip-172-31-30-133-apm-env Open SignalFx in your browser and select the \u00b5APM tab. Select the Troubleshooting tab, and select your environment you found and set the time to 15 minutes. This will show you the automatically generated Dependency Map for the Hot R.O.D. application. Please note the Show Traces button at the bottom of the page:","title":"2.1 Select Application Environment"},{"location":"apm/hotrod-trouble-timebased/#22-view-traces-in-the-trace-list","text":"Now click the Show Traces button at the bottom of the page. This will start loading all the traces view, and if there are more then 25 it will show a selection. You can always hit the Search all traces link at the bottom of the page to fetch all traces for the time period. In the scenario we are working with, the reported error that we are looking for is seen in the frontend service, when trying to call to the customer service to update customer details. So the first activity for identifying the issue, is to pre-select both those services as a filter for the trace list. This will just show the traces that have both these services in the trace.","title":"2.2 View traces in the Trace List"},{"location":"apm/hotrod-trouble-timebased/#23-filtering-traces-in-the-trace-list","text":"To do this, click on the services drop down at the top of the page and first select the frontend service. Then click on the button to add a new line, then select the customer service. On first review this step has not brought any visual changes, but there was a 3rd item we can use, we can filter on a specific time frame. In the previous lab, you should have noted down a time, we are going to use that to filter the traces to that specific time slot.","title":"2.3 Filtering traces in the Trace List"},{"location":"apm/hotrod-trouble-timebased/#24-filtering-traces-in-the-trace-list","text":"To do this, click on the duration drop down, (It should show -15m) and create a custom time slot. You can set the current time by clicking on the little clock icon behind the time entry slot. Make sure the time you noted down is in the range you set in the FROM and TO boxes. Keep the range as short as possible for the best result then hot the apply button to search for traces matching the filter in this time frame. If you have set your time range correctly you should now see a change, an extra column appears called Root Error . indicating that the trace contains the original error. To see the actual trace with the error, click on the blue linked TraceID in the TraceID column This will bring you to the Trace Waterfall view, allowing you to inspect the trace in detail.","title":"2.4 Filtering traces in the Trace List"},{"location":"apm/hotrod-trouble-timebased/#3-examine-traces-in-the-waterfall-view","text":"You should now be in the Trace Waterfall view and your screen should like the view below: The waterfall shows you the trace or route a request/interaction has taken though your application.","title":"3. Examine traces in the waterfall view"},{"location":"apm/hotrod-trouble-timebased/#4-exploring-the-waterfall-view","text":"As you can see from this trace, we have 3 front end spans, a customer span and a mysql span. The top frontend service has a deep red icon , this indicates that this service has returned with an error. The light red icon on the last frontend span, indicates that the it has received an error from an underlying service. The deep red icon on the customer service indicates that an error originates from that service. Now lets explore the waterfall view. First open the mysql span by clicking on the operation in the span label (SQL SELECT) to see what information is available in the tags that are part of this span. The TAGS section will help you to identify or search further for specific problems. There is information on your environment, your host and kubernetes related information, you can use to validate the health of theses platforms. You can also see information about the actual SQL query being performed. In this case \"SELECT * FROM customer WHERE customer_id=391\" Close the mysql span by clicking on the Operation in the span label again. Now click on the customer span, this is the span with a deep red icon and lets see if we can find the core of the problem. This will open the span info and look like this: You can see the various actions that are done by this service in the LOGS section. It is trying to load customer 391, and as we can see the request failed due an invalid customer ID.","title":"4. Exploring the waterfall view"},{"location":"apm/hotrod/","text":"Deploying Hot R.O.D. in K3s - Lab Summary \u00b6 Deploy the Hot R.O.D. application into Kubernetes (K3s) Verify the application is running Generate some artificial traffic See \u00b5APM data in the UI Ensure you have a running instance The setup part is already documented in the Preparation and Deploy the Smart Agent in K3s steps. If you are using an AWS/EC2 instance, make sure it is available and skip to Step 1 , otherwise ensure your Multipass instance is available and running before continuing. Input multipass list Example Output Name State IPv4 Image vmpe-k3s Running 192.168.64.17 Ubuntu 18.04 LTS 1. Deploy the Hot R.O.D. application into K3s \u00b6 To deploy the Hot R.O.D. application into K3s apply the deployment. Input cd ~/workshop kubectl apply -f apm/hotrod/k8s/deployment.yaml Output deployment.apps/hotrod created service/hotrod created To ensure the Hot R.O.D. application is running: Input kubectl get pods Example Output NAME READY STATUS RESTARTS AGE signalfx-agent-mmzxk 1/1 Running 0 110s hotrod-7cc9fc85b7-n765r 1/1 Running 0 41s 2. Viewing the Hot R.O.D. application in your browser \u00b6 AWC/EC2 Users If you are using an AWS/EC2 instance, the application will be available on port 8080 of the EC2 instance's IP address. Open your web browser and go to http:// EC2-IP :8080/ , you will then be able to see the application running. Then continue with the next section on how to Generate Traffic . In order to view the application in your web browser we need to find the LoadBalancer IP address and the port the application is listening on. Input kubectl get svc Example Output NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.43.0.1 <none> 443/TCP 43m hotrod LoadBalancer 10.43.32.97 192.168.64.35 8080:31521/TCP 40m Make note of the EXTERNAL-IP (in the example above this is 192.168.64.35 ). Open your web browser and type in http:// EXTERNAL-IP :8080 , you will then be able to see the application running. Click on customer name to order a car: 3. Generate some traffic to the application using Siege Benchmark \u00b6 Return to your shell and create an environment variable for the IP address and port that the Hot R.O.D. application is exposed on: Input HOTROD_ENDPOINT=$(kubectl get svc hotrod -n default -o jsonpath='{.spec.clusterIP}:{.spec.ports[0].port}') Confirm the environment variable is set Input curl $HOTROD_ENDPOINT Then run the following command(s) to create load on the service: Input siege -r2 -c20 \"http:// $HOTROD_ENDPOINT /dispatch?customer=392&nonse=0.17041229755366172\" Create some errors with an invalid customer number. Preparation For a follow up lab, make note of the current time. Input siege -r1 -c10 \"http:// $HOTROD_ENDPOINT /dispatch?customer=391&nonse=0.17041229755366172\" 4. Validating the Hot R.O.D. application in SignalFx \u00b6 Open the SignalFx UI, and go to you cluster in the Kubernetes Navigator. You should see the new Pod being started and containers being deployed. Usually it should only take around 20 seconds for the pod to transition into a Running state. When you click on the new pod in the SignalFx UI you should have a cluster that looks like below: If you select the WORKLOADS tab again you should now see that there is a new replica set and a deployment added for hotrod: Next, we want to validate that you are seeing the APM metrics in the UI. For this we need to know the name of your application environment. In this workshop all the environments use your hostname -apm-env . To find the hostname, check the prompt of you instance, please go to your instance (Multipass or AWS/EC2) and run the following command. Input echo \"Your \u00b5APM environment is: $( hostname ) -apm-env\" Example Output Your \u00b5APM environment is: ip-172-31-30-133-apm-env Now go to Dashboards \u2192 \u00b5APM \u2192 Service . Please select your environment you found in the previous task then select the frontend service and set time to -15m () No Data in charts if no data is visible, check that you have the right service frontend , and not front-end. To load the dashboard with more data run the following command a few times to create load on the service: Input siege -r2 -c20 \"http:// $HOTROD_ENDPOINT /dispatch?customer=392&nonse=0.17041229755366172\" With this automatically generated dashboard you can keep an eye out for the health of your service, it provides various performance related charts as well as relevant information on the underlying host and Kubernetes platform if applicable. Take some time to explore the various charts in this dashboard 5. Verify that \u00b5APM traces are reaching SignalFx \u00b6 Open SignalFx in your browser and select the \u00b5APM tab. Select the Troubleshooting tab, and select your environment you found before and set the time to 15 minutes. This will show you the automatically generated Dependency Map for the Hot R.O.D. application. It should look similar to the screenshot below: Warning If the screen looks very different you may by accident have selected the Previous Generation of APM ( \u00b5APM PG ) from the menu bar. To rectify this, go back and select the \u00b5APM tab. The legend at the bottom of the page explains the different visualizations in the Dependency Map. Service requests, error rate and root error rate. Request rate, latency and error rate Also in this view you can see the overall Error and Latency rates over time charts.","title":"Deploying Hot R.O.D. in K3s"},{"location":"apm/hotrod/#deploying-hot-rod-in-k3s-lab-summary","text":"Deploy the Hot R.O.D. application into Kubernetes (K3s) Verify the application is running Generate some artificial traffic See \u00b5APM data in the UI Ensure you have a running instance The setup part is already documented in the Preparation and Deploy the Smart Agent in K3s steps. If you are using an AWS/EC2 instance, make sure it is available and skip to Step 1 , otherwise ensure your Multipass instance is available and running before continuing. Input multipass list Example Output Name State IPv4 Image vmpe-k3s Running 192.168.64.17 Ubuntu 18.04 LTS","title":"Deploying Hot R.O.D. in K3s - Lab Summary"},{"location":"apm/hotrod/#1-deploy-the-hot-rod-application-into-k3s","text":"To deploy the Hot R.O.D. application into K3s apply the deployment. Input cd ~/workshop kubectl apply -f apm/hotrod/k8s/deployment.yaml Output deployment.apps/hotrod created service/hotrod created To ensure the Hot R.O.D. application is running: Input kubectl get pods Example Output NAME READY STATUS RESTARTS AGE signalfx-agent-mmzxk 1/1 Running 0 110s hotrod-7cc9fc85b7-n765r 1/1 Running 0 41s","title":"1. Deploy the Hot R.O.D. application into K3s"},{"location":"apm/hotrod/#2-viewing-the-hot-rod-application-in-your-browser","text":"AWC/EC2 Users If you are using an AWS/EC2 instance, the application will be available on port 8080 of the EC2 instance's IP address. Open your web browser and go to http:// EC2-IP :8080/ , you will then be able to see the application running. Then continue with the next section on how to Generate Traffic . In order to view the application in your web browser we need to find the LoadBalancer IP address and the port the application is listening on. Input kubectl get svc Example Output NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.43.0.1 <none> 443/TCP 43m hotrod LoadBalancer 10.43.32.97 192.168.64.35 8080:31521/TCP 40m Make note of the EXTERNAL-IP (in the example above this is 192.168.64.35 ). Open your web browser and type in http:// EXTERNAL-IP :8080 , you will then be able to see the application running. Click on customer name to order a car:","title":"2. Viewing the Hot R.O.D. application in your browser"},{"location":"apm/hotrod/#3-generate-some-traffic-to-the-application-using-siege-benchmark","text":"Return to your shell and create an environment variable for the IP address and port that the Hot R.O.D. application is exposed on: Input HOTROD_ENDPOINT=$(kubectl get svc hotrod -n default -o jsonpath='{.spec.clusterIP}:{.spec.ports[0].port}') Confirm the environment variable is set Input curl $HOTROD_ENDPOINT Then run the following command(s) to create load on the service: Input siege -r2 -c20 \"http:// $HOTROD_ENDPOINT /dispatch?customer=392&nonse=0.17041229755366172\" Create some errors with an invalid customer number. Preparation For a follow up lab, make note of the current time. Input siege -r1 -c10 \"http:// $HOTROD_ENDPOINT /dispatch?customer=391&nonse=0.17041229755366172\"","title":"3. Generate some traffic to the application using Siege Benchmark"},{"location":"apm/hotrod/#4-validating-the-hot-rod-application-in-signalfx","text":"Open the SignalFx UI, and go to you cluster in the Kubernetes Navigator. You should see the new Pod being started and containers being deployed. Usually it should only take around 20 seconds for the pod to transition into a Running state. When you click on the new pod in the SignalFx UI you should have a cluster that looks like below: If you select the WORKLOADS tab again you should now see that there is a new replica set and a deployment added for hotrod: Next, we want to validate that you are seeing the APM metrics in the UI. For this we need to know the name of your application environment. In this workshop all the environments use your hostname -apm-env . To find the hostname, check the prompt of you instance, please go to your instance (Multipass or AWS/EC2) and run the following command. Input echo \"Your \u00b5APM environment is: $( hostname ) -apm-env\" Example Output Your \u00b5APM environment is: ip-172-31-30-133-apm-env Now go to Dashboards \u2192 \u00b5APM \u2192 Service . Please select your environment you found in the previous task then select the frontend service and set time to -15m () No Data in charts if no data is visible, check that you have the right service frontend , and not front-end. To load the dashboard with more data run the following command a few times to create load on the service: Input siege -r2 -c20 \"http:// $HOTROD_ENDPOINT /dispatch?customer=392&nonse=0.17041229755366172\" With this automatically generated dashboard you can keep an eye out for the health of your service, it provides various performance related charts as well as relevant information on the underlying host and Kubernetes platform if applicable. Take some time to explore the various charts in this dashboard","title":"4. Validating the Hot R.O.D. application in SignalFx"},{"location":"apm/hotrod/#5-verify-that-apm-traces-are-reaching-signalfx","text":"Open SignalFx in your browser and select the \u00b5APM tab. Select the Troubleshooting tab, and select your environment you found before and set the time to 15 minutes. This will show you the automatically generated Dependency Map for the Hot R.O.D. application. It should look similar to the screenshot below: Warning If the screen looks very different you may by accident have selected the Previous Generation of APM ( \u00b5APM PG ) from the menu bar. To rectify this, go back and select the \u00b5APM tab. The legend at the bottom of the page explains the different visualizations in the Dependency Map. Service requests, error rate and root error rate. Request rate, latency and error rate Also in this view you can see the overall Error and Latency rates over time charts.","title":"5. Verify that \u00b5APM traces are reaching SignalFx"},{"location":"apm/sockshop/","text":"Deploying Sock Shop in K3s \u00b6 Note The setup part is already documented in the Preparation and Deploy the Smart Agent in K3s steps. Please ensure this instance is available and running before continuing. Input multipass list Output Name State IPv4 Image rwc-k3s Running 192.168.64.17 Ubuntu 18.04 LTS Warning The Sock Shop application requires some horse power to run it, please ensure you are running a Multipass or AWS/EC2 instance that can handle it. Sock Shop Multipass min. requirements: 4 vCPU, 15Gb Disk, 8Gb Memory Sock Shop AWS/EC2 min. requirements: t2.large 2 vCPU, 15Gb Disk, 8Gb Memory 1. Deploy the Sock Shop application into K3s \u00b6 To deploy the Sock Shop application into K3s apply the deployment Input cd ~/workshop/apm/sockshop kubectl create namespace sock-shop kubectl apply -f k8s/deployment.yaml Output namespace/sock-shop created deployment.apps/carts-db created service/carts-db created deployment.apps/carts created service/carts created deployment.apps/catalogue-db created service/catalogue-db created deployment.apps/catalogue created service/catalogue created deployment.apps/front-end created service/front-end created deployment.apps/orders-db created service/orders-db created deployment.apps/orders created service/orders created deployment.apps/payment created service/payment created deployment.apps/queue-master created service/queue-master created deployment.apps/rabbitmq created service/rabbitmq created deployment.apps/shipping created service/shipping created deployment.apps/user-db created service/user-db created deployment.apps/user created service/user created 2. Ensure Sock Shop is fully deployed \u00b6 To monitor the deployment of Sock Shop using k9s to monitor: Input k9s Once in k9s press 0 to show all namespaces: 3. Take Sock Shop for a test drive \u00b6 Sock Shop should be running in your cluster and exposes services via cluster IP and port. Obtain the ip address for the front-end service. Input export SOCKS_ENDPOINT = $( kubectl get svc front-end -n sock-shop -o jsonpath = '{.spec.clusterIP}:{.spec.ports[0].port}' ) Then confirm the SOCKS_ENDPOINT environment variable has been set: Input curl http:// $SOCKS_ENDPOINT Output ... </ script > </ body > </ html > 4. Viewing the SockShop application in your browser \u00b6 (If you are using an AWS/EC2 instance, please skip to this section.) To view the application in your web browser we need to find the LoadBalancer IP address and the port the application is listening on. Input kubectl get svc -n sock-shop front-end Output NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE front-end LoadBalancer 10.43.247.97 192.168.64.35 8081:30001/TCP 34m Make note of the EXTERNAL-IP (in the example above this is 192.168.64.35 ). Then head over to your web browser and type in http://[EXTERNAL-IP]:8081 , you should then be able to see the application running. Happy Shopping! 5. Apply load on Sock Shop \u00b6 A load testing scenario is available for the Sock Shop application. To generate some load run the following command: Input ./loadgen.sh -c 50 -r 3m The parameter -c controls the amount of concurrent clients and -r the runtime of the load test. To apply continuous load set -r to the desired runtime. The load test runs as a job in the K8S cluster. Observe the progress: Input kubectl -n sock-shop logs -f jobs/loadgen If you want to abort a load test, delete the job: Input kubectl -n sock-shop delete jobs/loadgen 6. Visualize and analyze trace data \u00b6 Navigate to \u00b5APM ( not \u00b5APM PG) and select Monitoring, then ensure you have selected your environment from the dropdown at the top, you should see something like this: 6.1. Explore the User Interface \u00b6 Review an automatically generated Service Dashboard. How do you correlate Service performance with Infrastructure? 6.2. Troubleshoot a service \u00b6 Let's stress the sock shop a bit. Increase the amount of clients running for the load test to something ludicrous, e.g.: Input ./loadgen.sh -c 1000 -a 100 -r 5m While the load test is running observe in SignalFx what happens with the services. Troubleshoot a service with a higher error rate. Also review the service dependencies. Look at individual traces and span performance.","title":"Deploying Sock Shop in K3s"},{"location":"apm/sockshop/#deploying-sock-shop-in-k3s","text":"Note The setup part is already documented in the Preparation and Deploy the Smart Agent in K3s steps. Please ensure this instance is available and running before continuing. Input multipass list Output Name State IPv4 Image rwc-k3s Running 192.168.64.17 Ubuntu 18.04 LTS Warning The Sock Shop application requires some horse power to run it, please ensure you are running a Multipass or AWS/EC2 instance that can handle it. Sock Shop Multipass min. requirements: 4 vCPU, 15Gb Disk, 8Gb Memory Sock Shop AWS/EC2 min. requirements: t2.large 2 vCPU, 15Gb Disk, 8Gb Memory","title":"Deploying Sock Shop in K3s"},{"location":"apm/sockshop/#1-deploy-the-sock-shop-application-into-k3s","text":"To deploy the Sock Shop application into K3s apply the deployment Input cd ~/workshop/apm/sockshop kubectl create namespace sock-shop kubectl apply -f k8s/deployment.yaml Output namespace/sock-shop created deployment.apps/carts-db created service/carts-db created deployment.apps/carts created service/carts created deployment.apps/catalogue-db created service/catalogue-db created deployment.apps/catalogue created service/catalogue created deployment.apps/front-end created service/front-end created deployment.apps/orders-db created service/orders-db created deployment.apps/orders created service/orders created deployment.apps/payment created service/payment created deployment.apps/queue-master created service/queue-master created deployment.apps/rabbitmq created service/rabbitmq created deployment.apps/shipping created service/shipping created deployment.apps/user-db created service/user-db created deployment.apps/user created service/user created","title":"1. Deploy the Sock Shop application into K3s"},{"location":"apm/sockshop/#2-ensure-sock-shop-is-fully-deployed","text":"To monitor the deployment of Sock Shop using k9s to monitor: Input k9s Once in k9s press 0 to show all namespaces:","title":"2. Ensure Sock Shop is fully deployed"},{"location":"apm/sockshop/#3-take-sock-shop-for-a-test-drive","text":"Sock Shop should be running in your cluster and exposes services via cluster IP and port. Obtain the ip address for the front-end service. Input export SOCKS_ENDPOINT = $( kubectl get svc front-end -n sock-shop -o jsonpath = '{.spec.clusterIP}:{.spec.ports[0].port}' ) Then confirm the SOCKS_ENDPOINT environment variable has been set: Input curl http:// $SOCKS_ENDPOINT Output ... </ script > </ body > </ html >","title":"3. Take Sock Shop for a test drive"},{"location":"apm/sockshop/#4-viewing-the-sockshop-application-in-your-browser","text":"(If you are using an AWS/EC2 instance, please skip to this section.) To view the application in your web browser we need to find the LoadBalancer IP address and the port the application is listening on. Input kubectl get svc -n sock-shop front-end Output NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE front-end LoadBalancer 10.43.247.97 192.168.64.35 8081:30001/TCP 34m Make note of the EXTERNAL-IP (in the example above this is 192.168.64.35 ). Then head over to your web browser and type in http://[EXTERNAL-IP]:8081 , you should then be able to see the application running. Happy Shopping!","title":"4. Viewing the SockShop application in your browser"},{"location":"apm/sockshop/#5-apply-load-on-sock-shop","text":"A load testing scenario is available for the Sock Shop application. To generate some load run the following command: Input ./loadgen.sh -c 50 -r 3m The parameter -c controls the amount of concurrent clients and -r the runtime of the load test. To apply continuous load set -r to the desired runtime. The load test runs as a job in the K8S cluster. Observe the progress: Input kubectl -n sock-shop logs -f jobs/loadgen If you want to abort a load test, delete the job: Input kubectl -n sock-shop delete jobs/loadgen","title":"5. Apply load on Sock Shop"},{"location":"apm/sockshop/#6-visualize-and-analyze-trace-data","text":"Navigate to \u00b5APM ( not \u00b5APM PG) and select Monitoring, then ensure you have selected your environment from the dropdown at the top, you should see something like this:","title":"6. Visualize and analyze trace data"},{"location":"apm/sockshop/#61-explore-the-user-interface","text":"Review an automatically generated Service Dashboard. How do you correlate Service performance with Infrastructure?","title":"6.1. Explore the User Interface"},{"location":"apm/sockshop/#62-troubleshoot-a-service","text":"Let's stress the sock shop a bit. Increase the amount of clients running for the load test to something ludicrous, e.g.: Input ./loadgen.sh -c 1000 -a 100 -r 5m While the load test is running observe in SignalFx what happens with the services. Troubleshoot a service with a higher error rate. Also review the service dependencies. Look at individual traces and span performance.","title":"6.2. Troubleshoot a service"},{"location":"dashboards/","text":"Working with Dashboards, Charts and Metrics \u00b6 Introduction to the SignalFx Dashboards and charts Editing and creating charts Filtering and analytical functions Using formulas Introduction to SignalFlow 1. Introduction to the SignalFx UI \u00b6 Logon to the SignalFx organization you have been invited to. Hover over DASHBOARDS in the top menu, and then click on All Dashboards . A number of prebuilt dashboards are provided for you in your default view. If you are already receiving metrics through a Cloud API integration or the Smart Agent you will see relevant dashboards for these services in SignalFx. Among the dashboards you will see a Dashboard group called Sample Data . This group exists by default in all SignalFx accounts. Let's take a closer look at it. 2. Inspecting the Sample Data \u00b6 In this dashboard view expand the Sample Data dashboard group by clicking on it, and then click on the Intro to SignalFx dashboard. You will see a selection of sample charts. To learn more about charts you can click on the other sample dashboards ( PART 1 , PART 2 and PART 3 ). Let's take a look at the Sample charts. Click on the SAMPLE CHARTS dashboard name. In the Sample Charts dashboard you can see a selection of charts that show a sample of the various styles, colors and formats you can apply to your charts in the dashboards.","title":"Introduction"},{"location":"dashboards/#working-with-dashboards-charts-and-metrics","text":"Introduction to the SignalFx Dashboards and charts Editing and creating charts Filtering and analytical functions Using formulas Introduction to SignalFlow","title":"Working with Dashboards, Charts and Metrics"},{"location":"dashboards/#1-introduction-to-the-signalfx-ui","text":"Logon to the SignalFx organization you have been invited to. Hover over DASHBOARDS in the top menu, and then click on All Dashboards . A number of prebuilt dashboards are provided for you in your default view. If you are already receiving metrics through a Cloud API integration or the Smart Agent you will see relevant dashboards for these services in SignalFx. Among the dashboards you will see a Dashboard group called Sample Data . This group exists by default in all SignalFx accounts. Let's take a closer look at it.","title":"1. Introduction to the SignalFx UI"},{"location":"dashboards/#2-inspecting-the-sample-data","text":"In this dashboard view expand the Sample Data dashboard group by clicking on it, and then click on the Intro to SignalFx dashboard. You will see a selection of sample charts. To learn more about charts you can click on the other sample dashboards ( PART 1 , PART 2 and PART 3 ). Let's take a look at the Sample charts. Click on the SAMPLE CHARTS dashboard name. In the Sample Charts dashboard you can see a selection of charts that show a sample of the various styles, colors and formats you can apply to your charts in the dashboards.","title":"2. Inspecting the Sample Data"},{"location":"dashboards/adding-charts/","text":"Adding charts to dashboards \u00b6 Let's now save our chart. Click on Save as... and enter a name for your chart; use your initials like [YOUR INITIALS] Latency Chart and click OK . In the next window, find your email address in the list and select it, then click OK . You will immediately be transported to the dashboard created under your selected group (make sure the group name on the top left is your email address). Last but not least, change the dashboard's name, by clicking the ... icon on the top right and selecting Rename . Enter a new name for your dashboard and click on Done . Congratulations! You have created your first chart and dashboard!","title":"Adding charts"},{"location":"dashboards/adding-charts/#adding-charts-to-dashboards","text":"Let's now save our chart. Click on Save as... and enter a name for your chart; use your initials like [YOUR INITIALS] Latency Chart and click OK . In the next window, find your email address in the list and select it, then click OK . You will immediately be transported to the dashboard created under your selected group (make sure the group name on the top left is your email address). Last but not least, change the dashboard's name, by clicking the ... icon on the top right and selecting Rename . Enter a new name for your dashboard and click on Done . Congratulations! You have created your first chart and dashboard!","title":"Adding charts to dashboards"},{"location":"dashboards/editing/","text":"Editing charts \u00b6 1. Edit Histogram Chart \u00b6 Click on the three dots ... on the Latency histogram chart in the Sample Data dashboard and then on Open (or you can click on the name of the chart which here is Latency histogram ). You will see the plot options, current plot and signal (metric) for the Latency histogram chart. Click on the different chart type icons to explore each of the visualizations. Notice their name while you click on or swipe over them. See how the chart changes. Note You can use different ways to visualize your metrics - you choose which chart type fits best for the visualization you want to have. For more info on the different chart types see Choosing a chart type . Click on the Line chart type and you will see the line plot. In the PLOT EDITOR tab under Signal you see the metric demo.trans.latency we are currently plotting. 2. Creating a new chart \u00b6 Let's now create a new chart and save it in a new dashboard! Click on the plus icon (top right of the UI) and from the drop down, click on Chart . You will now see a chart template like the following. Let's enter a metric to plot. We are going to use the metric demo.trans.latency . In the PLOT EDITOR tab under Signal enter demo.trans.latency . You will instantly see a number of Line plots, like below. The number 18 ts indicates that we are plotting 18 metric time series in the chart. Click on the DATA TABLE tab. You see now 18 rows, each representing a metics time series with a number of columns. If you swipe over the plot horizontally you will see the metrics in these columns at different times. In the demo_datacenter column you see that there are two data centers, Paris and Tokyo , for which we are getting metrics.","title":"Editing charts"},{"location":"dashboards/editing/#editing-charts","text":"","title":"Editing charts"},{"location":"dashboards/editing/#1-edit-histogram-chart","text":"Click on the three dots ... on the Latency histogram chart in the Sample Data dashboard and then on Open (or you can click on the name of the chart which here is Latency histogram ). You will see the plot options, current plot and signal (metric) for the Latency histogram chart. Click on the different chart type icons to explore each of the visualizations. Notice their name while you click on or swipe over them. See how the chart changes. Note You can use different ways to visualize your metrics - you choose which chart type fits best for the visualization you want to have. For more info on the different chart types see Choosing a chart type . Click on the Line chart type and you will see the line plot. In the PLOT EDITOR tab under Signal you see the metric demo.trans.latency we are currently plotting.","title":"1. Edit Histogram Chart"},{"location":"dashboards/editing/#2-creating-a-new-chart","text":"Let's now create a new chart and save it in a new dashboard! Click on the plus icon (top right of the UI) and from the drop down, click on Chart . You will now see a chart template like the following. Let's enter a metric to plot. We are going to use the metric demo.trans.latency . In the PLOT EDITOR tab under Signal enter demo.trans.latency . You will instantly see a number of Line plots, like below. The number 18 ts indicates that we are plotting 18 metric time series in the chart. Click on the DATA TABLE tab. You see now 18 rows, each representing a metics time series with a number of columns. If you swipe over the plot horizontally you will see the metrics in these columns at different times. In the demo_datacenter column you see that there are two data centers, Paris and Tokyo , for which we are getting metrics.","title":"2. Creating a new chart"},{"location":"dashboards/filtering/","text":"Using Filters \u00b6 1. Filtering and Analytics \u00b6 Let's now select the Paris datacenter to do some analytics - for that we will use a filter. Let's go back to the PLOT EDITOR tab and click on Add filter , wait until it automatically populates, choose demo_datacenter , and then Paris . In the F(x) column, add the analytic function Percentile:Aggregation , and leave the value to 95 (click outside to confirm). For info on the Percentile function and the other functions see Analytics reference . 2. Using Timeshift analytical function \u00b6 Let's now compare with older metrics. Click on ... and then on Clone in the dropdown to clone Signal A . You will see a new row identical to A , called B , both visible and plotted. For Signal B , in the F(x) column add the analytic function Timeshift and enter 7d (7 days = 1 week), and click outside to confirm. Click on the cog on the far right, and choose a Plot Color e.g. pink, to change color for the plot of B . Click on Close . Next, click into the field next to Time on the Override bar and choose Past Day from the dropdown. We now see plots for Signal A (the last day) as a blue plot, and 7 days ago in pink. In order to make this clearer we can click on the Area chart icon to change the visualization. We now have a better view of our two plots!","title":"Using filters"},{"location":"dashboards/filtering/#using-filters","text":"","title":"Using Filters"},{"location":"dashboards/filtering/#1-filtering-and-analytics","text":"Let's now select the Paris datacenter to do some analytics - for that we will use a filter. Let's go back to the PLOT EDITOR tab and click on Add filter , wait until it automatically populates, choose demo_datacenter , and then Paris . In the F(x) column, add the analytic function Percentile:Aggregation , and leave the value to 95 (click outside to confirm). For info on the Percentile function and the other functions see Analytics reference .","title":"1. Filtering and Analytics"},{"location":"dashboards/filtering/#2-using-timeshift-analytical-function","text":"Let's now compare with older metrics. Click on ... and then on Clone in the dropdown to clone Signal A . You will see a new row identical to A , called B , both visible and plotted. For Signal B , in the F(x) column add the analytic function Timeshift and enter 7d (7 days = 1 week), and click outside to confirm. Click on the cog on the far right, and choose a Plot Color e.g. pink, to change color for the plot of B . Click on Close . Next, click into the field next to Time on the Override bar and choose Past Day from the dropdown. We now see plots for Signal A (the last day) as a blue plot, and 7 days ago in pink. In order to make this clearer we can click on the Area chart icon to change the visualization. We now have a better view of our two plots!","title":"2. Using Timeshift analytical function"},{"location":"dashboards/formulas/","text":"Using Formulas \u00b6 1. Plotting differences \u00b6 Let's now plot the difference of all metric values for a day with 7 days in between. Click on Enter Formula then enter A-B (A minus B) and hide (deselect) all Signals using the eye, except C . We now see only the difference of all metric values of A and B being plotted. We see that we have some negative values on the plot because a metric value of B has some times larger value than the metric value of A at that time. Click on DATA TABLE and in that view swipe horizontally along the X axis to see the metric values at different times. 2. Using Absolute Value \u00b6 Click on PLOT EDITOR to get back to the Plot Editor view. Let's apply another function to get the values of C to positive values. Note By doing so we will see the difference between the metric values for a period of 24 hours with 7 days between. This difference can be used to see an alarming trend if we consider last week to be a baseline (the bigger the number - the more we deviate from the baseline) - but mainly we do this for you to get a bit more training on using analytical functions! In the PLOT EDITOR for C , under F(x) , click on Add Analytics and choose Absolute Value . You will see the C plot now having only positive values.","title":"Using formulas"},{"location":"dashboards/formulas/#using-formulas","text":"","title":"Using Formulas"},{"location":"dashboards/formulas/#1-plotting-differences","text":"Let's now plot the difference of all metric values for a day with 7 days in between. Click on Enter Formula then enter A-B (A minus B) and hide (deselect) all Signals using the eye, except C . We now see only the difference of all metric values of A and B being plotted. We see that we have some negative values on the plot because a metric value of B has some times larger value than the metric value of A at that time. Click on DATA TABLE and in that view swipe horizontally along the X axis to see the metric values at different times.","title":"1. Plotting differences"},{"location":"dashboards/formulas/#2-using-absolute-value","text":"Click on PLOT EDITOR to get back to the Plot Editor view. Let's apply another function to get the values of C to positive values. Note By doing so we will see the difference between the metric values for a period of 24 hours with 7 days between. This difference can be used to see an alarming trend if we consider last week to be a baseline (the bigger the number - the more we deviate from the baseline) - but mainly we do this for you to get a bit more training on using analytical functions! In the PLOT EDITOR for C , under F(x) , click on Add Analytics and choose Absolute Value . You will see the C plot now having only positive values.","title":"2. Using Absolute Value"},{"location":"dashboards/overlay/","text":"Using Overlays \u00b6 Let's overlay metrics and events to our initial plot to see if there is any correlation with high latency. To discover and add new metrics to the chart from the ones that are being sent to SignalFx already, click on Browse on the bottom of the screen. In the METRICS sidebar on the right, enter demo and click on the search icon to search. Observe that the Find Metrics option is pre-selected. The metrics search is showing 3 metrics with demo in the name. Select demo.trans.count and click on the Add Plot green button. Click on the blue eye icon next to C to hide that Signal, and on the greyed eye icon for Signal A to show it. On plot D , apply the Percentile:Aggregation function and set to 95 . Enter -1h in the Time frame for the entire chart. We see that there is a correlation between latency and number of transactions. Note Likewise we could check Find Events and find events like deployment events etc. to correlate with. Click on the the greater than sign icon to collapse the METRICS sidebar.","title":"Using overlays"},{"location":"dashboards/overlay/#using-overlays","text":"Let's overlay metrics and events to our initial plot to see if there is any correlation with high latency. To discover and add new metrics to the chart from the ones that are being sent to SignalFx already, click on Browse on the bottom of the screen. In the METRICS sidebar on the right, enter demo and click on the search icon to search. Observe that the Find Metrics option is pre-selected. The metrics search is showing 3 metrics with demo in the name. Select demo.trans.count and click on the Add Plot green button. Click on the blue eye icon next to C to hide that Signal, and on the greyed eye icon for Signal A to show it. On plot D , apply the Percentile:Aggregation function and set to 95 . Enter -1h in the Time frame for the entire chart. We see that there is a correlation between latency and number of transactions. Note Likewise we could check Find Events and find events like deployment events etc. to correlate with. Click on the the greater than sign icon to collapse the METRICS sidebar.","title":"Using Overlays"},{"location":"dashboards/signalflow/","text":"SignalFlow \u00b6 Let's take a look at SignalFlow - the analytics language of SignalFx that can be used to setup monitoring as code. Click on View SignalFlow . You will see the SignalFlow code that composes the chart we were working on. SignalFlow A = data ( 'demo.trans.latency' , filter = filter ( 'demo_datacenter' , 'Paris' )) . percentile ( pct = 95 ) . publish ( label = 'A' ) B = data ( 'demo.trans.latency' , filter = filter ( 'demo_datacenter' , 'Paris' )) . percentile ( pct = 95 ) . timeshift ( '1w' ) . publish ( label = 'B' , enable = False ) C = ( A - B ) . abs () . publish ( label = 'C' , enable = False ) D = data ( 'demo.trans.count' ) . percentile ( pct = 95 ) . publish ( label = 'D' ) SignalFlow is the analytics language of SignalFx. Among other benefits, it can be used to setup monitoring as code. For more info on SignalFlow see Getting started with SignalFlow . Click on View Builder to go back to the Chart Builder UI.","title":"SignalFlow"},{"location":"dashboards/signalflow/#signalflow","text":"Let's take a look at SignalFlow - the analytics language of SignalFx that can be used to setup monitoring as code. Click on View SignalFlow . You will see the SignalFlow code that composes the chart we were working on. SignalFlow A = data ( 'demo.trans.latency' , filter = filter ( 'demo_datacenter' , 'Paris' )) . percentile ( pct = 95 ) . publish ( label = 'A' ) B = data ( 'demo.trans.latency' , filter = filter ( 'demo_datacenter' , 'Paris' )) . percentile ( pct = 95 ) . timeshift ( '1w' ) . publish ( label = 'B' , enable = False ) C = ( A - B ) . abs () . publish ( label = 'C' , enable = False ) D = data ( 'demo.trans.count' ) . percentile ( pct = 95 ) . publish ( label = 'D' ) SignalFlow is the analytics language of SignalFx. Among other benefits, it can be used to setup monitoring as code. For more info on SignalFlow see Getting started with SignalFlow . Click on View Builder to go back to the Chart Builder UI.","title":"SignalFlow"},{"location":"detectors/detectors/","text":"Working with Detectors - Lab Summary \u00b6 Create a Detector from one of your charts Setting Alert conditions Running a pre-flight check Working with muting rules 1. Create a detector from one of your charts \u00b6 In DASHBOARDS click on your dashboard group (the one with your email address) and then on the dashboard name where the chart you created in the previous lab resides or search for your previously created dashboard's name, and click on that dashboard's name in the results. We are now going to create a new detector from this chart. Once you see the chart, click on the bell icon on your chart and then on New Detector From Chart . In the text field next to Detector Name , ADD YOUR INITIALS before the proposed detector name. Naming the detector It's important that you add your initials in front of the proposed detector name. It should be something like this: LI's Latency Chart Detector . Click on Create Alert Rule . In the Detector window, inside Alert signal , the Signal we will alert on is marked with a (blue) bell in the Alert on column. The bell indicates which Signal is being used to generate the alert. Click on Proceed to Alert Condition . 2. Setting Alert condition \u00b6 In Alert condition , click on Static Threshold and then on Proceed to Alert Settings . In Alert Settings , enter the value 290 in the Threshold field. In the same window change Time on top right to past day ( -1d ). 3. Alert pre-flight check \u00b6 SignalFx will now perform a pre-flight check after 5 seconds. See the Estimated alert count . Based on the current alert settings, the amount of alerts we would\u2019ve received in 1 day would have been approx. 18 . About pre-flight checks Once you set an alert condition, SignalFx shows how many alerts you would get based on the current settings, and in the timeframe set on the upper right corner - in this case, the past day. Immediately, the platform will start analyzing the signals with the current settings, and perform something we call a Pre-flight Check. This enables you to test the alert conditions using the historical data in the platform, to ensure the settings are logical and will not inadvertently generate an alert storm, removing the guess work from configuring alerts in a simple but very powerful way, only available using SignalFx. To read more about detector previewing, please visit this link Setting up detectors . 4. Configuring the alert message \u00b6 In Alert Setting click on Proceed to Alert Message . In Alert message , under Severity choose Major . Click on Proceed to Alert Recipients . Click on Add Recipient and then on your email address displayed as the first option. Notification Services That's the same as entering that email address OR you can enter another email address by clicking on E-mail... . That's just one example of the many Notification Services SignalFx has available. You can check this out by going to the INTEGRATIONS tab of the top menu, and see Notification Services . 5. Activating the alert \u00b6 Click on Proceed to Alert Activation . In Activate... click on Activate Alert Rule . If you want to get alerts quicker you can click back on Alert Settings and lower the value from 290 to say 280 . If you change the Time to -1h you can see how many alerts you might get with the threshold you have chosen based on the metics from the last 1 hour. Hover over ALERTS in the top menu and then click on Detectors . You will see you detector listed here. Congratulations ! You have created your first detector and activated it!","title":"Creating a Detector"},{"location":"detectors/detectors/#working-with-detectors-lab-summary","text":"Create a Detector from one of your charts Setting Alert conditions Running a pre-flight check Working with muting rules","title":"Working with Detectors - Lab Summary"},{"location":"detectors/detectors/#1-create-a-detector-from-one-of-your-charts","text":"In DASHBOARDS click on your dashboard group (the one with your email address) and then on the dashboard name where the chart you created in the previous lab resides or search for your previously created dashboard's name, and click on that dashboard's name in the results. We are now going to create a new detector from this chart. Once you see the chart, click on the bell icon on your chart and then on New Detector From Chart . In the text field next to Detector Name , ADD YOUR INITIALS before the proposed detector name. Naming the detector It's important that you add your initials in front of the proposed detector name. It should be something like this: LI's Latency Chart Detector . Click on Create Alert Rule . In the Detector window, inside Alert signal , the Signal we will alert on is marked with a (blue) bell in the Alert on column. The bell indicates which Signal is being used to generate the alert. Click on Proceed to Alert Condition .","title":"1. Create a detector from one of your charts"},{"location":"detectors/detectors/#2-setting-alert-condition","text":"In Alert condition , click on Static Threshold and then on Proceed to Alert Settings . In Alert Settings , enter the value 290 in the Threshold field. In the same window change Time on top right to past day ( -1d ).","title":"2. Setting Alert condition"},{"location":"detectors/detectors/#3-alert-pre-flight-check","text":"SignalFx will now perform a pre-flight check after 5 seconds. See the Estimated alert count . Based on the current alert settings, the amount of alerts we would\u2019ve received in 1 day would have been approx. 18 . About pre-flight checks Once you set an alert condition, SignalFx shows how many alerts you would get based on the current settings, and in the timeframe set on the upper right corner - in this case, the past day. Immediately, the platform will start analyzing the signals with the current settings, and perform something we call a Pre-flight Check. This enables you to test the alert conditions using the historical data in the platform, to ensure the settings are logical and will not inadvertently generate an alert storm, removing the guess work from configuring alerts in a simple but very powerful way, only available using SignalFx. To read more about detector previewing, please visit this link Setting up detectors .","title":"3. Alert pre-flight check"},{"location":"detectors/detectors/#4-configuring-the-alert-message","text":"In Alert Setting click on Proceed to Alert Message . In Alert message , under Severity choose Major . Click on Proceed to Alert Recipients . Click on Add Recipient and then on your email address displayed as the first option. Notification Services That's the same as entering that email address OR you can enter another email address by clicking on E-mail... . That's just one example of the many Notification Services SignalFx has available. You can check this out by going to the INTEGRATIONS tab of the top menu, and see Notification Services .","title":"4. Configuring the alert message"},{"location":"detectors/detectors/#5-activating-the-alert","text":"Click on Proceed to Alert Activation . In Activate... click on Activate Alert Rule . If you want to get alerts quicker you can click back on Alert Settings and lower the value from 290 to say 280 . If you change the Time to -1h you can see how many alerts you might get with the threshold you have chosen based on the metics from the last 1 hour. Hover over ALERTS in the top menu and then click on Detectors . You will see you detector listed here. Congratulations ! You have created your first detector and activated it!","title":"5. Activating the alert"},{"location":"detectors/muting/","text":"Working with Muting Rules - Lab Summary \u00b6 Learn how to configure how to mute Alerts 1. Learn how to configure muting your alerts \u00b6 There will be times when you might want to mute certain notifications. For example, if you want to schedule downtime for maintenance on a server or set of servers, or if you are testing new code or settings etc. For that you can use muting rules in SignalFx. Let's create one! Hover over ALERTS in the menu and from the drop down click on Detectors . You will see a list of active detectors. If you created an detector in Working with Detectors you can click on the three dots ... on the far right for that detector; if not, do that for another detector. From the drop-down click on Create Muting Rule... . In the Muting Rule window check Mute Indefinitely and enter a reason. Note This will mute the notifications permanently until you come back here and un-check this box or resume notifications for this detector. Click Next and in the new modal window confirm the muting rule setup. Click on Mute Indefinitely button to confirm. You won't be receiving any email notifications from you detector until you resume notifications again. Let's now see how to do that! 2. Resuming notifications \u00b6 To Resume notifications, hover over ALERTS in the top menu and click on Muting Rules . You will see the name of the detector you muted notifications for under Detector . Click on the thee dots ... on the far right. Click on Resume Notifications . Click on Resume to confirm and resume notifications for this detector. Congratulations! You have now resumed your alert notifications!","title":"Creating a Muting Rule"},{"location":"detectors/muting/#working-with-muting-rules-lab-summary","text":"Learn how to configure how to mute Alerts","title":"Working with Muting Rules - Lab Summary"},{"location":"detectors/muting/#1-learn-how-to-configure-muting-your-alerts","text":"There will be times when you might want to mute certain notifications. For example, if you want to schedule downtime for maintenance on a server or set of servers, or if you are testing new code or settings etc. For that you can use muting rules in SignalFx. Let's create one! Hover over ALERTS in the menu and from the drop down click on Detectors . You will see a list of active detectors. If you created an detector in Working with Detectors you can click on the three dots ... on the far right for that detector; if not, do that for another detector. From the drop-down click on Create Muting Rule... . In the Muting Rule window check Mute Indefinitely and enter a reason. Note This will mute the notifications permanently until you come back here and un-check this box or resume notifications for this detector. Click Next and in the new modal window confirm the muting rule setup. Click on Mute Indefinitely button to confirm. You won't be receiving any email notifications from you detector until you resume notifications again. Let's now see how to do that!","title":"1. Learn how to configure muting your alerts"},{"location":"detectors/muting/#2-resuming-notifications","text":"To Resume notifications, hover over ALERTS in the top menu and click on Muting Rules . You will see the name of the detector you muted notifications for under Detector . Click on the thee dots ... on the far right. Click on Resume Notifications . Click on Resume to confirm and resume notifications for this detector. Congratulations! You have now resumed your alert notifications!","title":"2. Resuming notifications"},{"location":"module-support/cleanup/","text":"Post Workshop Clean Up \u00b6 Multipass Once you have finished with this Workshop exit from the Multipass instance to get back to your system command prompt. Enter the following to delete and purge the Multipass instance: multipass delete --purge $INSTANCE AWS/EC2 Once you have finished with this Workshop exit from the AWS/EC2 instance to get back to your system command prompt. We will use Terraform to destroy the instance with the parameters you used in Smart Agent module: cd ~/workshop/ec2 terraform destroy -var = \"aws_instance_count=1\" -var = \"instance_type=1\" Enter Instance Count , Provide the desired region and Select instance type required . When prompted type yes to confirm you want to destroy, this will take a while to complete. aws_instance.devops-instance[0]: Destroying... [id=i-088560a5f6e2bbdbb] aws_instance.devops-instance[0]: Still destroying... [id=i-088560a5f6e2bbdbb, 10s elapsed] aws_instance.devops-instance[0]: Still destroying... [id=i-088560a5f6e2bbdbb, 20s elapsed] aws_instance.devops-instance[0]: Still destroying... [id=i-088560a5f6e2bbdbb, 30s elapsed] aws_instance.devops-instance[0]: Still destroying... [id=i-088560a5f6e2bbdbb, 40s elapsed] aws_instance.devops-instance[0]: Still destroying... [id=i-088560a5f6e2bbdbb, 50s elapsed] aws_instance.devops-instance[0]: Destruction complete after 56s aws_security_group.instance: Destroying... [id=sg-0d6841fbeef022a9f] aws_security_group.instance: Destruction complete after 2s","title":"<b>Post Workshop Clean Up</b>"},{"location":"module-support/cleanup/#post-workshop-clean-up","text":"Multipass Once you have finished with this Workshop exit from the Multipass instance to get back to your system command prompt. Enter the following to delete and purge the Multipass instance: multipass delete --purge $INSTANCE AWS/EC2 Once you have finished with this Workshop exit from the AWS/EC2 instance to get back to your system command prompt. We will use Terraform to destroy the instance with the parameters you used in Smart Agent module: cd ~/workshop/ec2 terraform destroy -var = \"aws_instance_count=1\" -var = \"instance_type=1\" Enter Instance Count , Provide the desired region and Select instance type required . When prompted type yes to confirm you want to destroy, this will take a while to complete. aws_instance.devops-instance[0]: Destroying... [id=i-088560a5f6e2bbdbb] aws_instance.devops-instance[0]: Still destroying... [id=i-088560a5f6e2bbdbb, 10s elapsed] aws_instance.devops-instance[0]: Still destroying... [id=i-088560a5f6e2bbdbb, 20s elapsed] aws_instance.devops-instance[0]: Still destroying... [id=i-088560a5f6e2bbdbb, 30s elapsed] aws_instance.devops-instance[0]: Still destroying... [id=i-088560a5f6e2bbdbb, 40s elapsed] aws_instance.devops-instance[0]: Still destroying... [id=i-088560a5f6e2bbdbb, 50s elapsed] aws_instance.devops-instance[0]: Destruction complete after 56s aws_security_group.instance: Destroying... [id=sg-0d6841fbeef022a9f] aws_security_group.instance: Destruction complete after 2s","title":"Post Workshop Clean Up"},{"location":"module-support/hotrod-eks/","text":"Deploying Hot R.O.D. in AWS/EKS \u00b6 Enabling \u00b5APM An Organization needs to be pre-provisioned as a \u00b5APM entitlement is required for the purposes of this module. Please contact someone from SignalFx to get a trial instance with \u00b5APM enabled if you don\u2019t have one already. To check if you have an Organization with \u00b5APM enabled, just login to SignalFx and check that you have the \u00b5APM tab on the top navbar next to Dashboards. 1. Launch the Multipass instance \u00b6 If you have not already completed the Smart Agent Preparation , then please do so, otherwise jump to Step #2 2. Create environment variables \u00b6 Create the following environment variables for SignalFx and AWS to use in the proceeding steps: SignalFx export ACCESS_TOKEN=[ACCESS_TOKEN] export REALM=[REALM e.g. us1] AWS export AWS_ACCESS_KEY_ID=[AWS Access Key] export AWS_SECRET_ACCESS_KEY=[AWS Secret Access Key] export AWS_DEFAULT_REGION=[e.g. us-east-1] export AWS_DEFAULT_OUTPUT=json export EKS_CLUSTER_NAME=$(hostname)-APP-DEV You can check for the latest SignalFx Smart Agent release on Github . 3. Configure AWS CLI for your account \u00b6 Use the AWS CLI to configure access to your AWS environment. The environment variables configured above mean you can just hit enter on each of the prompts to accept the values: Input aws configure Output AWS Access Key ID [****************TVAQ]: AWS Secret Access Key [****************MkB4]: Default region name [us-east-1]: Default output format [json]: 4. Create a cluster running Amazon Elastic Kubernetes Service (EKS) \u00b6 Input eksctl create cluster \\ --name $EKS_CLUSTER_NAME \\ --region $AWS_DEFAULT_REGION \\ --node-type t3.medium \\ --nodes-min 3 \\ --nodes-max 7 \\ --version=1.15 Output [\u2139] eksctl version 0.16.0 [\u2139] using region us-east-1 [\u2139] setting availability zones to [us-east-1a us-east-1f] [\u2139] subnets for us-east-1a - public:192.168.0.0/19 private:192.168.64.0/19 [\u2139] subnets for us-east-1f - public:192.168.32.0/19 private:192.168.96.0/19 [\u2139] nodegroup \"ng-371a784a\" will use \"ami-0e5bb2367e692b807\" [AmazonLinux2/1.15] [\u2139] using Kubernetes version 1.15 [\u2139] creating EKS cluster \"EKS-APP-DEV\" in \"us-east-1\" region with un-managed nodes [\u2139] will create 2 separate CloudFormation stacks for cluster itself and the initial nodegroup [\u2139] if you encounter any issues, check CloudFormation console or try 'eksctl utils describe-stacks --region=us-east-1 --cluster=EKS-APP-DEV' [\u2139] CloudWatch logging will not be enabled for cluster \"EKS-APP-DEV\" in \"us-east-1\" [\u2139] you can enable it with 'eksctl utils update-cluster-logging --region=us-east-1 --cluster=EKS-APP-DEV' [\u2139] Kubernetes API endpoint access will use default of {publicAccess=true, privateAccess=false} for cluster \"EKS-APP-DEV\" in \"us-east-1\" [\u2139] 2 sequential tasks: { create cluster control plane \"EKS-APP-DEV\", create nodegroup \"ng-371a784a\" } [\u2139] building cluster stack \"eksctl-EKS-APP-DEV-cluster\" [\u2139] deploying stack \"eksctl-EKS-APP-DEV-cluster\" [\u2139] building nodegroup stack \"eksctl-EKS-APP-DEV-nodegroup-ng-371a784a\" [\u2139] deploying stack \"eksctl-EKS-APP-DEV-nodegroup-ng-371a784a\" [\u2714] all EKS cluster resources for \"EKS-APP-DEV\" have been created [!] unable to write kubeconfig , please retry with 'eksctl utils write-kubeconfig -n EKS-APP-DEV': unable to modify kubeconfig /home/ubuntu/.kube/config: open /etc/rancher/k3s/k3s.yaml.lock: permission denied [\u2139] adding identity \"arn:aws:iam::327192335161:role/eksctl-EKS-APP-DEV-nodegroup-ng-3-NodeInstanceRole-2RMH7RBODD62\" to auth ConfigMap [\u2139] nodegroup \"ng-371a784a\" has 0 node(s) [\u2139] waiting for at least 3 node(s) to become ready in \"ng-371a784a\" [\u2139] nodegroup \"ng-371a784a\" has 3 node(s) [\u2139] node \"ip-192-168-35-104.ec2.internal\" is ready [\u2139] node \"ip-192-168-52-88.ec2.internal\" is ready [\u2139] node \"ip-192-168-8-236.ec2.internal\" is ready [\u2714] EKS cluster \"EKS-APP-DEV\" in \"us-east-1\" region is ready This may take some time (10-15 minutes). Ensure you see your cluster active in AWS EKS console before proceeding. Note You can ignore the error about unable to write kubeconfig as we address this below. Once complete update your kubeconfig to allow kubectl access to the cluster: Input sudo eksctl utils write-kubeconfig -n $EKS_CLUSTER_NAME 5. Deploy SignalFx SmartAgent to your EKS Cluster \u00b6 Add the SignalFx Helm chart repository to Helm: Input helm repo add signalfx https://dl.signalfx.com/helm-repo Output \"signalfx\" has been added to your repositories Ensure the latest state of the SignalFx Helm repository: Input helm repo update Output Hang tight while we grab the latest from your chart repositories... ...Successfully got an update from the \"signalfx\" chart repository Install the Smart Agent Helm chart with the following commands: Input helm install \\ --set signalFxAccessToken=$ACCESS_TOKEN \\ --set clusterName=$EKS_CLUSTER_NAME \\ --set signalFxRealm=$REALM \\ --set kubeletAPI.url=https://localhost:10250 \\ --set traceEndpointUrl=https://ingest.$REALM.signalfx.com/v2/trace \\ signalfx-agent signalfx/signalfx-agent \\ -f workshop/k3s/values.yaml Output NAME: signalfx-agent LAST DEPLOYED: Mon Apr 13 14:23:19 2020 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: The SignalFx agent is being deployed in your Kubernetes cluster. You should see metrics flowing once the agent image is downloaded and started (this may take a few minutes since it has to download the agent container image). Assuming you are logged into SignalFx in your browser, visit https://app.us0.signalfx.com/#/navigator/kubernetes%20pods/kubernetes%20pods to see all of the pods in your cluster. Validate cluster looks healthy in SignalFx Kubernetes Navigator dashboard 6. Deploy Hot R.O.D. Application to EKS \u00b6 Input kubectl apply -f ~/workshop/apm/hotrod/k8s/deployment.yaml To ensure the Hot R.O.D. application is running see examples below: Input kubectl get pods Output NAME READY STATUS RESTARTS AGE hotrod-7564774bf5-vjpfw 1/1 Running 0 47h signalfx-agent-jmq4f 1/1 Running 0 138m signalfx-agent-nk8p9 1/1 Running 0 138m signalfx-agent-q5tzh 1/1 Running 0 138m You then need find the IP address assigned to the Hot R.O.D. service: Input kubectl get svc Output NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE hotrod LoadBalancer 10.100.188.249 af26ce80ef2e14c9292ae5b4bc0d2dd0-1826890352.us-east-2.elb.amazonaws.com 8080:32521/TCP 47h kubernetes ClusterIP 10.100.0.1 <none> 443/TCP 3d1h Create an environment variable for the IP address and port that the Hot R.O.D. application is exposed on: Input HOTROD_ENDPOINT=$(kubectl get svc hotrod -n default -o jsonpath='{.spec.clusterIP}:{.spec.ports[0].port}') You can view / exercise Hot R.O.D. yourself in a browser by opening the EXTERNAL-IP:PORT as shown above e.g. Example URL https://af26ce80ef2e14c9292ae5b4bc0d2dd0-1826890352.us-east-2.elb.amazonaws.com:8080 7. Generate some traffic to the application using Siege Benchmark \u00b6 Input siege -r10 -c10 \"http:// $HOTROD_ENDPOINT /dispatch?customer=392&nonse=0.17041229755366172\" Create some errors with an invalid customer number Input siege -r10 -c10 \"http:// $HOTROD_ENDPOINT /dispatch?customer=391&nonse=0.17041229755366172\" You should now be able to exercise SignalFx APM dashboards. 8. Cleaning up \u00b6 To delete entire EKS cluster: Input eksctl delete cluster $EKS_CLUSTER_NAME Output [\u2139] eksctl version 0.16.0 [\u2139] using region us-east-1 [\u2139] deleting EKS cluster \"RWC-APP-DEV\" [\u2139] deleted 0 Fargate profile(s) [\u2139] cleaning up LoadBalancer services [\u2139] 2 sequential tasks: { delete nodegroup \"ng-371a784a\", delete cluster control plane \"EKS-APP-DEV\" [async] } [\u2139] will delete stack \"eksctl-EKS-APP-DEV-nodegroup-ng-371a784a\" [\u2139] waiting for stack \"eksctl-EKS-APP-DEV-nodegroup-ng-371a784a\" to get deleted [\u2139] will delete stack \"eksctl-EKS-APP-DEV-cluster\" [\u2714] all cluster resources were deleted Or to delete individual components: Input kubectl delete deploy/hotrod svc/hotrod helm delete signalfx-agent To switch back to using the local K3s cluster: Input sudo kubectl config use-context default","title":"Deploying Hot R.O.D. in EKS"},{"location":"module-support/hotrod-eks/#deploying-hot-rod-in-awseks","text":"Enabling \u00b5APM An Organization needs to be pre-provisioned as a \u00b5APM entitlement is required for the purposes of this module. Please contact someone from SignalFx to get a trial instance with \u00b5APM enabled if you don\u2019t have one already. To check if you have an Organization with \u00b5APM enabled, just login to SignalFx and check that you have the \u00b5APM tab on the top navbar next to Dashboards.","title":"Deploying Hot R.O.D. in AWS/EKS"},{"location":"module-support/hotrod-eks/#1-launch-the-multipass-instance","text":"If you have not already completed the Smart Agent Preparation , then please do so, otherwise jump to Step #2","title":"1. Launch the Multipass instance"},{"location":"module-support/hotrod-eks/#2-create-environment-variables","text":"Create the following environment variables for SignalFx and AWS to use in the proceeding steps: SignalFx export ACCESS_TOKEN=[ACCESS_TOKEN] export REALM=[REALM e.g. us1] AWS export AWS_ACCESS_KEY_ID=[AWS Access Key] export AWS_SECRET_ACCESS_KEY=[AWS Secret Access Key] export AWS_DEFAULT_REGION=[e.g. us-east-1] export AWS_DEFAULT_OUTPUT=json export EKS_CLUSTER_NAME=$(hostname)-APP-DEV You can check for the latest SignalFx Smart Agent release on Github .","title":"2. Create environment variables"},{"location":"module-support/hotrod-eks/#3-configure-aws-cli-for-your-account","text":"Use the AWS CLI to configure access to your AWS environment. The environment variables configured above mean you can just hit enter on each of the prompts to accept the values: Input aws configure Output AWS Access Key ID [****************TVAQ]: AWS Secret Access Key [****************MkB4]: Default region name [us-east-1]: Default output format [json]:","title":"3. Configure AWS CLI for your account"},{"location":"module-support/hotrod-eks/#4-create-a-cluster-running-amazon-elastic-kubernetes-service-eks","text":"Input eksctl create cluster \\ --name $EKS_CLUSTER_NAME \\ --region $AWS_DEFAULT_REGION \\ --node-type t3.medium \\ --nodes-min 3 \\ --nodes-max 7 \\ --version=1.15 Output [\u2139] eksctl version 0.16.0 [\u2139] using region us-east-1 [\u2139] setting availability zones to [us-east-1a us-east-1f] [\u2139] subnets for us-east-1a - public:192.168.0.0/19 private:192.168.64.0/19 [\u2139] subnets for us-east-1f - public:192.168.32.0/19 private:192.168.96.0/19 [\u2139] nodegroup \"ng-371a784a\" will use \"ami-0e5bb2367e692b807\" [AmazonLinux2/1.15] [\u2139] using Kubernetes version 1.15 [\u2139] creating EKS cluster \"EKS-APP-DEV\" in \"us-east-1\" region with un-managed nodes [\u2139] will create 2 separate CloudFormation stacks for cluster itself and the initial nodegroup [\u2139] if you encounter any issues, check CloudFormation console or try 'eksctl utils describe-stacks --region=us-east-1 --cluster=EKS-APP-DEV' [\u2139] CloudWatch logging will not be enabled for cluster \"EKS-APP-DEV\" in \"us-east-1\" [\u2139] you can enable it with 'eksctl utils update-cluster-logging --region=us-east-1 --cluster=EKS-APP-DEV' [\u2139] Kubernetes API endpoint access will use default of {publicAccess=true, privateAccess=false} for cluster \"EKS-APP-DEV\" in \"us-east-1\" [\u2139] 2 sequential tasks: { create cluster control plane \"EKS-APP-DEV\", create nodegroup \"ng-371a784a\" } [\u2139] building cluster stack \"eksctl-EKS-APP-DEV-cluster\" [\u2139] deploying stack \"eksctl-EKS-APP-DEV-cluster\" [\u2139] building nodegroup stack \"eksctl-EKS-APP-DEV-nodegroup-ng-371a784a\" [\u2139] deploying stack \"eksctl-EKS-APP-DEV-nodegroup-ng-371a784a\" [\u2714] all EKS cluster resources for \"EKS-APP-DEV\" have been created [!] unable to write kubeconfig , please retry with 'eksctl utils write-kubeconfig -n EKS-APP-DEV': unable to modify kubeconfig /home/ubuntu/.kube/config: open /etc/rancher/k3s/k3s.yaml.lock: permission denied [\u2139] adding identity \"arn:aws:iam::327192335161:role/eksctl-EKS-APP-DEV-nodegroup-ng-3-NodeInstanceRole-2RMH7RBODD62\" to auth ConfigMap [\u2139] nodegroup \"ng-371a784a\" has 0 node(s) [\u2139] waiting for at least 3 node(s) to become ready in \"ng-371a784a\" [\u2139] nodegroup \"ng-371a784a\" has 3 node(s) [\u2139] node \"ip-192-168-35-104.ec2.internal\" is ready [\u2139] node \"ip-192-168-52-88.ec2.internal\" is ready [\u2139] node \"ip-192-168-8-236.ec2.internal\" is ready [\u2714] EKS cluster \"EKS-APP-DEV\" in \"us-east-1\" region is ready This may take some time (10-15 minutes). Ensure you see your cluster active in AWS EKS console before proceeding. Note You can ignore the error about unable to write kubeconfig as we address this below. Once complete update your kubeconfig to allow kubectl access to the cluster: Input sudo eksctl utils write-kubeconfig -n $EKS_CLUSTER_NAME","title":"4. Create a cluster running Amazon Elastic Kubernetes Service (EKS)"},{"location":"module-support/hotrod-eks/#5-deploy-signalfx-smartagent-to-your-eks-cluster","text":"Add the SignalFx Helm chart repository to Helm: Input helm repo add signalfx https://dl.signalfx.com/helm-repo Output \"signalfx\" has been added to your repositories Ensure the latest state of the SignalFx Helm repository: Input helm repo update Output Hang tight while we grab the latest from your chart repositories... ...Successfully got an update from the \"signalfx\" chart repository Install the Smart Agent Helm chart with the following commands: Input helm install \\ --set signalFxAccessToken=$ACCESS_TOKEN \\ --set clusterName=$EKS_CLUSTER_NAME \\ --set signalFxRealm=$REALM \\ --set kubeletAPI.url=https://localhost:10250 \\ --set traceEndpointUrl=https://ingest.$REALM.signalfx.com/v2/trace \\ signalfx-agent signalfx/signalfx-agent \\ -f workshop/k3s/values.yaml Output NAME: signalfx-agent LAST DEPLOYED: Mon Apr 13 14:23:19 2020 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: The SignalFx agent is being deployed in your Kubernetes cluster. You should see metrics flowing once the agent image is downloaded and started (this may take a few minutes since it has to download the agent container image). Assuming you are logged into SignalFx in your browser, visit https://app.us0.signalfx.com/#/navigator/kubernetes%20pods/kubernetes%20pods to see all of the pods in your cluster. Validate cluster looks healthy in SignalFx Kubernetes Navigator dashboard","title":"5. Deploy SignalFx SmartAgent to your EKS Cluster"},{"location":"module-support/hotrod-eks/#6-deploy-hot-rod-application-to-eks","text":"Input kubectl apply -f ~/workshop/apm/hotrod/k8s/deployment.yaml To ensure the Hot R.O.D. application is running see examples below: Input kubectl get pods Output NAME READY STATUS RESTARTS AGE hotrod-7564774bf5-vjpfw 1/1 Running 0 47h signalfx-agent-jmq4f 1/1 Running 0 138m signalfx-agent-nk8p9 1/1 Running 0 138m signalfx-agent-q5tzh 1/1 Running 0 138m You then need find the IP address assigned to the Hot R.O.D. service: Input kubectl get svc Output NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE hotrod LoadBalancer 10.100.188.249 af26ce80ef2e14c9292ae5b4bc0d2dd0-1826890352.us-east-2.elb.amazonaws.com 8080:32521/TCP 47h kubernetes ClusterIP 10.100.0.1 <none> 443/TCP 3d1h Create an environment variable for the IP address and port that the Hot R.O.D. application is exposed on: Input HOTROD_ENDPOINT=$(kubectl get svc hotrod -n default -o jsonpath='{.spec.clusterIP}:{.spec.ports[0].port}') You can view / exercise Hot R.O.D. yourself in a browser by opening the EXTERNAL-IP:PORT as shown above e.g. Example URL https://af26ce80ef2e14c9292ae5b4bc0d2dd0-1826890352.us-east-2.elb.amazonaws.com:8080","title":"6. Deploy Hot R.O.D. Application to EKS"},{"location":"module-support/hotrod-eks/#7-generate-some-traffic-to-the-application-using-siege-benchmark","text":"Input siege -r10 -c10 \"http:// $HOTROD_ENDPOINT /dispatch?customer=392&nonse=0.17041229755366172\" Create some errors with an invalid customer number Input siege -r10 -c10 \"http:// $HOTROD_ENDPOINT /dispatch?customer=391&nonse=0.17041229755366172\" You should now be able to exercise SignalFx APM dashboards.","title":"7. Generate some traffic to the application using Siege Benchmark"},{"location":"module-support/hotrod-eks/#8-cleaning-up","text":"To delete entire EKS cluster: Input eksctl delete cluster $EKS_CLUSTER_NAME Output [\u2139] eksctl version 0.16.0 [\u2139] using region us-east-1 [\u2139] deleting EKS cluster \"RWC-APP-DEV\" [\u2139] deleted 0 Fargate profile(s) [\u2139] cleaning up LoadBalancer services [\u2139] 2 sequential tasks: { delete nodegroup \"ng-371a784a\", delete cluster control plane \"EKS-APP-DEV\" [async] } [\u2139] will delete stack \"eksctl-EKS-APP-DEV-nodegroup-ng-371a784a\" [\u2139] waiting for stack \"eksctl-EKS-APP-DEV-nodegroup-ng-371a784a\" to get deleted [\u2139] will delete stack \"eksctl-EKS-APP-DEV-cluster\" [\u2714] all cluster resources were deleted Or to delete individual components: Input kubectl delete deploy/hotrod svc/hotrod helm delete signalfx-agent To switch back to using the local K3s cluster: Input sudo kubectl config use-context default","title":"8. Cleaning up"},{"location":"module-support/vm/","text":"Lab Summary \u00b6 Deploy SignalFx Smart Agent via install script on a VM Confirm the Smart Agent is working and sending data Use multipass to create a vanilla Ubuntu VM and shell into it. You can also use a Linux-based VM with your cloud provider of choice. Replace [INITIALS] with your actual initials. Input multipass launch [ INITIALS ] -vm multipass shell [ INITIALs ] -vm 1. Deploy SignalFx Smart Agent via install script on a VM \u00b6 You will need to obtain your Access Token from the SignalFx UI. You can find your Access Token by clicking on your profile icon on the top right of the SignalFx UI. Then select Organization Settings \u2192 Access Tokens . Expand the Default token, then click on Show Token to expose your token. Later in the lab you can come back here and click the Copy button which will copy it to your clipboard so you can paste it when you need to provide an access token in the lab. You will also need to obtain the name of the Realm for your SignalFx account. Click on the profile icon again, but this time select 'My Profile'. The Ream can be found in the middle of the page within the Organizations section. In this example it is us1 . SignalFx maintains a shell script to install on supported distributions. Copy the script below and replace $REALM and $ACCESS_TOKEN with the values found in previous screen: Input curl -sSL https://dl.signalfx.com/signalfx-agent.sh > /tmp/signalfx-agent.sh sudo sh /tmp/signalfx-agent.sh --realm $REALM -- $ACCESS_TOKEN Once the installation is complete check the status of the agent. Input signalfx-agent status Output SignalFx Agent version: 5.1.2 Agent uptime: 4s Observers active: host Active Monitors: 9 Configured Monitors: 9 Discovered Endpoint Count: 16 Bad Monitor Config: None Global Dimensions: {host: as-k3s} GlobalSpanTags: map[] Datapoints sent (last minute): 0 Datapoints failed (last minute): 0 Datapoints overwritten (total): 0 Events Sent (last minute): 0 Trace Spans Sent (last minute): 0 Trace Spans overwritten (total): 0 Additional status commands: signalfx-agent status config - show resolved config in use by agent signalfx-agent status endpoints - show discovered endpoints signalfx-agent status monitors - show active monitors signalfx-agent status all - show everything Important Make a note of the value displayed for host in the Global Dimensions section of the output, as you need this later! 2. Confirm the Smart Agent is working and sending data \u00b6 To see the Metrics that the Smart Agent is sending to SignalFx, please goto the SignalFX UI, and select Infrastructure \u2192 Hosts to see the lists of hosts. Here you see a list of the Nodes that have an Smart Agent installed and are reporting into SignalFx. Make sure you see your Multipass or AWS/EC2 instance in the list of hosts. (The hostname from the previous section) You can also set a filter for just your instance by selecting the host: attribute, followed by picking the name of your host from the drop down list. Click on the link to your host from the list, this wil take you to the overview page of your host. Make sure you have the SYSTEM METRIC tab selected. Here you can see various charts that relate to the health of your host, like CPU & Memory Used%, Disk I/O and many more. You can also see the list of services running on your host by selecting the PROCESSES tab. Take a moment to explore the various charts and the Processes list.","title":"Deploy Smart Agent on a VM"},{"location":"module-support/vm/#lab-summary","text":"Deploy SignalFx Smart Agent via install script on a VM Confirm the Smart Agent is working and sending data Use multipass to create a vanilla Ubuntu VM and shell into it. You can also use a Linux-based VM with your cloud provider of choice. Replace [INITIALS] with your actual initials. Input multipass launch [ INITIALS ] -vm multipass shell [ INITIALs ] -vm","title":"Lab Summary"},{"location":"module-support/vm/#1-deploy-signalfx-smart-agent-via-install-script-on-a-vm","text":"You will need to obtain your Access Token from the SignalFx UI. You can find your Access Token by clicking on your profile icon on the top right of the SignalFx UI. Then select Organization Settings \u2192 Access Tokens . Expand the Default token, then click on Show Token to expose your token. Later in the lab you can come back here and click the Copy button which will copy it to your clipboard so you can paste it when you need to provide an access token in the lab. You will also need to obtain the name of the Realm for your SignalFx account. Click on the profile icon again, but this time select 'My Profile'. The Ream can be found in the middle of the page within the Organizations section. In this example it is us1 . SignalFx maintains a shell script to install on supported distributions. Copy the script below and replace $REALM and $ACCESS_TOKEN with the values found in previous screen: Input curl -sSL https://dl.signalfx.com/signalfx-agent.sh > /tmp/signalfx-agent.sh sudo sh /tmp/signalfx-agent.sh --realm $REALM -- $ACCESS_TOKEN Once the installation is complete check the status of the agent. Input signalfx-agent status Output SignalFx Agent version: 5.1.2 Agent uptime: 4s Observers active: host Active Monitors: 9 Configured Monitors: 9 Discovered Endpoint Count: 16 Bad Monitor Config: None Global Dimensions: {host: as-k3s} GlobalSpanTags: map[] Datapoints sent (last minute): 0 Datapoints failed (last minute): 0 Datapoints overwritten (total): 0 Events Sent (last minute): 0 Trace Spans Sent (last minute): 0 Trace Spans overwritten (total): 0 Additional status commands: signalfx-agent status config - show resolved config in use by agent signalfx-agent status endpoints - show discovered endpoints signalfx-agent status monitors - show active monitors signalfx-agent status all - show everything Important Make a note of the value displayed for host in the Global Dimensions section of the output, as you need this later!","title":"1. Deploy SignalFx Smart Agent via install script on a VM"},{"location":"module-support/vm/#2-confirm-the-smart-agent-is-working-and-sending-data","text":"To see the Metrics that the Smart Agent is sending to SignalFx, please goto the SignalFX UI, and select Infrastructure \u2192 Hosts to see the lists of hosts. Here you see a list of the Nodes that have an Smart Agent installed and are reporting into SignalFx. Make sure you see your Multipass or AWS/EC2 instance in the list of hosts. (The hostname from the previous section) You can also set a filter for just your instance by selecting the host: attribute, followed by picking the name of your host from the drop down list. Click on the link to your host from the list, this wil take you to the overview page of your host. Make sure you have the SYSTEM METRIC tab selected. Here you can see various charts that relate to the health of your host, like CPU & Memory Used%, Disk I/O and many more. You can also see the list of services running on your host by selecting the PROCESSES tab. Take a moment to explore the various charts and the Processes list.","title":"2. Confirm the Smart Agent is working and sending data"},{"location":"monitoring-as-code/","text":"Monitoring as Code - Lab Summary \u00b6 Use Terraform 1 to manage SignalFx Dashboards and Detectors Initialize the Terraform SignalFx Provider 2 . Run Terraform to create SignalFx detectors and dashboards from code using the SignalFx Terraform Provider. See how Terraform can also delete detectors and dashboards. 1. Initial setup \u00b6 Remaining in your Multipass or AWS/EC2 instance from the Smart Agent module, change into the signalfx-jumpstart directory Input cd ~/signalfx-jumpstart The environment variables needed should already be set from Deploy the Smart Agent in K3s . If not, create the following environment variables to use in the Terraform steps below Input export ACCESS_TOKEN= SIGNALFX_ACCESS_TOKEN export REALM= REALM e.g. us1 export PREFIX=$(cat /dev/urandom | base64 | tr -dc 'A-Z' | head -c4) Initialize Terraform and upgrade to the latest version of the SignalFx Terraform Provider Upgrading the SignalFx Terraform Provider You will need to run this command each time a new version of the SignalFx Terraform Provider is released. You can track the releases on GitHub . Input terraform init -upgrade Output Upgrading modules... - aws in modules/aws - azure in modules/azure - docker in modules/docker - gcp in modules/gcp - host in modules/host - kubernetes in modules/kubernetes - parent_child_dashboard in modules/dashboards/parent - pivotal in modules/pivotal - usage_dashboard in modules/dashboards/usage Initializing the backend... Initializing provider plugins... - Checking for available provider plugins... - Downloading plugin for provider \"signalfx\" (terraform-providers/signalfx) 4.18.6... The following providers do not have any version constraints in configuration, so the latest version was installed. To prevent automatic upgrades to new major versions that may contain breaking changes, it is recommended to add version = \"...\" constraints to the corresponding provider blocks in configuration, with the constraint strings suggested below. * provider.signalfx: version = \"~> 4.18\" Terraform has been successfully initialized! You may now begin working with Terraform. Try running \"terraform plan\" to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary. Create a new workspace: Input terraform workspace new workshop Output Created and switched to workspace \"workspace\"! You're now on a new, empty workspace. Workspaces isolate their state, so if you run \"terraform plan\" Terraform will not see any existing state for this configuration. Terraform is a tool for building, changing, and versioning infrastructure safely and efficiently. Terraform can manage existing and popular service providers as well as custom in-house solutions. Configuration files describe to Terraform the components needed to run a single application or your entire datacenter. Terraform generates an execution plan describing what it will do to reach the desired state, and then executes it to build the described infrastructure. As the configuration changes, Terraform is able to determine what changed and create incremental execution plans which can be applied. The infrastructure Terraform can manage includes low-level components such as compute instances, storage, and networking, as well as high-level components such as DNS entries, SaaS features, etc. \u21a9 A provider is responsible for understanding API interactions and exposing resources. Providers generally are an IaaS (e.g. Alibaba Cloud, AWS, GCP, Microsoft Azure, OpenStack), PaaS (e.g. Heroku), or SaaS services (e.g. SignalFx, Terraform Cloud, DNSimple, Cloudflare). \u21a9","title":"Initial Setup"},{"location":"monitoring-as-code/#monitoring-as-code-lab-summary","text":"Use Terraform 1 to manage SignalFx Dashboards and Detectors Initialize the Terraform SignalFx Provider 2 . Run Terraform to create SignalFx detectors and dashboards from code using the SignalFx Terraform Provider. See how Terraform can also delete detectors and dashboards.","title":"Monitoring as Code - Lab Summary"},{"location":"monitoring-as-code/#1-initial-setup","text":"Remaining in your Multipass or AWS/EC2 instance from the Smart Agent module, change into the signalfx-jumpstart directory Input cd ~/signalfx-jumpstart The environment variables needed should already be set from Deploy the Smart Agent in K3s . If not, create the following environment variables to use in the Terraform steps below Input export ACCESS_TOKEN= SIGNALFX_ACCESS_TOKEN export REALM= REALM e.g. us1 export PREFIX=$(cat /dev/urandom | base64 | tr -dc 'A-Z' | head -c4) Initialize Terraform and upgrade to the latest version of the SignalFx Terraform Provider Upgrading the SignalFx Terraform Provider You will need to run this command each time a new version of the SignalFx Terraform Provider is released. You can track the releases on GitHub . Input terraform init -upgrade Output Upgrading modules... - aws in modules/aws - azure in modules/azure - docker in modules/docker - gcp in modules/gcp - host in modules/host - kubernetes in modules/kubernetes - parent_child_dashboard in modules/dashboards/parent - pivotal in modules/pivotal - usage_dashboard in modules/dashboards/usage Initializing the backend... Initializing provider plugins... - Checking for available provider plugins... - Downloading plugin for provider \"signalfx\" (terraform-providers/signalfx) 4.18.6... The following providers do not have any version constraints in configuration, so the latest version was installed. To prevent automatic upgrades to new major versions that may contain breaking changes, it is recommended to add version = \"...\" constraints to the corresponding provider blocks in configuration, with the constraint strings suggested below. * provider.signalfx: version = \"~> 4.18\" Terraform has been successfully initialized! You may now begin working with Terraform. Try running \"terraform plan\" to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary. Create a new workspace: Input terraform workspace new workshop Output Created and switched to workspace \"workspace\"! You're now on a new, empty workspace. Workspaces isolate their state, so if you run \"terraform plan\" Terraform will not see any existing state for this configuration. Terraform is a tool for building, changing, and versioning infrastructure safely and efficiently. Terraform can manage existing and popular service providers as well as custom in-house solutions. Configuration files describe to Terraform the components needed to run a single application or your entire datacenter. Terraform generates an execution plan describing what it will do to reach the desired state, and then executes it to build the described infrastructure. As the configuration changes, Terraform is able to determine what changed and create incremental execution plans which can be applied. The infrastructure Terraform can manage includes low-level components such as compute instances, storage, and networking, as well as high-level components such as DNS entries, SaaS features, etc. \u21a9 A provider is responsible for understanding API interactions and exposing resources. Providers generally are an IaaS (e.g. Alibaba Cloud, AWS, GCP, Microsoft Azure, OpenStack), PaaS (e.g. Heroku), or SaaS services (e.g. SignalFx, Terraform Cloud, DNSimple, Cloudflare). \u21a9","title":"1. Initial setup"},{"location":"monitoring-as-code/destroy/","text":"Destroy Terraform \u00b6 1. Destroy all your hard work \u00b6 You will first need to ensure you are in the the workspace you created in Step #1 : Input terraform workspace select workshop Destroy all Detectors and Dashboards that were previously applied. Input terraform destroy -var = \"access_token= $ACCESS_TOKEN \" -var = \"realm= $REALM \" Validate all the detectors have been removed by navigating to ALERTS \u2192 Detectors","title":"Destroy Terraform"},{"location":"monitoring-as-code/destroy/#destroy-terraform","text":"","title":"Destroy Terraform"},{"location":"monitoring-as-code/destroy/#1-destroy-all-your-hard-work","text":"You will first need to ensure you are in the the workspace you created in Step #1 : Input terraform workspace select workshop Destroy all Detectors and Dashboards that were previously applied. Input terraform destroy -var = \"access_token= $ACCESS_TOKEN \" -var = \"realm= $REALM \" Validate all the detectors have been removed by navigating to ALERTS \u2192 Detectors","title":"1. Destroy all your hard work"},{"location":"monitoring-as-code/plan-and-apply/","text":"Plan and Apply Terraform \u00b6 1. Create an execution plan \u00b6 Review the execution plan. Input terraform plan -var = \"access_token= $ACCESS_TOKEN \" -var = \"realm= $REALM \" -var = \"sfx_prefix= $PREFIX \" If the plan executes successfully, we can go ahead and apply: 2. Apply actions from execution plan \u00b6 Input terraform apply -var = \"access_token= $ACCESS_TOKEN \" -var = \"realm= $REALM \" -var = \"sfx_prefix= $PREFIX \" Validate that the detectors were created, under the ALERTS \u2192 Detectors , you should see a list of new detectors with the a prefix of your initials:","title":"Plan and Apply Terraform"},{"location":"monitoring-as-code/plan-and-apply/#plan-and-apply-terraform","text":"","title":"Plan and Apply Terraform"},{"location":"monitoring-as-code/plan-and-apply/#1-create-an-execution-plan","text":"Review the execution plan. Input terraform plan -var = \"access_token= $ACCESS_TOKEN \" -var = \"realm= $REALM \" -var = \"sfx_prefix= $PREFIX \" If the plan executes successfully, we can go ahead and apply:","title":"1. Create an execution plan"},{"location":"monitoring-as-code/plan-and-apply/#2-apply-actions-from-execution-plan","text":"Input terraform apply -var = \"access_token= $ACCESS_TOKEN \" -var = \"realm= $REALM \" -var = \"sfx_prefix= $PREFIX \" Validate that the detectors were created, under the ALERTS \u2192 Detectors , you should see a list of new detectors with the a prefix of your initials:","title":"2. Apply actions from execution plan"},{"location":"resources/","text":"Additional Splunk for DevOps Resources \u00b6 Below are helpful resources about Splunk and the DevOps use case. Documentation \u00b6 SignalFX Platform Docs SignalFX API Docs VictorOps Platform Docs VictorOps API Docs Blog Posts \u00b6 \"How SignalFx Does Site Reliability Engineering (SRE)\" \"OpenTelemetry for Business Continuity\" \"In Observability RED is the new Black\" \"Alerts to Incident Response in Three Easy Steps\" Webinars & Podcast \u00b6 \"Future of Microservices and APM\" \"DevOps from the Top Podcast\"","title":"Links"},{"location":"resources/#additional-splunk-for-devops-resources","text":"Below are helpful resources about Splunk and the DevOps use case.","title":"Additional Splunk for DevOps Resources"},{"location":"resources/#documentation","text":"SignalFX Platform Docs SignalFX API Docs VictorOps Platform Docs VictorOps API Docs","title":"Documentation"},{"location":"resources/#blog-posts","text":"\"How SignalFx Does Site Reliability Engineering (SRE)\" \"OpenTelemetry for Business Continuity\" \"In Observability RED is the new Black\" \"Alerts to Incident Response in Three Easy Steps\"","title":"Blog Posts"},{"location":"resources/#webinars-podcast","text":"\"Future of Microservices and APM\" \"DevOps from the Top Podcast\"","title":"Webinars &amp; Podcast"},{"location":"servicebureau/billing-and-usage/","text":"Service Bureau - Lab Summary \u00b6 How to keep track of the usage of SignalFx in your organization Learn how to keep track of spend by exploring the Billing and Usage interface Creating Teams Adding notification rules to Teams Controlling Team usage 1. Understanding SignalFx engagement \u00b6 To fully understand SignalFx engagement inside your organization, click on the Settings icon on the top right of the SignalFx UI. It may also look like this From the drop down, select the Organizations Settings \u2192 Organization Overview , this will provide you with the following dashboard that shows you how your SignalFx organization is being used: On the left hand menu (not shown in the above screenshot) you will see a list of members, and in the centre, various charts that show you the number of users, teams, charts, dashboards, and dashboard groups created, as well as various growth trends. The screenshot is taken from an demonstration organization, the Workshop organization you're looking at may have less data to work with as this is cleared down after each workshop. Take a minute to explore the various charts in the Organization Overview of this Workshop instance. 2. Usage and Billing \u00b6 If you want to see what your usage is against your contract you can select the Organizations Settings \u2192 Billing and Usage from your profile icon top right of the SignalFx UI. Or the faster way is to select the Billing and Usage item from the left hand pane. This screen may take a few seconds to load whilst it calculates and pulls in the usage. 3. Understanding usage \u00b6 You will see a screen similar like the one below that will give you an overview of the current usage, the average usage and your entitlement per category : Hosts, Containers, Custom Metrics and High Resolution Metrics. For more information about about these categories please refer to Billing and Usage information 4. Examine usage in detail \u00b6 The top chart shows you the current subscription levels per category (shown by the red arrows at the top in the screenshot below). Also, your current usage of the four catagories is displayed (shown at the red lines at the bottom of the chart). In this example you can see that there are 18 Hosts, 0 Containers and 1038 Custom Metrics and 0 High Resolution Metrics. In the bottom chart, you can see the usage per category for the current period (shown in the drop-down box on the top right of the chart). The blue line marked Average Usage indicates what SignalFx will use to calculate your average usage for the current billing period. Info As you can see from the screenshot, SignalFx does not use High Watermark or P95% for cost calculation but the actual average hourly usage, allowing you to do performance testing or Blue/Green style deployments etc. without the risk of overage charges. To get a feel for the options you can change the metric displayed by selecting the different options from the Usage Metric drop down on the left, or change the the Billing Period with the drop down on the right. Please take a minute to explore the different time periods & categories and their views. Finally, the pane on the right shows you information about your Subscription.","title":"Billing and Usage"},{"location":"servicebureau/billing-and-usage/#service-bureau-lab-summary","text":"How to keep track of the usage of SignalFx in your organization Learn how to keep track of spend by exploring the Billing and Usage interface Creating Teams Adding notification rules to Teams Controlling Team usage","title":"Service Bureau - Lab Summary"},{"location":"servicebureau/billing-and-usage/#1-understanding-signalfx-engagement","text":"To fully understand SignalFx engagement inside your organization, click on the Settings icon on the top right of the SignalFx UI. It may also look like this From the drop down, select the Organizations Settings \u2192 Organization Overview , this will provide you with the following dashboard that shows you how your SignalFx organization is being used: On the left hand menu (not shown in the above screenshot) you will see a list of members, and in the centre, various charts that show you the number of users, teams, charts, dashboards, and dashboard groups created, as well as various growth trends. The screenshot is taken from an demonstration organization, the Workshop organization you're looking at may have less data to work with as this is cleared down after each workshop. Take a minute to explore the various charts in the Organization Overview of this Workshop instance.","title":"1. Understanding SignalFx engagement"},{"location":"servicebureau/billing-and-usage/#2-usage-and-billing","text":"If you want to see what your usage is against your contract you can select the Organizations Settings \u2192 Billing and Usage from your profile icon top right of the SignalFx UI. Or the faster way is to select the Billing and Usage item from the left hand pane. This screen may take a few seconds to load whilst it calculates and pulls in the usage.","title":"2. Usage and Billing"},{"location":"servicebureau/billing-and-usage/#3-understanding-usage","text":"You will see a screen similar like the one below that will give you an overview of the current usage, the average usage and your entitlement per category : Hosts, Containers, Custom Metrics and High Resolution Metrics. For more information about about these categories please refer to Billing and Usage information","title":"3. Understanding usage"},{"location":"servicebureau/billing-and-usage/#4-examine-usage-in-detail","text":"The top chart shows you the current subscription levels per category (shown by the red arrows at the top in the screenshot below). Also, your current usage of the four catagories is displayed (shown at the red lines at the bottom of the chart). In this example you can see that there are 18 Hosts, 0 Containers and 1038 Custom Metrics and 0 High Resolution Metrics. In the bottom chart, you can see the usage per category for the current period (shown in the drop-down box on the top right of the chart). The blue line marked Average Usage indicates what SignalFx will use to calculate your average usage for the current billing period. Info As you can see from the screenshot, SignalFx does not use High Watermark or P95% for cost calculation but the actual average hourly usage, allowing you to do performance testing or Blue/Green style deployments etc. without the risk of overage charges. To get a feel for the options you can change the metric displayed by selecting the different options from the Usage Metric drop down on the left, or change the the Billing Period with the drop down on the right. Please take a minute to explore the different time periods & categories and their views. Finally, the pane on the right shows you information about your Subscription.","title":"4. Examine usage in detail"},{"location":"servicebureau/teams/","text":"Teams - Lab Summary \u00b6 Introduction to Teams Create a Team and add members to Team Discover how you can restrict usage for Teams by creating separate access tokens and set limits. 1. Introduction to Teams \u00b6 To make sure that users see the dashboards and alerts that are relevant to them when using SignalFX, most organizations will use SignalFx's Teams feature to assign a member to one or more Teams. Ideally, this matches work related roles, for example, members of a Dev-Ops or Product Management group would be assigned to the corresponding Teams in SignalFx. When a user logs into SignalFx, they can choose which Team Dashboard will be their home page and they will typically select the page for their primary role. In the example below, the user is a member of the Development, Operations and Product Management Teams, and is currently viewing the Dashboard for the Operations Team. This Dashboard has specific Dashboard Groups for NGINX, Infra and K8s assigned but any Dashboard Group can be linked to a Teams Dashboard. They can use the menu along the top left to quickly navigate between their allocated teams, or they can use the ALL TEAMS dropdown on the right to select specific Team Dashboards, as well as quickly accessing ALL DASHBOARDS using the adjacent link. Alerts can be linked to specific Teams so the Team can monitor only the Alerts they are interested in, and in the above example they currently have 1 active Critical Alert. The Description for the Team Dashboard can be customized and can include links to team specific resources (using Markdown). 2. Creating a new Team \u00b6 To work with to SignalFx's Team UI click on the Settings icon on the top right of the SignalFx UI. It may also look like this . Select the Organizations Settings \u2192 Teams tab, or select the Teams tab from the left pane. When the Team UI is selected you will be presented with the list of current Teams. To add a new Team click on the green button. This will present you with the Create New Team dialog. Create your own team by naming it [YOUR-INITIALS]-Team and add yourself by searching for your name and selecting the Add link next to your name. This should result in a dialog similar to the one below: You can remove selected users by pressing Remove or the small x . Make sure you have your group created with your initials and with yourself added as a member, then click Done . This will bring you back to the Teams list that will now show your Team and the one's created by others. Note The Teams(s) you are a member of have a grey Member icon in front of it. If no members are assigned to your Team, you should see a blue Add Members link instead of the member count, clicking on that link will get you to the Edit Team dialog where you can add yourself. This is the same dialog you get when pressing the 3 dots ... at the end of the line with your Team and selecting Edit Team The ... menu gives you the option to Edit, Join, Leave or Delete a Team (leave and join will depend on if you are currently a member). 3. Adding Notification Rules \u00b6 You can set up specific Notification rules per team, click on the NOTIFICATION POLICY tab, this will open the notification edit menu. By default the system offers you the ability to set up a general notification rule for your team. Note The Email all team members option means all members of this Team will receive an email with the Alert information, regardless of the alert type. 3.1 Adding recipients \u00b6 You can add other recipients, by clicking . These recipients do not need to be SignalFx users. However if you click on the link Configure separate notification tiers for different severity alerts you can configure every alert level independently. Different alert rules for the different alert levels can be configured, as shown in the above image. Critical and Major are using Splunk's VictorOps Incident Management solution. For the Minor alerts we send it to the Teams Slack channel and for Warning and Info we send an email. 3.2 Notification Integrations \u00b6 In addition to sending alert notifications via email, you can configure SignalFx to send alert notifications to the services shown below. Take a moment to create some notification rules for you Team. 4. Controlling a Team's usage \u00b6 If you wish to control the consumption of Hosts, Containers, Custom Metrics and High Resolution Metrics, you can create multiple Access Tokens and allocate them to different parts of your organization. Assuming you are still within the Organization Overview section, simply select the Access Tokens tab from the left pane. However to get to this section from anywhere click on the settings icon at the top right top of the page and select Organizations Settings \u2192 Access tokens The Access Tokens Interface provides an overview of your Allotments in the form of a list of Access Tokens that have been generated. Every Organization will have a Default token generated when they are first setup, but there will typically be multiple Tokens configured. Each Token is unique and can be assigned limits for the amount of Hosts, Containers, Custom Metrics and High Resolution Metrics it can consume. The Usage Status Column quickly shows if a token is above or below its assigned limits. 4.1 Creating a new token \u00b6 Let create a new token by clicking on the button. This will provide you with the Name Your Access Token dialog. Enter the new name of the new Token by using your Initials e.g. PH-Token After you press Ok, you will be taken back to the Access Token UI, here your new token should be present, among the ones created by others. If you have made an error in your naming, want to disable/enable a token or set a Token limit, click on the 3 ... menu button behind a token limit to open the manage token menu. If you made a typo you can use the Rename Token option to correct the name of your token. 4.2 Disabling a token \u00b6 If you need to make sure a token cannot be used to send Metrics in you can Disable a token. Click on the Disable button to Disable the token, this means the token cannot be used for sending in data to SignalFX. The line with Your Token should become greyed out to indicate that is has been Disabled as you can see in the screenshot below. Go ahead and click on the 3 ... menu button to Disable and Enable your token. 4.3 Manage token usage limits \u00b6 Now Lets start limiting usage by clicking on Manage Token Limit in the 3 ... menu. This will show the Manage Token Limit Dialog: In this Dialog you can set the limits per category. Please go ahead and specify the limits as shown above for each usage metric. For our lab use your own email address, and double check that you have the correct numbers in your dialog box as shown above. Token limits are used to trigger an alert that notify one or more recipients when the usage has been above 90% of the limit for 5 minutes. To specify the recipients, click Add Recipient, then select the recipient or notification method you want to use. (Specifying recipients is optional but highly recommended.) The severity for token alerts is always Critical. Click on Update to save your Access Tokens limits and The Alert Settings. Note When a token is at or above its limit in a usage category, new metrics for that usage category will not be stored and processed by SignalFx. This will make sure you there will be no unexpected cost due to a team sending in data without restriction. Note If you wish to get alerts before you hit 90%, you can create additional detectors using whatever values you want. These detectors could target the Teams consuming the specific Access Tokens so they can take action before the admins need to get involved. In your company you would distribute these new Access Tokens to various teams, controlling how much information/data they can send to SignalFx. This will allow you to fine tune the way you consume your SignalFx allotment and stop expensive surprises from happening. Congratulations! You have now have completed the Service Bureau module.","title":"Teams"},{"location":"servicebureau/teams/#teams-lab-summary","text":"Introduction to Teams Create a Team and add members to Team Discover how you can restrict usage for Teams by creating separate access tokens and set limits.","title":"Teams - Lab Summary"},{"location":"servicebureau/teams/#1-introduction-to-teams","text":"To make sure that users see the dashboards and alerts that are relevant to them when using SignalFX, most organizations will use SignalFx's Teams feature to assign a member to one or more Teams. Ideally, this matches work related roles, for example, members of a Dev-Ops or Product Management group would be assigned to the corresponding Teams in SignalFx. When a user logs into SignalFx, they can choose which Team Dashboard will be their home page and they will typically select the page for their primary role. In the example below, the user is a member of the Development, Operations and Product Management Teams, and is currently viewing the Dashboard for the Operations Team. This Dashboard has specific Dashboard Groups for NGINX, Infra and K8s assigned but any Dashboard Group can be linked to a Teams Dashboard. They can use the menu along the top left to quickly navigate between their allocated teams, or they can use the ALL TEAMS dropdown on the right to select specific Team Dashboards, as well as quickly accessing ALL DASHBOARDS using the adjacent link. Alerts can be linked to specific Teams so the Team can monitor only the Alerts they are interested in, and in the above example they currently have 1 active Critical Alert. The Description for the Team Dashboard can be customized and can include links to team specific resources (using Markdown).","title":"1. Introduction to Teams"},{"location":"servicebureau/teams/#2-creating-a-new-team","text":"To work with to SignalFx's Team UI click on the Settings icon on the top right of the SignalFx UI. It may also look like this . Select the Organizations Settings \u2192 Teams tab, or select the Teams tab from the left pane. When the Team UI is selected you will be presented with the list of current Teams. To add a new Team click on the green button. This will present you with the Create New Team dialog. Create your own team by naming it [YOUR-INITIALS]-Team and add yourself by searching for your name and selecting the Add link next to your name. This should result in a dialog similar to the one below: You can remove selected users by pressing Remove or the small x . Make sure you have your group created with your initials and with yourself added as a member, then click Done . This will bring you back to the Teams list that will now show your Team and the one's created by others. Note The Teams(s) you are a member of have a grey Member icon in front of it. If no members are assigned to your Team, you should see a blue Add Members link instead of the member count, clicking on that link will get you to the Edit Team dialog where you can add yourself. This is the same dialog you get when pressing the 3 dots ... at the end of the line with your Team and selecting Edit Team The ... menu gives you the option to Edit, Join, Leave or Delete a Team (leave and join will depend on if you are currently a member).","title":"2. Creating a new Team"},{"location":"servicebureau/teams/#3-adding-notification-rules","text":"You can set up specific Notification rules per team, click on the NOTIFICATION POLICY tab, this will open the notification edit menu. By default the system offers you the ability to set up a general notification rule for your team. Note The Email all team members option means all members of this Team will receive an email with the Alert information, regardless of the alert type.","title":"3. Adding Notification Rules"},{"location":"servicebureau/teams/#31-adding-recipients","text":"You can add other recipients, by clicking . These recipients do not need to be SignalFx users. However if you click on the link Configure separate notification tiers for different severity alerts you can configure every alert level independently. Different alert rules for the different alert levels can be configured, as shown in the above image. Critical and Major are using Splunk's VictorOps Incident Management solution. For the Minor alerts we send it to the Teams Slack channel and for Warning and Info we send an email.","title":"3.1 Adding recipients"},{"location":"servicebureau/teams/#32-notification-integrations","text":"In addition to sending alert notifications via email, you can configure SignalFx to send alert notifications to the services shown below. Take a moment to create some notification rules for you Team.","title":"3.2 Notification Integrations"},{"location":"servicebureau/teams/#4-controlling-a-teams-usage","text":"If you wish to control the consumption of Hosts, Containers, Custom Metrics and High Resolution Metrics, you can create multiple Access Tokens and allocate them to different parts of your organization. Assuming you are still within the Organization Overview section, simply select the Access Tokens tab from the left pane. However to get to this section from anywhere click on the settings icon at the top right top of the page and select Organizations Settings \u2192 Access tokens The Access Tokens Interface provides an overview of your Allotments in the form of a list of Access Tokens that have been generated. Every Organization will have a Default token generated when they are first setup, but there will typically be multiple Tokens configured. Each Token is unique and can be assigned limits for the amount of Hosts, Containers, Custom Metrics and High Resolution Metrics it can consume. The Usage Status Column quickly shows if a token is above or below its assigned limits.","title":"4. Controlling a Team's usage"},{"location":"servicebureau/teams/#41-creating-a-new-token","text":"Let create a new token by clicking on the button. This will provide you with the Name Your Access Token dialog. Enter the new name of the new Token by using your Initials e.g. PH-Token After you press Ok, you will be taken back to the Access Token UI, here your new token should be present, among the ones created by others. If you have made an error in your naming, want to disable/enable a token or set a Token limit, click on the 3 ... menu button behind a token limit to open the manage token menu. If you made a typo you can use the Rename Token option to correct the name of your token.","title":"4.1 Creating a new token"},{"location":"servicebureau/teams/#42-disabling-a-token","text":"If you need to make sure a token cannot be used to send Metrics in you can Disable a token. Click on the Disable button to Disable the token, this means the token cannot be used for sending in data to SignalFX. The line with Your Token should become greyed out to indicate that is has been Disabled as you can see in the screenshot below. Go ahead and click on the 3 ... menu button to Disable and Enable your token.","title":"4.2 Disabling a token"},{"location":"servicebureau/teams/#43-manage-token-usage-limits","text":"Now Lets start limiting usage by clicking on Manage Token Limit in the 3 ... menu. This will show the Manage Token Limit Dialog: In this Dialog you can set the limits per category. Please go ahead and specify the limits as shown above for each usage metric. For our lab use your own email address, and double check that you have the correct numbers in your dialog box as shown above. Token limits are used to trigger an alert that notify one or more recipients when the usage has been above 90% of the limit for 5 minutes. To specify the recipients, click Add Recipient, then select the recipient or notification method you want to use. (Specifying recipients is optional but highly recommended.) The severity for token alerts is always Critical. Click on Update to save your Access Tokens limits and The Alert Settings. Note When a token is at or above its limit in a usage category, new metrics for that usage category will not be stored and processed by SignalFx. This will make sure you there will be no unexpected cost due to a team sending in data without restriction. Note If you wish to get alerts before you hit 90%, you can create additional detectors using whatever values you want. These detectors could target the Teams consuming the specific Access Tokens so they can take action before the admins need to get involved. In your company you would distribute these new Access Tokens to various teams, controlling how much information/data they can send to SignalFx. This will allow you to fine tune the way you consume your SignalFx allotment and stop expensive surprises from happening. Congratulations! You have now have completed the Service Bureau module.","title":"4.3 Manage token usage limits"},{"location":"smartagent/","text":"Introduction \u00b6 During this technical workshop you will build out an environment based on a lightweight Kubernetes deployment. In order to simplify the workshop modules, a pre-configure VM is provided either via Multipass or a AWS/EC2 instance. The instance is pre-configured with all the software required to install the Smart Agent in Kubernetes, deploy a NGNIX ReplicaSet 1 and finally deploy a microservices application which has been instrumented to send Traces and Spans using Jaeger 2 . The workshop also introduces you to dashboarding, editing and creating charts, creating detectors to fire alerts, Monitoring as Code 3 and the SignalFx Service Bureau 3 By the end of this technical workshop you will have a good understanding of some of the key features and capabilities of the SignalFx platform. Kubernetes ReplicaSet \u21a9 Jaeger, inspired by Dapper and OpenZipkin, is a distributed tracing system released as open source by Uber Technologies. It is used for monitoring and troubleshooting microservices-based distributed systems \u21a9 Monitoring as Code and Service Bureau \u21a9 \u21a9","title":"Workshop Introduction"},{"location":"smartagent/#introduction","text":"During this technical workshop you will build out an environment based on a lightweight Kubernetes deployment. In order to simplify the workshop modules, a pre-configure VM is provided either via Multipass or a AWS/EC2 instance. The instance is pre-configured with all the software required to install the Smart Agent in Kubernetes, deploy a NGNIX ReplicaSet 1 and finally deploy a microservices application which has been instrumented to send Traces and Spans using Jaeger 2 . The workshop also introduces you to dashboarding, editing and creating charts, creating detectors to fire alerts, Monitoring as Code 3 and the SignalFx Service Bureau 3 By the end of this technical workshop you will have a good understanding of some of the key features and capabilities of the SignalFx platform. Kubernetes ReplicaSet \u21a9 Jaeger, inspired by Dapper and OpenZipkin, is a distributed tracing system released as open source by Uber Technologies. It is used for monitoring and troubleshooting microservices-based distributed systems \u21a9 Monitoring as Code and Service Bureau \u21a9 \u21a9","title":"Introduction"},{"location":"smartagent/k3s/","text":"Deploying the Smart Agent in Kubernetes (K3s) \u00b6 Use the SignalFx Helm chart to install the Smart Agent in K3s Explore your cluster in the Kubernetes Navigator 1. Obtain SignalFx Access Token \u00b6 You will need to obtain your Access Token 1 from the SignalFx UI once Kubernetes is running. You can find your Access Token by clicking on your profile icon on the top right of the SignalFx UI. Then select Organization Settings \u2192 Access Tokens . Expand the Default token, then click on Show Token to expose your token. Click the Copy button to copy to clipboard. You will also need to obtain the name of the Realm for your SignalFx account. Click on the profile icon again, but this time select My Profile . The Realm can be found in the middle of the page within the Organizations section. In this example it is us1 . 2. Use Helm to deploy agent \u00b6 Create the following variables to use in the proceeding helm install command, replacing the highlighted VARIABLE with the appropriate values. For instance, if your realm is us1 , you would export REALM=us1 . Input export ACCESS_TOKEN= ACCESS TOKEN, from organisation page export REALM= REALM e.g. us1 Install the agent using the SignalFx Helm chart. Firstly, add the SignalFx Helm chart repository to Helm. Input helm repo add signalfx https://dl.signalfx.com/helm-repo Ensure the latest version of the SignalFx Helm repository Input helm repo update Install the Smart Agent Helm chart with the following commands, do NOT edit this: Input helm install \\ --set signalFxAccessToken=$ACCESS_TOKEN \\ --set clusterName=$(hostname)-k3s-cluster \\ --set kubeletAPI.url=https://localhost:10250 \\ --set signalFxRealm=$REALM \\ --set traceEndpointUrl=https://ingest.$REALM.signalfx.com/v2/trace \\ --set gatherDockerMetrics=false \\ signalfx-agent signalfx/signalfx-agent \\ -f ~/workshop/k3s/values.yaml You can monitor the progress of the deployment by running kubectl get pods which should typically report a new pod is up and running after about 30 seconds. Ensure the status is reported as Running before continuing. Input kubectl get pods Output NAME READY STATUS RESTARTS AGE signalfx-agent-66tvr 1/1 Running 0 7s Ensure there are no errors by tailing the logs from the Smart Agent Pod. Output should look similar to the log output shown below. Use the label set by the helm install to tail logs (You will need to press Ctrl + C to exit). Or use the installed k9s terminal UI for bonus points! Input kubectl logs -l app = signalfx-agent -f Output signalfx-agent time=\"2020-05-27T20:52:10Z\" level=info msg=\"Starting up agent version 5.2.1\" \u2502 signalfx-agent time=\"2020-05-27T20:52:10Z\" level=info msg=\"Watching for config file changes\" \u2502 signalfx-agent time=\"2020-05-27T20:52:10Z\" level=info msg=\"New config loaded\" \u2502 signalfx-agent time=\"2020-05-27T20:52:10Z\" level=info msg=\"Using log level info\" \u2502 signalfx-agent time=\"2020-05-27T20:52:10Z\" level=info msg=\"Fetching host id dimensions\" \u2502 signalfx-agent time=\"2020-05-27T20:52:10Z\" level=info msg=\"Trying to get fully qualified hostname\" \u2502 signalfx-agent time=\"2020-05-27T20:52:10Z\" level=info msg=\"Using hostname sedj\" \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Using host id dimensions map[host:sedj kubernetes_node_uid:ea3bf9ff-3f04-4485-9702-6e7097b261dd]\" \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Sending datapoints to https://ingest.us0.signalfx.com/v2/datapoint\" \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Sending events to https://ingest.us0.signalfx.com/v2/event\" \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Sending trace spans to https://ingest.us0.signalfx.com/v2/trace\" \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Setting cluster:sedj-k3s-cluster property on host:sedj dimension\" \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=1 monitorType=cpu \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=2 monitorType=filesystems \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=3 monitorType=disk-io \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=4 monitorType=net-io \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=5 monitorType=load \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=6 monitorType=memory \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=7 monitorType=host-metadata \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=8 monitorType=processlist \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=9 monitorType=vmem \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=10 monitorType=kubelet-stats \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=11 monitorType=kubernetes-cluster \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=12 monitorType=signalfx-forwarder \u2502 signalfx-agent I0527 20:52:12.796150 1 leaderelection.go:242] attempting to acquire leader lease default/signalfx-agent-leader... \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=13 monitorType=kubernetes-events \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Done configuring agent\" \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Serving internal metrics at localhost:8095\" \u2502 signalfx-agent I0527 20:52:12.813288 1 leaderelection.go:252] successfully acquired lease default/signalfx-agent-leader \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"K8s leader is now node sedj\" \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"This instance is now the leader and will send events\" monitorType=kubernetes-events \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Starting K8s API resource sync\" \u2502 3. Validate metrics in the UI \u00b6 In the SignalFx UI, goto INFRASTRUCTURE \u2192 Kubernetes Navigator \u2192 Cluster Map and open the Kubernetes Navigator Cluster Map to ensure metrics are being sent. Validate that your cluster is discovered and reporting by finding your cluster (in the workshop you will see many other clusters). To find your cluster name run the following command and copy the output to your clipboard: Input echo $( hostname ) -k3s-cluster replace screenshot To examine the health of your node, first click on the blue cross on your cluster. This will drill down to the node level. Next, open the side bar by clicking on the side bar button to open the Metrics side bar. Once it is open, you can use the slider on the side to explore the various charts relevant to your cluster/node: CPU, Memory, Network, Events etc. replace screenshot Access tokens (sometimes called org tokens) are long-lived organization-level tokens. By default, these tokens persist for 5 years, and thus are suitable for embedding into emitters that send data points over long periods of time, or for any long-running scripts that call the SignalFx API. \u21a9","title":"Deploy the Smart Agent in K3s"},{"location":"smartagent/k3s/#deploying-the-smart-agent-in-kubernetes-k3s","text":"Use the SignalFx Helm chart to install the Smart Agent in K3s Explore your cluster in the Kubernetes Navigator","title":"Deploying the Smart Agent in Kubernetes (K3s)"},{"location":"smartagent/k3s/#1-obtain-signalfx-access-token","text":"You will need to obtain your Access Token 1 from the SignalFx UI once Kubernetes is running. You can find your Access Token by clicking on your profile icon on the top right of the SignalFx UI. Then select Organization Settings \u2192 Access Tokens . Expand the Default token, then click on Show Token to expose your token. Click the Copy button to copy to clipboard. You will also need to obtain the name of the Realm for your SignalFx account. Click on the profile icon again, but this time select My Profile . The Realm can be found in the middle of the page within the Organizations section. In this example it is us1 .","title":"1. Obtain SignalFx Access Token"},{"location":"smartagent/k3s/#2-use-helm-to-deploy-agent","text":"Create the following variables to use in the proceeding helm install command, replacing the highlighted VARIABLE with the appropriate values. For instance, if your realm is us1 , you would export REALM=us1 . Input export ACCESS_TOKEN= ACCESS TOKEN, from organisation page export REALM= REALM e.g. us1 Install the agent using the SignalFx Helm chart. Firstly, add the SignalFx Helm chart repository to Helm. Input helm repo add signalfx https://dl.signalfx.com/helm-repo Ensure the latest version of the SignalFx Helm repository Input helm repo update Install the Smart Agent Helm chart with the following commands, do NOT edit this: Input helm install \\ --set signalFxAccessToken=$ACCESS_TOKEN \\ --set clusterName=$(hostname)-k3s-cluster \\ --set kubeletAPI.url=https://localhost:10250 \\ --set signalFxRealm=$REALM \\ --set traceEndpointUrl=https://ingest.$REALM.signalfx.com/v2/trace \\ --set gatherDockerMetrics=false \\ signalfx-agent signalfx/signalfx-agent \\ -f ~/workshop/k3s/values.yaml You can monitor the progress of the deployment by running kubectl get pods which should typically report a new pod is up and running after about 30 seconds. Ensure the status is reported as Running before continuing. Input kubectl get pods Output NAME READY STATUS RESTARTS AGE signalfx-agent-66tvr 1/1 Running 0 7s Ensure there are no errors by tailing the logs from the Smart Agent Pod. Output should look similar to the log output shown below. Use the label set by the helm install to tail logs (You will need to press Ctrl + C to exit). Or use the installed k9s terminal UI for bonus points! Input kubectl logs -l app = signalfx-agent -f Output signalfx-agent time=\"2020-05-27T20:52:10Z\" level=info msg=\"Starting up agent version 5.2.1\" \u2502 signalfx-agent time=\"2020-05-27T20:52:10Z\" level=info msg=\"Watching for config file changes\" \u2502 signalfx-agent time=\"2020-05-27T20:52:10Z\" level=info msg=\"New config loaded\" \u2502 signalfx-agent time=\"2020-05-27T20:52:10Z\" level=info msg=\"Using log level info\" \u2502 signalfx-agent time=\"2020-05-27T20:52:10Z\" level=info msg=\"Fetching host id dimensions\" \u2502 signalfx-agent time=\"2020-05-27T20:52:10Z\" level=info msg=\"Trying to get fully qualified hostname\" \u2502 signalfx-agent time=\"2020-05-27T20:52:10Z\" level=info msg=\"Using hostname sedj\" \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Using host id dimensions map[host:sedj kubernetes_node_uid:ea3bf9ff-3f04-4485-9702-6e7097b261dd]\" \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Sending datapoints to https://ingest.us0.signalfx.com/v2/datapoint\" \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Sending events to https://ingest.us0.signalfx.com/v2/event\" \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Sending trace spans to https://ingest.us0.signalfx.com/v2/trace\" \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Setting cluster:sedj-k3s-cluster property on host:sedj dimension\" \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=1 monitorType=cpu \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=2 monitorType=filesystems \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=3 monitorType=disk-io \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=4 monitorType=net-io \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=5 monitorType=load \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=6 monitorType=memory \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=7 monitorType=host-metadata \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=8 monitorType=processlist \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=9 monitorType=vmem \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=10 monitorType=kubelet-stats \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=11 monitorType=kubernetes-cluster \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=12 monitorType=signalfx-forwarder \u2502 signalfx-agent I0527 20:52:12.796150 1 leaderelection.go:242] attempting to acquire leader lease default/signalfx-agent-leader... \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Creating new monitor\" discoveryRule= monitorID=13 monitorType=kubernetes-events \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Done configuring agent\" \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Serving internal metrics at localhost:8095\" \u2502 signalfx-agent I0527 20:52:12.813288 1 leaderelection.go:252] successfully acquired lease default/signalfx-agent-leader \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"K8s leader is now node sedj\" \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"This instance is now the leader and will send events\" monitorType=kubernetes-events \u2502 signalfx-agent time=\"2020-05-27T20:52:12Z\" level=info msg=\"Starting K8s API resource sync\" \u2502","title":"2. Use Helm to deploy agent"},{"location":"smartagent/k3s/#3-validate-metrics-in-the-ui","text":"In the SignalFx UI, goto INFRASTRUCTURE \u2192 Kubernetes Navigator \u2192 Cluster Map and open the Kubernetes Navigator Cluster Map to ensure metrics are being sent. Validate that your cluster is discovered and reporting by finding your cluster (in the workshop you will see many other clusters). To find your cluster name run the following command and copy the output to your clipboard: Input echo $( hostname ) -k3s-cluster replace screenshot To examine the health of your node, first click on the blue cross on your cluster. This will drill down to the node level. Next, open the side bar by clicking on the side bar button to open the Metrics side bar. Once it is open, you can use the slider on the side to explore the various charts relevant to your cluster/node: CPU, Memory, Network, Events etc. replace screenshot Access tokens (sometimes called org tokens) are long-lived organization-level tokens. By default, these tokens persist for 5 years, and thus are suitable for embedding into emitters that send data points over long periods of time, or for any long-running scripts that call the SignalFx API. \u21a9","title":"3. Validate metrics in the UI"},{"location":"smartagent/nginx/","text":"Deploying NGINX in K3s - Lab Summary \u00b6 Deploy a NGINX ReplicaSet into your K3s cluster and confirm the auto discovery of your NGINX deployment. Run a benchmark test to create metrics and confirm them streaming into SignalFX! 1. Start your NGINX \u00b6 This deployment of NGINX has been configured to use Kubernetes pod annotations to tell the Smart Agent how to monitor the service. This is achieved by defining the port and monitor type to use for monitoring the NGINX service e.g. Example Annotation agent.signalfx.com/monitorType.80: \"collectd/nginx\" Remain in the Multipass or AWS/EC2 shell session and change into the nginx directory: Input cd ~/workshop/k3s/nginx Verify the number of pods running in the SignalFx UI by selecting the WORKLOADS tab. This should give you an overview of the workloads on your cluster. Note the single agent container running per node among the default Kubernetes pods. This single container will monitor all the pods and services being deployed on this node! Now switch back to the default cluster node view by selecting the MAP tab and select your cluster again. 2. Create NGINX deployment \u00b6 Create the NGINX configmap using the nginx.conf file: Input kubectl create configmap nginxconfig --from-file=nginx.conf Output configmap/nginxconfig created Then create the deployment: Input kubectl create -f nginx-deployment.yaml Output deployment.apps/nginx-deployment created Validate the deployment has been successful and that the NGINX pods are running. If you have the SignalFx UI open you should see new Pods being started and containers being deployed. It should only take around 20 seconds for the pods to transition into a Running state. In the SignalFx UI you should have a cluster that looks like below: If you select the WORKLOADS tab again you should now see that there is a new replica set and a deployment added for NGINX: Let's validate this in your shell as well: Input kubectl get pods Output NAME READY STATUS RESTARTS AGE signalfx-agent-n7nz2 1/1 Running 0 11m nginx-deployment-f96cf6966-jhmjp 1/1 Running 0 21s nginx-deployment-f96cf6966-459vf 1/1 Running 0 21s nginx-deployment-f96cf6966-vrnfc 1/1 Running 0 21s nginx-deployment-f96cf6966-7z4tm 1/1 Running 0 21s Before running a benchmark against NGINX (to generate metrics) we need to expose port 80 (HTTP) Input kubectl create service nodeport nginx --tcp=80:80 Output service/nginx created Run kubectl get svc then make a note of the CLUSTER-IP address that is allocated to the NGINX service. Input kubectl get svc Output NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.96.0.1 <none> 443/TCP 9m3s nginx NodePort 10.110.36.62 <none> 80:30995/TCP 8s 3. Run Siege Benchmark \u00b6 Using the NGINX CLUSTER-IP address reported from above, use the Siege Load Testing command ( siege ) to generate some traffic to light up your SignalFx NGINX dashboard. Run this a couple of times! Input siege -b -r 50 -c 20 --no-parser http:// CLUSTER-IP ADDRESS / 1>/dev/null Output ** SIEGE 4.0.5 ** Preparing 20 concurrent users for battle. The server is now under siege... Transactions: 1000 hits Availability: 100.00 % Elapsed time: 1.17 secs Data transferred: 20.05 MB Response time: 0.02 secs Transaction rate: 854.70 trans/sec Throughput: 17.14 MB/sec Concurrency: 19.77 Successful transactions: 1000 Failed transactions: 0 Longest transaction: 0.16 Shortest transaction: 0.01 Validate you are seeing metrics in the UI by going to Dashboards \u2192 NGINX \u2192 NGINX Servers","title":"Deploy NGINX in K3s"},{"location":"smartagent/nginx/#deploying-nginx-in-k3s-lab-summary","text":"Deploy a NGINX ReplicaSet into your K3s cluster and confirm the auto discovery of your NGINX deployment. Run a benchmark test to create metrics and confirm them streaming into SignalFX!","title":"Deploying NGINX in K3s - Lab Summary"},{"location":"smartagent/nginx/#1-start-your-nginx","text":"This deployment of NGINX has been configured to use Kubernetes pod annotations to tell the Smart Agent how to monitor the service. This is achieved by defining the port and monitor type to use for monitoring the NGINX service e.g. Example Annotation agent.signalfx.com/monitorType.80: \"collectd/nginx\" Remain in the Multipass or AWS/EC2 shell session and change into the nginx directory: Input cd ~/workshop/k3s/nginx Verify the number of pods running in the SignalFx UI by selecting the WORKLOADS tab. This should give you an overview of the workloads on your cluster. Note the single agent container running per node among the default Kubernetes pods. This single container will monitor all the pods and services being deployed on this node! Now switch back to the default cluster node view by selecting the MAP tab and select your cluster again.","title":"1. Start your NGINX"},{"location":"smartagent/nginx/#2-create-nginx-deployment","text":"Create the NGINX configmap using the nginx.conf file: Input kubectl create configmap nginxconfig --from-file=nginx.conf Output configmap/nginxconfig created Then create the deployment: Input kubectl create -f nginx-deployment.yaml Output deployment.apps/nginx-deployment created Validate the deployment has been successful and that the NGINX pods are running. If you have the SignalFx UI open you should see new Pods being started and containers being deployed. It should only take around 20 seconds for the pods to transition into a Running state. In the SignalFx UI you should have a cluster that looks like below: If you select the WORKLOADS tab again you should now see that there is a new replica set and a deployment added for NGINX: Let's validate this in your shell as well: Input kubectl get pods Output NAME READY STATUS RESTARTS AGE signalfx-agent-n7nz2 1/1 Running 0 11m nginx-deployment-f96cf6966-jhmjp 1/1 Running 0 21s nginx-deployment-f96cf6966-459vf 1/1 Running 0 21s nginx-deployment-f96cf6966-vrnfc 1/1 Running 0 21s nginx-deployment-f96cf6966-7z4tm 1/1 Running 0 21s Before running a benchmark against NGINX (to generate metrics) we need to expose port 80 (HTTP) Input kubectl create service nodeport nginx --tcp=80:80 Output service/nginx created Run kubectl get svc then make a note of the CLUSTER-IP address that is allocated to the NGINX service. Input kubectl get svc Output NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.96.0.1 <none> 443/TCP 9m3s nginx NodePort 10.110.36.62 <none> 80:30995/TCP 8s","title":"2. Create NGINX deployment"},{"location":"smartagent/nginx/#3-run-siege-benchmark","text":"Using the NGINX CLUSTER-IP address reported from above, use the Siege Load Testing command ( siege ) to generate some traffic to light up your SignalFx NGINX dashboard. Run this a couple of times! Input siege -b -r 50 -c 20 --no-parser http:// CLUSTER-IP ADDRESS / 1>/dev/null Output ** SIEGE 4.0.5 ** Preparing 20 concurrent users for battle. The server is now under siege... Transactions: 1000 hits Availability: 100.00 % Elapsed time: 1.17 secs Data transferred: 20.05 MB Response time: 0.02 secs Transaction rate: 854.70 trans/sec Throughput: 17.14 MB/sec Concurrency: 19.77 Successful transactions: 1000 Failed transactions: 0 Longest transaction: 0.16 Shortest transaction: 0.01 Validate you are seeing metrics in the UI by going to Dashboards \u2192 NGINX \u2192 NGINX Servers","title":"3. Run Siege Benchmark"},{"location":"smartagent/prep/","text":"Get Data In - Lab Summary \u00b6 Download the Workshop Start a Multipass 1 or AWS/EC2 instance Deploy the SignalFx Smart Agent 2 in K3s Validate Kubernetes 3 K3s cluster is visible in Kubernetes Navigator Deploy a NGINX 4 ReplicaSet in K3s Validate NGNIX metrics are flowing 1. Module Pre-requisites \u00b6 Running Locally Multipass Install Multipass for your operating system. Make sure you are using at least version 1.2.0 . On a Mac you can also install via Homebrew e.g. brew cask install multipass Struggling with Multipass? Ask your instructor(s) for access to a pre-provisioned AWS/EC2 instance, you can then ignore the rest of this preparation lab and go straight to the next lab Deploying the Smart Agent in Kubernetes (K3s) . Running in AWS AWS/EC2 Instance Install Terraform for your operating system. Please make sure it is version 0.12.18 or above. On a Mac you can also install via Homebrew e.g. brew install terraform . This will get around Mac OS Catalina security. 2. Download DevOps Workshop \u00b6 Regardless if you are running this lab locally or if you are going to create your own AWS/EC2 Instance you need to download the DevOps Workshop zip file locally, unzip the file, rename it and cd into the directory. Linux/Mac OS WSVERSION = 1 .21 curl -OL https://github.com/signalfx/devops-workshop/archive/v $WSVERSION .zip unzip v $WSVERSION .zip mv devops-workshop- $WSVERSION workshop cd workshop export INSTANCE = $( cat /dev/urandom | base64 | tr -dc 'a-z' | head -c4 ) Windows Info Download the zip by clicking on the following URL https://github.com/signalfx/devops-workshop/archive/v1.21.zip . Once downloaded, unzip the the file and rename it to workshop . Then, from the command prompt change into that directory and run $INSTANCE = (\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\".tochararray() | sort {Get-Random})[0..3] -join '' If you are using your own AWS/EC2 instance please skip to 3. Launch Instance section and select the Launch AWS/EC2 instance tab 3. Launch Instance \u00b6 Launch Multipass instance In this section you will build and launch the Multipass instance which will run the Kubernetes (K3s) environment that you will use in multiple labs. For \u00b5APM module we use the Hot R.O.D 5 application to emit Traces/Spans for SignalFx \u00b5APM. Launch your instance with: multipass launch \\ --name $INSTANCE \\ --cloud-init cloud-init/k3s.yaml Once the instance has been successfully created (this can take several minutes), shell into it. Input multipass shell $INSTANCE Output \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2557 \u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u255d \u255a\u2588\u2588\u2557 \u2588\u2588\u2554\u255d\u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2588\u2588\u2551 \u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u255a\u2588\u2588\u2588\u2588\u2554\u255d \u255a\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2551 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551 \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d To run a command as administrator (user \"root\"), use \"sudo <command>\". See \"man sudo_root\" for details Waiting for cloud-init status... Your instance is ready! ubuntu@vmpe-k3s:~$ Once your instance presents you with the DevOps logo, you have completed the preparation for your Multipass instance and can go directly to the next lab Deploy the Smart Agent in K3s . Launch AWS/EC2 instance In this section you will use terraform to build an AWS/EC2 instance in your favorite AWS region and will automatically deploy the Kubernetes (K3s) environment that you will use in this Workshop. AWS Access Keys You will need access to an AWS account to obtain both AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY . Minimum requirements For the \u00b5APM module we are using the Hot R.O.D. application. The minimum requirements are: Hot R.O.D AWS/EC2 Instance min. requirements: t2.micro 1 vCPU, 8Gb Disk, 1Gb Memory Prepare Terraform The first step is to go into the sub-directory where the Terraform files are located and initialise Terraform and upgrade the AWS Terraform Provider. Input cd ec2 terraform init -upgrade Output ~/workshop/ec2$ terraform init -upgrade Initializing the backend... Initializing provider plugins... - Checking for available provider plugins... - Downloading plugin for provider \"aws\" (hashicorp/aws) 2.60.0... The following providers do not have any version constraints in configuration, so the latest version was installed. To prevent automatic upgrades to new major versions that may contain breaking changes, it is recommended to add version = \"...\" constraints to the corresponding provider blocks in configuration, with the constraint strings suggested below. * provider.aws: version = \"~> 2.60\" Terraform has been successfully initialized! You may now begin working with Terraform. Try running \"terraform plan\" to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary. Create AWS/EC2 Instance Creating the AWS/EC2 instance is done in two steps, a planning phase and an apply phase. The planning phase will validate the Terraform scripts and check what changes it will make to your AWS environment. The apply phase will actually create the instance. First, you need to create environment variables for your AWS access keys. Input export AWS_ACCESS_KEY_ID = \" YOUR_AWS_ACCESS_KEY_ID \" export AWS_SECRET_ACCESS_KEY = \" YOUR_AWS_SECRET_ACCESS_KEY \" echo $AWS_ACCESS_KEY_ID $AWS_SECRET_ACCESS_KEY Output ID: Axxxxxxxxxxxxxxxxy, KEY: Axxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxb Once you have confirmed that you have set you AWS_SECRET_ACCESS_KEY_ID & AWS_SECRET_ACCESS_KEY correctly, you can start with the planning phase. Important Desired AWS Region : (Any AWS region by name, for example us-west-2 ) Please remember these values as you will need them again for the planning phase and when you use Terraform to destroy your AWS/EC2 instance. As we only wish to provide the input once, we are going to capture the output in a .out file that we can use for the apply step. Please provide your initials for the output file as indicated. Input terraform plan -var = \"aws_instance_count=1\" -var = \"instance_type=1\" -out = devops-plan.out Enter your desired AWS Region where you wish to run the AWS/EC2 instance e.g. us-west-2 Example var.aws_region Provide the desired region Enter a value: us-west-2 Output Refreshing Terraform state in-memory prior to plan... The refreshed state will be used to calculate this plan, but will not be persisted to local or remote state storage. data.aws_ami.latest-ubuntu: Refreshing state... ------------------------------------------------------------------------ An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: **(BIG WALL OF AWS RELATED TEXT REMOVED)** Plan: 2 to add, 0 to change, 0 to destroy. ------------------------------------------------------------------------ This plan was saved to: devops-plan.out To perform exactly these actions, run the following command to apply: terraform apply \"devops-plan.out\" If there are no errors in the output and terraform has created your output file, you can start the apply phase of Terraform. This will create the AWS/EC2 instance. Input terraform apply \"devops-plan.out\" Output ws_security_group.instance: Creating... aws_security_group.instance: Creation complete after 2s [id=sg-0459afecae5953b51] aws_instance.devops-instance[0]: Creating... aws_instance.devops-instance[0]: Still creating... [10s elapsed] aws_instance.devops-instance[0]: Still creating... [20s elapsed] aws_instance.devops-instance[0]: Creation complete after 23s [id=i-095a12cd39f8e2283] Apply complete! Resources: 2 added, 0 changed, 0 destroyed. The state of your infrastructure has been saved to the path below. This state is required to modify and destroy your infrastructure, so keep it safe. To inspect the complete state use the `terraform show` command. State path: terraform.tfstate Outputs: ip = [ \"YOUR IP ADDRESS\", ] Verify there are no errors and copy the ip address that you see in the green output. SSH into AWS/EC2 Instance Once the instance has been successfully created (this can take several minutes), ssh into it. In most cases your ssh client will ask you to verify the connection. Input ssh ubuntu@YOUR IP ADDRESS Output The authenticity of host 'YOUR IP ADDRESS (YOUR IP ADDRESS)' can't be established. ECDSA key fingerprint is SHA256:XdqN55g0z/ER660PARM+mGqtpYpwM3333YS9Ac8Y9hLY. Are you sure you want to continue connecting (yes/no/[fingerprint])? Please confirm that you wish to continue by replying to the prompt with yes Input Are you sure you want to continue connecting ( yes/no/ [ fingerprint ]) ? yes Output Warning: Permanently added 'YOUR IP ADDRESS' (ECDSA) to the list of known hosts. ubuntu@YOUR IP ADDRESS's password: To login to your instance please use the password provided by the Workshop host. Input ubuntu@YOUR IP ADDRESS ' s password: PASSWORD Output \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2557 \u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u255d \u255a\u2588\u2588\u2557 \u2588\u2588\u2554\u255d\u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2588\u2588\u2551 \u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u255a\u2588\u2588\u2588\u2588\u2554\u255d \u255a\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2551 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551 \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d To run a command as administrator (user \"root\"), use \"sudo <command>\". See \"man sudo_root\" for details Waiting for cloud-init status... Your instance is ready! ubuntu@ip-172-31-41-196:~$ Once your instance presents you with the DevOps logo, make sure you see Your instance is ready! in the output. You have now completed the preparation for your AWS/EC2 instance and can go directly to the next lab Deploy the Smart Agent in K3s . Multipass is a lightweight VM manager for Linux, Windows and macOS. It's designed for developers who want a fresh Ubuntu environment with a single command. It uses KVM on Linux, Hyper-V on Windows and HyperKit on macOS to run the VM with minimal overhead. It can also use VirtualBox on Windows and macOS. Multipass will fetch images for you and keep them up to date. \u21a9 The SignalFx Smart Agent gathers host performance, application, and service-level metrics from both containerized and non-container environments. The Smart Agent installs with more than 100 bundled monitors for gathering data, including Python-based plug-ins such as Mongo, Redis, and Docker. \u21a9 What is Kubernetes? \u21a9 What is NGINX? \u21a9 What is Hot R.O.D.? \u21a9","title":"Workshop Preparation"},{"location":"smartagent/prep/#get-data-in-lab-summary","text":"Download the Workshop Start a Multipass 1 or AWS/EC2 instance Deploy the SignalFx Smart Agent 2 in K3s Validate Kubernetes 3 K3s cluster is visible in Kubernetes Navigator Deploy a NGINX 4 ReplicaSet in K3s Validate NGNIX metrics are flowing","title":"Get Data In - Lab Summary"},{"location":"smartagent/prep/#1-module-pre-requisites","text":"Running Locally Multipass Install Multipass for your operating system. Make sure you are using at least version 1.2.0 . On a Mac you can also install via Homebrew e.g. brew cask install multipass Struggling with Multipass? Ask your instructor(s) for access to a pre-provisioned AWS/EC2 instance, you can then ignore the rest of this preparation lab and go straight to the next lab Deploying the Smart Agent in Kubernetes (K3s) . Running in AWS AWS/EC2 Instance Install Terraform for your operating system. Please make sure it is version 0.12.18 or above. On a Mac you can also install via Homebrew e.g. brew install terraform . This will get around Mac OS Catalina security.","title":"1. Module Pre-requisites"},{"location":"smartagent/prep/#2-download-devops-workshop","text":"Regardless if you are running this lab locally or if you are going to create your own AWS/EC2 Instance you need to download the DevOps Workshop zip file locally, unzip the file, rename it and cd into the directory. Linux/Mac OS WSVERSION = 1 .21 curl -OL https://github.com/signalfx/devops-workshop/archive/v $WSVERSION .zip unzip v $WSVERSION .zip mv devops-workshop- $WSVERSION workshop cd workshop export INSTANCE = $( cat /dev/urandom | base64 | tr -dc 'a-z' | head -c4 ) Windows Info Download the zip by clicking on the following URL https://github.com/signalfx/devops-workshop/archive/v1.21.zip . Once downloaded, unzip the the file and rename it to workshop . Then, from the command prompt change into that directory and run $INSTANCE = (\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\".tochararray() | sort {Get-Random})[0..3] -join '' If you are using your own AWS/EC2 instance please skip to 3. Launch Instance section and select the Launch AWS/EC2 instance tab","title":"2. Download DevOps Workshop"},{"location":"smartagent/prep/#3-launch-instance","text":"Launch Multipass instance In this section you will build and launch the Multipass instance which will run the Kubernetes (K3s) environment that you will use in multiple labs. For \u00b5APM module we use the Hot R.O.D 5 application to emit Traces/Spans for SignalFx \u00b5APM. Launch your instance with: multipass launch \\ --name $INSTANCE \\ --cloud-init cloud-init/k3s.yaml Once the instance has been successfully created (this can take several minutes), shell into it. Input multipass shell $INSTANCE Output \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2557 \u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u255d \u255a\u2588\u2588\u2557 \u2588\u2588\u2554\u255d\u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2588\u2588\u2551 \u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u255a\u2588\u2588\u2588\u2588\u2554\u255d \u255a\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2551 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551 \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d To run a command as administrator (user \"root\"), use \"sudo <command>\". See \"man sudo_root\" for details Waiting for cloud-init status... Your instance is ready! ubuntu@vmpe-k3s:~$ Once your instance presents you with the DevOps logo, you have completed the preparation for your Multipass instance and can go directly to the next lab Deploy the Smart Agent in K3s . Launch AWS/EC2 instance In this section you will use terraform to build an AWS/EC2 instance in your favorite AWS region and will automatically deploy the Kubernetes (K3s) environment that you will use in this Workshop. AWS Access Keys You will need access to an AWS account to obtain both AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY . Minimum requirements For the \u00b5APM module we are using the Hot R.O.D. application. The minimum requirements are: Hot R.O.D AWS/EC2 Instance min. requirements: t2.micro 1 vCPU, 8Gb Disk, 1Gb Memory Prepare Terraform The first step is to go into the sub-directory where the Terraform files are located and initialise Terraform and upgrade the AWS Terraform Provider. Input cd ec2 terraform init -upgrade Output ~/workshop/ec2$ terraform init -upgrade Initializing the backend... Initializing provider plugins... - Checking for available provider plugins... - Downloading plugin for provider \"aws\" (hashicorp/aws) 2.60.0... The following providers do not have any version constraints in configuration, so the latest version was installed. To prevent automatic upgrades to new major versions that may contain breaking changes, it is recommended to add version = \"...\" constraints to the corresponding provider blocks in configuration, with the constraint strings suggested below. * provider.aws: version = \"~> 2.60\" Terraform has been successfully initialized! You may now begin working with Terraform. Try running \"terraform plan\" to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary. Create AWS/EC2 Instance Creating the AWS/EC2 instance is done in two steps, a planning phase and an apply phase. The planning phase will validate the Terraform scripts and check what changes it will make to your AWS environment. The apply phase will actually create the instance. First, you need to create environment variables for your AWS access keys. Input export AWS_ACCESS_KEY_ID = \" YOUR_AWS_ACCESS_KEY_ID \" export AWS_SECRET_ACCESS_KEY = \" YOUR_AWS_SECRET_ACCESS_KEY \" echo $AWS_ACCESS_KEY_ID $AWS_SECRET_ACCESS_KEY Output ID: Axxxxxxxxxxxxxxxxy, KEY: Axxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxb Once you have confirmed that you have set you AWS_SECRET_ACCESS_KEY_ID & AWS_SECRET_ACCESS_KEY correctly, you can start with the planning phase. Important Desired AWS Region : (Any AWS region by name, for example us-west-2 ) Please remember these values as you will need them again for the planning phase and when you use Terraform to destroy your AWS/EC2 instance. As we only wish to provide the input once, we are going to capture the output in a .out file that we can use for the apply step. Please provide your initials for the output file as indicated. Input terraform plan -var = \"aws_instance_count=1\" -var = \"instance_type=1\" -out = devops-plan.out Enter your desired AWS Region where you wish to run the AWS/EC2 instance e.g. us-west-2 Example var.aws_region Provide the desired region Enter a value: us-west-2 Output Refreshing Terraform state in-memory prior to plan... The refreshed state will be used to calculate this plan, but will not be persisted to local or remote state storage. data.aws_ami.latest-ubuntu: Refreshing state... ------------------------------------------------------------------------ An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: **(BIG WALL OF AWS RELATED TEXT REMOVED)** Plan: 2 to add, 0 to change, 0 to destroy. ------------------------------------------------------------------------ This plan was saved to: devops-plan.out To perform exactly these actions, run the following command to apply: terraform apply \"devops-plan.out\" If there are no errors in the output and terraform has created your output file, you can start the apply phase of Terraform. This will create the AWS/EC2 instance. Input terraform apply \"devops-plan.out\" Output ws_security_group.instance: Creating... aws_security_group.instance: Creation complete after 2s [id=sg-0459afecae5953b51] aws_instance.devops-instance[0]: Creating... aws_instance.devops-instance[0]: Still creating... [10s elapsed] aws_instance.devops-instance[0]: Still creating... [20s elapsed] aws_instance.devops-instance[0]: Creation complete after 23s [id=i-095a12cd39f8e2283] Apply complete! Resources: 2 added, 0 changed, 0 destroyed. The state of your infrastructure has been saved to the path below. This state is required to modify and destroy your infrastructure, so keep it safe. To inspect the complete state use the `terraform show` command. State path: terraform.tfstate Outputs: ip = [ \"YOUR IP ADDRESS\", ] Verify there are no errors and copy the ip address that you see in the green output. SSH into AWS/EC2 Instance Once the instance has been successfully created (this can take several minutes), ssh into it. In most cases your ssh client will ask you to verify the connection. Input ssh ubuntu@YOUR IP ADDRESS Output The authenticity of host 'YOUR IP ADDRESS (YOUR IP ADDRESS)' can't be established. ECDSA key fingerprint is SHA256:XdqN55g0z/ER660PARM+mGqtpYpwM3333YS9Ac8Y9hLY. Are you sure you want to continue connecting (yes/no/[fingerprint])? Please confirm that you wish to continue by replying to the prompt with yes Input Are you sure you want to continue connecting ( yes/no/ [ fingerprint ]) ? yes Output Warning: Permanently added 'YOUR IP ADDRESS' (ECDSA) to the list of known hosts. ubuntu@YOUR IP ADDRESS's password: To login to your instance please use the password provided by the Workshop host. Input ubuntu@YOUR IP ADDRESS ' s password: PASSWORD Output \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2557 \u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u255d \u255a\u2588\u2588\u2557 \u2588\u2588\u2554\u255d\u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2588\u2588\u2551 \u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u255a\u2588\u2588\u2588\u2588\u2554\u255d \u255a\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2551 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551 \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d To run a command as administrator (user \"root\"), use \"sudo <command>\". See \"man sudo_root\" for details Waiting for cloud-init status... Your instance is ready! ubuntu@ip-172-31-41-196:~$ Once your instance presents you with the DevOps logo, make sure you see Your instance is ready! in the output. You have now completed the preparation for your AWS/EC2 instance and can go directly to the next lab Deploy the Smart Agent in K3s . Multipass is a lightweight VM manager for Linux, Windows and macOS. It's designed for developers who want a fresh Ubuntu environment with a single command. It uses KVM on Linux, Hyper-V on Windows and HyperKit on macOS to run the VM with minimal overhead. It can also use VirtualBox on Windows and macOS. Multipass will fetch images for you and keep them up to date. \u21a9 The SignalFx Smart Agent gathers host performance, application, and service-level metrics from both containerized and non-container environments. The Smart Agent installs with more than 100 bundled monitors for gathering data, including Python-based plug-ins such as Mongo, Redis, and Docker. \u21a9 What is Kubernetes? \u21a9 What is NGINX? \u21a9 What is Hot R.O.D.? \u21a9","title":"3. Launch Instance"},{"location":"victorops/cleanup/","text":"Post Workshop Clean Up \u00b6 Once you have finished with this workshop exit from the Multipass instance(s) you are in and get back to your system command prompt. You can use multipass list to get the names of any current running instances: Input multipass list Example Output Name State IPv4 Image vmpe-vo1 Running 192.168.64.13 Ubuntu 18.04 LTS vmpe-vo2 Running 192.168.64.14 Ubuntu 18.04 LTS Ensure the INSTANCE environment variable is still set: Input echo $INSTANCE If the environment varilable is not set, then you will have to replace ${INSTANCE} below with the prefix of the instance name from the multipass list above. Run the following commands to delete the Multipass instance(s): Input multipass delete --purge ${ INSTANCE } -vo1 multipass delete --purge ${ INSTANCE } -vo2","title":"<b>Workshop Clean-up</b><br /><small>2 minutes</small>"},{"location":"victorops/cleanup/#post-workshop-clean-up","text":"Once you have finished with this workshop exit from the Multipass instance(s) you are in and get back to your system command prompt. You can use multipass list to get the names of any current running instances: Input multipass list Example Output Name State IPv4 Image vmpe-vo1 Running 192.168.64.13 Ubuntu 18.04 LTS vmpe-vo2 Running 192.168.64.14 Ubuntu 18.04 LTS Ensure the INSTANCE environment variable is still set: Input echo $INSTANCE If the environment varilable is not set, then you will have to replace ${INSTANCE} below with the prefix of the instance name from the multipass list above. Run the following commands to delete the Multipass instance(s): Input multipass delete --purge ${ INSTANCE } -vo1 multipass delete --purge ${ INSTANCE } -vo2","title":"Post Workshop Clean Up"},{"location":"victorops/getting_started/","text":"VictorOps Getting Started - Lab Summary \u00b6 Activate your login Configure your Profile Create your Team Configure Rotations Configure Escalation Policies Create Routing Keys 1. Activate your login \u00b6 You should have received an invitation to Activate your VictorOps account via e-mail, click the Activate Account link and follow the prompts. If you did not receive an invitation it is probably because you already have a VictorOps login, linked to a different organisation. If so login to to that Org, then use the organisation dropdown next to your username in the top left to switch to the AppDev-EMEA Org. If you have forgotten your password go to the sign-in page and use the forgotten password link to reset your password. 2. Configure Your Profile \u00b6 Once you are logged in to VictorOps you now need to set up your profile. Click on your login name in the top right hand corner and chose Profile from the drop down. 2.1 Contact Methods \u00b6 Confirm your contact methods are listed correctly and add any additional phone numbers and e-mail address you wish to use. 2.2 Mobile Devices \u00b6 To install the VictorOps app for your smartphone search your phones App Store for VictorOps to find the appropriate version of the app. The publisher should be listed as VictorOps Inc. Configuration help guides are available: Apple Android Install the App and login, then refresh the Profile page and your device should now be listed under the devices section. Click the Test push notification button and confirm you receive the test message. 2.3 Personal Calendar \u00b6 This link will enable you to sync your VictorOps on-call schedule with your calendar, however as you do not have any allocated shifts yet this will currently be empty. You can add it to your calendar by copying the link into your preferred application and setting it up as a new subscription.","title":"Initial Setup"},{"location":"victorops/getting_started/#victorops-getting-started-lab-summary","text":"Activate your login Configure your Profile Create your Team Configure Rotations Configure Escalation Policies Create Routing Keys","title":"VictorOps Getting Started - Lab Summary"},{"location":"victorops/getting_started/#1-activate-your-login","text":"You should have received an invitation to Activate your VictorOps account via e-mail, click the Activate Account link and follow the prompts. If you did not receive an invitation it is probably because you already have a VictorOps login, linked to a different organisation. If so login to to that Org, then use the organisation dropdown next to your username in the top left to switch to the AppDev-EMEA Org. If you have forgotten your password go to the sign-in page and use the forgotten password link to reset your password.","title":"1. Activate your login"},{"location":"victorops/getting_started/#2-configure-your-profile","text":"Once you are logged in to VictorOps you now need to set up your profile. Click on your login name in the top right hand corner and chose Profile from the drop down.","title":"2. Configure Your Profile"},{"location":"victorops/getting_started/#21-contact-methods","text":"Confirm your contact methods are listed correctly and add any additional phone numbers and e-mail address you wish to use.","title":"2.1 Contact Methods"},{"location":"victorops/getting_started/#22-mobile-devices","text":"To install the VictorOps app for your smartphone search your phones App Store for VictorOps to find the appropriate version of the app. The publisher should be listed as VictorOps Inc. Configuration help guides are available: Apple Android Install the App and login, then refresh the Profile page and your device should now be listed under the devices section. Click the Test push notification button and confirm you receive the test message.","title":"2.2 Mobile Devices"},{"location":"victorops/getting_started/#23-personal-calendar","text":"This link will enable you to sync your VictorOps on-call schedule with your calendar, however as you do not have any allocated shifts yet this will currently be empty. You can add it to your calendar by copying the link into your preferred application and setting it up as a new subscription.","title":"2.3 Personal Calendar"},{"location":"victorops/getting_started/escalation/","text":"Configure Escalation Policies \u00b6 Navigate to the Escalation Polices tab on the Teams sub menu, you should have no existing Polices so we need to create some. We are going to create the following Polices to cover off three typical use cases. 1. 24/7 Policy \u00b6 Click Add Escalation Policy Policy Name: 24/7 Step 1 Immediately Notify the on-duty user(s) in rotation \u2192 Senior SRE Escalation Click Save 2. Primary Policy \u00b6 Click Add Escalation Policy Policy Name: Primary Step 1 Immediately Notify the on-duty user(s) in rotation \u2192 Follow the Sun Support - Business Hours Click Add Step Step 2 If still unacked after 15 minutes Notify the next user(s) in the current on-duty shift \u2192 Follow the Sun Support - Business Hours Click Add Step Step 3 If still unacked after 15 more minutes Execute Policy \u2192 [Your Team Name] : 24/7 Click Save 3. Waiting Room Policy \u00b6 Click Add Escalation Policy Policy Name: Waiting Room Step 1 If still unacked after 10 more minutes Execute Policy \u2192 [Your Team Name] : Primary Click Save You should now have the following three escalation polices: You may have noticed that when we created each policy there was the following warning message: Warning There are no routing keys for this policy - it will only receive incidents via manual reroute or when on another escalation policy This is because there are no Routing Keys linked to these Escalation Polices, so now that we have these polices configured we can go and create the Routing Keys.","title":"Configure Escalation Policies"},{"location":"victorops/getting_started/escalation/#configure-escalation-policies","text":"Navigate to the Escalation Polices tab on the Teams sub menu, you should have no existing Polices so we need to create some. We are going to create the following Polices to cover off three typical use cases.","title":"Configure Escalation Policies"},{"location":"victorops/getting_started/escalation/#1-247-policy","text":"Click Add Escalation Policy Policy Name: 24/7 Step 1 Immediately Notify the on-duty user(s) in rotation \u2192 Senior SRE Escalation Click Save","title":"1. 24/7 Policy"},{"location":"victorops/getting_started/escalation/#2-primary-policy","text":"Click Add Escalation Policy Policy Name: Primary Step 1 Immediately Notify the on-duty user(s) in rotation \u2192 Follow the Sun Support - Business Hours Click Add Step Step 2 If still unacked after 15 minutes Notify the next user(s) in the current on-duty shift \u2192 Follow the Sun Support - Business Hours Click Add Step Step 3 If still unacked after 15 more minutes Execute Policy \u2192 [Your Team Name] : 24/7 Click Save","title":"2. Primary Policy"},{"location":"victorops/getting_started/escalation/#3-waiting-room-policy","text":"Click Add Escalation Policy Policy Name: Waiting Room Step 1 If still unacked after 10 more minutes Execute Policy \u2192 [Your Team Name] : Primary Click Save You should now have the following three escalation polices: You may have noticed that when we created each policy there was the following warning message: Warning There are no routing keys for this policy - it will only receive incidents via manual reroute or when on another escalation policy This is because there are no Routing Keys linked to these Escalation Polices, so now that we have these polices configured we can go and create the Routing Keys.","title":"3. Waiting Room Policy"},{"location":"victorops/getting_started/multipass/","text":"Creating a Test Environment \u00b6 You are going to need to record a number of values during this Workshop which we will export as variables in later steps so create values.txt locally to store the following values as you work through the Workshop. values.txt export SFXVOPSID= export ACCESS_TOKEN= export REALM= export ROUTINGKEY= Service_API_Endpoint= 1. Multipass \u00b6 The easiest way to test VictorOps is to use Multipass to a local test VM which will be monitored by SignalFx. If you do not already have Multipass installed you can download the installer from here . MacOS users can install it using Homebrew by running: Code brew cask install multipass 2. SignalFx Details \u00b6 We will use cloud-init to install the SignalFx Agent into the VMs but we first need to obtain the Access Token and Realm from your SignalFx account. You can find your Access Token by clicking on the Settings icon on the top right of the SignalFx UI, select Organization Settings \u2192 Access Tokens , expand the Default token, then click on Show Token to expose your token. Click the Copy button to copy it to your clipboard, then paste it into your values.txt using the ACCESS_TOKEN parameter. You will also need to obtain the name of the Realm for your SignalFx account. Click on the Settings icon again, but this time select My Profile . The Ream can be found in the middle of the page within the Organizations section. In this example it is us1 , make a note of this in your values.txt using the REALM parameter. 3. Local VMs using Multipass \u00b6 The next step is to pull down the cloud-init file to launch a pre-configured VM. Input curl -s https://raw.githubusercontent.com/signalfx/devops-workshop/master/cloud-init/victorops.yaml -o victorops.yaml Open victorops.yaml in your preferred editor and replace SIGNALFX_REALM & SIGNALFX_ACCESS_TOKEN with the values stored in your values.txt . victorops.yaml #cloud-config ssh_pwauth : yes password : DevOps2020! chpasswd : expire : false package_update : true packages : - unzip runcmd : # Download Workshop - export WSVERSION=v1.14 - curl -s -OL https://github.com/signalfx/devops-workshop/archive/$WSVERSION.zip - unzip -qq $WSVERSION.zip -d /home/ubuntu/ - mv /home/ubuntu/devops-workshop-${WSVERSION#v} /home/ubuntu/workshop # Configure motd - curl -s https://raw.githubusercontent.com/signalfx/devops-workshop/master/etc/motd -o /etc/motd - chmod -x /etc/update-motd.d/* # Install Terraform - curl -s -OL https://releases.hashicorp.com/terraform/0.12.25/terraform_0.12.25_linux_amd64.zip - unzip -qq terraform_0.12.25_linux_amd64.zip -d /usr/local/bin/ # Set correct permissions on ubuntu user home directory - chown -R ubuntu:ubuntu /home/ubuntu # Install Smart Agent - curl -sSL https://dl.signalfx.com/signalfx-agent.sh > /tmp/signalfx-agent.sh - sh /tmp/signalfx-agent.sh --realm SIGNALFX_REALM -- SIGNALFX_ACCESS_TOKEN Correct Spacing There should be a space between -- and the SIGNALFX_ACCESS_TOKEN value on the last line. e.g. - sh /tmp/signalfx-agent.sh --realm us1 -- 9jGYH..... Remaining in the same directory where you created the victorops.yaml , run the following commands to create your VM. The first command will generate a random unique 4 character string. This will prevent clashes in the SignalFx UI. Free up resources You may also want to first shutdown any other VMs you still have running from previous modules to free up resources. Create the VM: Input export INSTANCE = $( cat /dev/urandom | base64 | tr -dc 'a-z' | head -c4 ) multipass launch \\ --name ${ INSTANCE } -vo1 \\ --cloud-init victorops.yaml Example Output Launched: vpme-vo1 Once your VM has been created check within the SignalFx UI, INFRASTRUCTURE tab, and confirm it is reporting in correctly; allow 30-60 secs for it to appear. If it fails to appear, double check your SIGNALFX_REALM and SIGNALFX_ACCESS_TOKEN settings within your victorops.yaml file. If errors are found these can easily be updated directly within the VM. You may need to manually update the token , api_url or ingest_url files located within /etc/signalfx within the VM depending on which value you had incorrect - please reach out to the instructor for advice and assistance.","title":"Create test environment"},{"location":"victorops/getting_started/multipass/#creating-a-test-environment","text":"You are going to need to record a number of values during this Workshop which we will export as variables in later steps so create values.txt locally to store the following values as you work through the Workshop. values.txt export SFXVOPSID= export ACCESS_TOKEN= export REALM= export ROUTINGKEY= Service_API_Endpoint=","title":"Creating a Test Environment"},{"location":"victorops/getting_started/multipass/#1-multipass","text":"The easiest way to test VictorOps is to use Multipass to a local test VM which will be monitored by SignalFx. If you do not already have Multipass installed you can download the installer from here . MacOS users can install it using Homebrew by running: Code brew cask install multipass","title":"1. Multipass"},{"location":"victorops/getting_started/multipass/#2-signalfx-details","text":"We will use cloud-init to install the SignalFx Agent into the VMs but we first need to obtain the Access Token and Realm from your SignalFx account. You can find your Access Token by clicking on the Settings icon on the top right of the SignalFx UI, select Organization Settings \u2192 Access Tokens , expand the Default token, then click on Show Token to expose your token. Click the Copy button to copy it to your clipboard, then paste it into your values.txt using the ACCESS_TOKEN parameter. You will also need to obtain the name of the Realm for your SignalFx account. Click on the Settings icon again, but this time select My Profile . The Ream can be found in the middle of the page within the Organizations section. In this example it is us1 , make a note of this in your values.txt using the REALM parameter.","title":"2. SignalFx Details"},{"location":"victorops/getting_started/multipass/#3-local-vms-using-multipass","text":"The next step is to pull down the cloud-init file to launch a pre-configured VM. Input curl -s https://raw.githubusercontent.com/signalfx/devops-workshop/master/cloud-init/victorops.yaml -o victorops.yaml Open victorops.yaml in your preferred editor and replace SIGNALFX_REALM & SIGNALFX_ACCESS_TOKEN with the values stored in your values.txt . victorops.yaml #cloud-config ssh_pwauth : yes password : DevOps2020! chpasswd : expire : false package_update : true packages : - unzip runcmd : # Download Workshop - export WSVERSION=v1.14 - curl -s -OL https://github.com/signalfx/devops-workshop/archive/$WSVERSION.zip - unzip -qq $WSVERSION.zip -d /home/ubuntu/ - mv /home/ubuntu/devops-workshop-${WSVERSION#v} /home/ubuntu/workshop # Configure motd - curl -s https://raw.githubusercontent.com/signalfx/devops-workshop/master/etc/motd -o /etc/motd - chmod -x /etc/update-motd.d/* # Install Terraform - curl -s -OL https://releases.hashicorp.com/terraform/0.12.25/terraform_0.12.25_linux_amd64.zip - unzip -qq terraform_0.12.25_linux_amd64.zip -d /usr/local/bin/ # Set correct permissions on ubuntu user home directory - chown -R ubuntu:ubuntu /home/ubuntu # Install Smart Agent - curl -sSL https://dl.signalfx.com/signalfx-agent.sh > /tmp/signalfx-agent.sh - sh /tmp/signalfx-agent.sh --realm SIGNALFX_REALM -- SIGNALFX_ACCESS_TOKEN Correct Spacing There should be a space between -- and the SIGNALFX_ACCESS_TOKEN value on the last line. e.g. - sh /tmp/signalfx-agent.sh --realm us1 -- 9jGYH..... Remaining in the same directory where you created the victorops.yaml , run the following commands to create your VM. The first command will generate a random unique 4 character string. This will prevent clashes in the SignalFx UI. Free up resources You may also want to first shutdown any other VMs you still have running from previous modules to free up resources. Create the VM: Input export INSTANCE = $( cat /dev/urandom | base64 | tr -dc 'a-z' | head -c4 ) multipass launch \\ --name ${ INSTANCE } -vo1 \\ --cloud-init victorops.yaml Example Output Launched: vpme-vo1 Once your VM has been created check within the SignalFx UI, INFRASTRUCTURE tab, and confirm it is reporting in correctly; allow 30-60 secs for it to appear. If it fails to appear, double check your SIGNALFX_REALM and SIGNALFX_ACCESS_TOKEN settings within your victorops.yaml file. If errors are found these can easily be updated directly within the VM. You may need to manually update the token , api_url or ingest_url files located within /etc/signalfx within the VM depending on which value you had incorrect - please reach out to the instructor for advice and assistance.","title":"3. Local VMs using Multipass"},{"location":"victorops/getting_started/paging/","text":"Paging Polices \u00b6 Paging Polices specify how you will be contacted by VictorOps when on-call. The Primary Paging Policy will have defaulted to sending you an SMS assuming you added your phone number when activating your account. We will now configure this policy into a three tier multi-stage policy similar to the image below. 1. Send a push notification \u00b6 Click the edit policy button in the top right corner for the Primary Paging Policy. Send a push notification to all my devices Execute the next step if I have not responded within 5 minutes Click Add a Step 2. Send an e-mail \u00b6 Send an e-mail to [your email address] Execute the next step if I have not responded within 5 minutes Click Add a Step Call your number \u00b6 Every 5 minutes until we have reached you Make a phone call to [your phone number] Then save the policy. 3. Custom Paging Policies \u00b6 When you are on-call or in the escalation path of an incident, you will receive notifications in this order following these time delays. To cease the paging you must acknowledge the incident. Acknowledgements can occur in one of the following ways: Expanding the Push Notification on your device and selecting Acknowledge Responding to the SMS with the 5 digit code included Pressing 4 during the Phone Call Slack Button For more information on Notification Types, see here . Custom paging polices enable you to override the primary policy based on the time and day of the week. A good example would be get the system to immediately phone you whenever you get a page during the evening or weekends as this is more likely to get your attention than a push notification. Create a new Custom Policy by clicking Add a Policy and configure with the following settings: 3.1 Custom evening policy \u00b6 Policy Name: Evening Every 5 minutes until we have reached you Make a phone call to [your phone number] Time Period: All 7 Days Timezone Between 7pm and 9am Save the policy then add one more 3.2 Custom weekend policy \u00b6 Policy Name: Weekend Every 5 minutes until we have reached you Make a phone call to [your phone number] Time Period: Sat & Sun Timezone Between 9am and 7pm These custom paging policies will be used during the specified times in place of the Primary Policy. However admins do have the ability to ignore these custom policies, and we will highlight how this is achieved in a later module. The final option here is the setting for Recovery Notifications. As these are typically low priority simply sending you an email or a push notification are the typical settings used. Your profile is now fully configured using these example configurations. Organizations will have different views on how profiles should be configured and will typically issue guidelines for paging policies and times between escalations etc.","title":"Paging polices"},{"location":"victorops/getting_started/paging/#paging-polices","text":"Paging Polices specify how you will be contacted by VictorOps when on-call. The Primary Paging Policy will have defaulted to sending you an SMS assuming you added your phone number when activating your account. We will now configure this policy into a three tier multi-stage policy similar to the image below.","title":"Paging Polices"},{"location":"victorops/getting_started/paging/#1-send-a-push-notification","text":"Click the edit policy button in the top right corner for the Primary Paging Policy. Send a push notification to all my devices Execute the next step if I have not responded within 5 minutes Click Add a Step","title":"1. Send a push notification"},{"location":"victorops/getting_started/paging/#2-send-an-e-mail","text":"Send an e-mail to [your email address] Execute the next step if I have not responded within 5 minutes Click Add a Step","title":"2. Send an e-mail"},{"location":"victorops/getting_started/paging/#call-your-number","text":"Every 5 minutes until we have reached you Make a phone call to [your phone number] Then save the policy.","title":"Call your number"},{"location":"victorops/getting_started/paging/#3-custom-paging-policies","text":"When you are on-call or in the escalation path of an incident, you will receive notifications in this order following these time delays. To cease the paging you must acknowledge the incident. Acknowledgements can occur in one of the following ways: Expanding the Push Notification on your device and selecting Acknowledge Responding to the SMS with the 5 digit code included Pressing 4 during the Phone Call Slack Button For more information on Notification Types, see here . Custom paging polices enable you to override the primary policy based on the time and day of the week. A good example would be get the system to immediately phone you whenever you get a page during the evening or weekends as this is more likely to get your attention than a push notification. Create a new Custom Policy by clicking Add a Policy and configure with the following settings:","title":"3. Custom Paging Policies"},{"location":"victorops/getting_started/paging/#31-custom-evening-policy","text":"Policy Name: Evening Every 5 minutes until we have reached you Make a phone call to [your phone number] Time Period: All 7 Days Timezone Between 7pm and 9am Save the policy then add one more","title":"3.1 Custom evening policy"},{"location":"victorops/getting_started/paging/#32-custom-weekend-policy","text":"Policy Name: Weekend Every 5 minutes until we have reached you Make a phone call to [your phone number] Time Period: Sat & Sun Timezone Between 9am and 7pm These custom paging policies will be used during the specified times in place of the Primary Policy. However admins do have the ability to ignore these custom policies, and we will highlight how this is achieved in a later module. The final option here is the setting for Recovery Notifications. As these are typically low priority simply sending you an email or a push notification are the typical settings used. Your profile is now fully configured using these example configurations. Organizations will have different views on how profiles should be configured and will typically issue guidelines for paging policies and times between escalations etc.","title":"3.2 Custom weekend policy"},{"location":"victorops/getting_started/rotations/","text":"Configure Rotations \u00b6 Navigate to the Rotations tab on the Teams sub menu, you should have no existing Rotations so we need to create some. The 1st Rotation you will create is for a follow the sun support pattern where the members of each shift provide cover during their normal working hours within their time zone. The 2nd will be a Rotation used to provide escalation support by more experienced senior members of the team, based on a 24/7, 1 week shift pattern. 1. Follow the Sun Support - Business Hours \u00b6 Click Add Rotation Enter a name of \" Follow the Sun Support - Business Hours \" and Select Partial day from the three available shift templates. Enter a Shift name of \" Asia \" Time Zone set to \" Asia/Tokyo \" Each user is on duty from \" Monday through Friday from 9.00am to 5.00pm \" Handoff happens every \" 7 days \" The next handoff happens - Select the next Monday using the calendar Click Save Rotation You will now be prompted to add Members to this shift; add the Asia members who are jimhalpert, lydia and marie, but only if you're using the AppDev-EMEA Organisation for this workshop. If you're using your own Organisation refer to the specific list provided separately. Now add an 2nd shift for Europe by again clicking +Add a shift \u2192 Partial Day Enter a Shift name of \" Europe \" Time Zone set to \" Europe/London \" Each user is on duty from \" Monday through Friday from 9.00am to 5.00pm \" Handoff happens every \" 7 days \" The next handoff happens - Select the next Monday using the calendar Click Save Shift You will again be prompted to add Members to this shift; add the Europe members who are duanechow, gomez and heisenberg, but only if you're using the AppDev-EMEA Organisation for this workshop. If you're using your own Organisation refer to the specific list provided separately. Now add a 3rd shift for West Coast USA by again clicking +Add a shift - Partial Day Enter a Shift name of \" West Coast \" Time Zone set to \" US/Pacific \" Each user is on duty from \" Monday through Friday from 9.00am to 5.00pm \" Handoff happens every \" 7 days \" The next handoff happens - Select the next Monday using the calendar Click Save Shift You will again be prompted to add Members to this shift; add the West Coast members who are maximo, michaelscott and tuco, but only if you're using the AppDev-EMEA Organisation for this workshop. If you're using your own Organisation refer to the specific list provided separately. The first user added will be the 'current' user for that shift. You can re-order the shifts by simply dragging the users up and down, and you can change the current user by clicking Set Current on an alternate user You will now have three different Shift patterns, that provide cover 24hr hours, Mon - Fri, but with no cover at weekends. We will now add another Rotation for our Senior SRE Escalation cover. 2. Senior SRE Escalation \u00b6 Click Add Rotation Enter a name of \" Senior SRE Escalation \" Select 24/7 from the three available shift templates Enter a Shift name of \" Senior SRE Escalation \" Time Zone set to \" Asia/Tokyo \" Handoff happens every \" 7 days at 9.00am \" The next handoff happens [select the next Monday from the date picker] Click Save Rotation You will again be prompted to add Members to this shift; add the 24/7 members who are jackwelker, hank and pambeesly, but only if you're using the AppDev-EMEA Organisation for this workshop. If you're using your own Organisation refer to the specific list provided separately. That completes the configuration of the Rotations, we now need to configure the Escalation Policies and Routing Keys.","title":"Configure Rotations"},{"location":"victorops/getting_started/rotations/#configure-rotations","text":"Navigate to the Rotations tab on the Teams sub menu, you should have no existing Rotations so we need to create some. The 1st Rotation you will create is for a follow the sun support pattern where the members of each shift provide cover during their normal working hours within their time zone. The 2nd will be a Rotation used to provide escalation support by more experienced senior members of the team, based on a 24/7, 1 week shift pattern.","title":"Configure Rotations"},{"location":"victorops/getting_started/rotations/#1-follow-the-sun-support-business-hours","text":"Click Add Rotation Enter a name of \" Follow the Sun Support - Business Hours \" and Select Partial day from the three available shift templates. Enter a Shift name of \" Asia \" Time Zone set to \" Asia/Tokyo \" Each user is on duty from \" Monday through Friday from 9.00am to 5.00pm \" Handoff happens every \" 7 days \" The next handoff happens - Select the next Monday using the calendar Click Save Rotation You will now be prompted to add Members to this shift; add the Asia members who are jimhalpert, lydia and marie, but only if you're using the AppDev-EMEA Organisation for this workshop. If you're using your own Organisation refer to the specific list provided separately. Now add an 2nd shift for Europe by again clicking +Add a shift \u2192 Partial Day Enter a Shift name of \" Europe \" Time Zone set to \" Europe/London \" Each user is on duty from \" Monday through Friday from 9.00am to 5.00pm \" Handoff happens every \" 7 days \" The next handoff happens - Select the next Monday using the calendar Click Save Shift You will again be prompted to add Members to this shift; add the Europe members who are duanechow, gomez and heisenberg, but only if you're using the AppDev-EMEA Organisation for this workshop. If you're using your own Organisation refer to the specific list provided separately. Now add a 3rd shift for West Coast USA by again clicking +Add a shift - Partial Day Enter a Shift name of \" West Coast \" Time Zone set to \" US/Pacific \" Each user is on duty from \" Monday through Friday from 9.00am to 5.00pm \" Handoff happens every \" 7 days \" The next handoff happens - Select the next Monday using the calendar Click Save Shift You will again be prompted to add Members to this shift; add the West Coast members who are maximo, michaelscott and tuco, but only if you're using the AppDev-EMEA Organisation for this workshop. If you're using your own Organisation refer to the specific list provided separately. The first user added will be the 'current' user for that shift. You can re-order the shifts by simply dragging the users up and down, and you can change the current user by clicking Set Current on an alternate user You will now have three different Shift patterns, that provide cover 24hr hours, Mon - Fri, but with no cover at weekends. We will now add another Rotation for our Senior SRE Escalation cover.","title":"1. Follow the Sun Support - Business Hours"},{"location":"victorops/getting_started/rotations/#2-senior-sre-escalation","text":"Click Add Rotation Enter a name of \" Senior SRE Escalation \" Select 24/7 from the three available shift templates Enter a Shift name of \" Senior SRE Escalation \" Time Zone set to \" Asia/Tokyo \" Handoff happens every \" 7 days at 9.00am \" The next handoff happens [select the next Monday from the date picker] Click Save Rotation You will again be prompted to add Members to this shift; add the 24/7 members who are jackwelker, hank and pambeesly, but only if you're using the AppDev-EMEA Organisation for this workshop. If you're using your own Organisation refer to the specific list provided separately. That completes the configuration of the Rotations, we now need to configure the Escalation Policies and Routing Keys.","title":"2. Senior SRE Escalation"},{"location":"victorops/getting_started/routing/","text":"Create Routing Keys \u00b6 Routing Keys map the incoming alert messages from your monitoring system to an Escalation Policy which in turn sends the notifications to the appropriate team. In order to get your unique Routing Key, from the same command shell where you created your VM run the following command: Input echo $INSTANCE Example Output vmpe Closed session If you have inadvertently closed the session down, open a new session and run multipass list to show the name of your VM, the 1st 4 letters are the values we are looking for. Make a note of this 4 character string or copy to your clipboard. Navigate to Settings on the main menu bar, you should now be at the Routing Keys page. You are going to create the following two Routing Keys using the naming conventions listed in the following table, but replacing INSTANCE with the 4 characters from above and replace TEAM_NAME with the team you were allocated or created earlier. Routing Key Escalation Policies INSTANCE _PRI TEAM_NAME : Primary INSTANCE _WR TEAM_NAME : Waiting Room There will probably already be a number of Routing Keys configured, but to add a new one simply scroll to the bottom of the page and then click Add Key In the left hand box, enter the name for the key as per the convention detailed above. In the Routing Key column, select the appropriate policy from the drop down in the Escalation Polices column. Note If there are a large number of participants on the workshop, resulting in an unusually large number of Escalation Policies sometimes the search filter does not list all the Policies under your Team Name. If this happens instead of using the search feature, simply scroll down to your team name, all the policies will then be listed. Repeat the above steps for both Keys, xxx_PRI and xxx_WR. Note You can assign a Routing Key to multiple Escalation Policies if required by simply selecting more from the list If you now navigate back to Teams \u2192 [Your Team Name] \u2192 Escalation Policies and look at the settings for your Primary and Waiting Room polices you will see that these now have Routes assigned to them. The 24/7 policy does not have a Route assigned as this will only be triggered via an Execute Policy escalation from the Primary policy. This completes the initial getting started steps for VictorOps, the next step will be to configure the Integration between VictorOps and SignalFx.","title":"Creating Routing keys"},{"location":"victorops/getting_started/routing/#create-routing-keys","text":"Routing Keys map the incoming alert messages from your monitoring system to an Escalation Policy which in turn sends the notifications to the appropriate team. In order to get your unique Routing Key, from the same command shell where you created your VM run the following command: Input echo $INSTANCE Example Output vmpe Closed session If you have inadvertently closed the session down, open a new session and run multipass list to show the name of your VM, the 1st 4 letters are the values we are looking for. Make a note of this 4 character string or copy to your clipboard. Navigate to Settings on the main menu bar, you should now be at the Routing Keys page. You are going to create the following two Routing Keys using the naming conventions listed in the following table, but replacing INSTANCE with the 4 characters from above and replace TEAM_NAME with the team you were allocated or created earlier. Routing Key Escalation Policies INSTANCE _PRI TEAM_NAME : Primary INSTANCE _WR TEAM_NAME : Waiting Room There will probably already be a number of Routing Keys configured, but to add a new one simply scroll to the bottom of the page and then click Add Key In the left hand box, enter the name for the key as per the convention detailed above. In the Routing Key column, select the appropriate policy from the drop down in the Escalation Polices column. Note If there are a large number of participants on the workshop, resulting in an unusually large number of Escalation Policies sometimes the search filter does not list all the Policies under your Team Name. If this happens instead of using the search feature, simply scroll down to your team name, all the policies will then be listed. Repeat the above steps for both Keys, xxx_PRI and xxx_WR. Note You can assign a Routing Key to multiple Escalation Policies if required by simply selecting more from the list If you now navigate back to Teams \u2192 [Your Team Name] \u2192 Escalation Policies and look at the settings for your Primary and Waiting Room polices you will see that these now have Routes assigned to them. The 24/7 policy does not have a Route assigned as this will only be triggered via an Execute Policy escalation from the Primary policy. This completes the initial getting started steps for VictorOps, the next step will be to configure the Integration between VictorOps and SignalFx.","title":"Create Routing Keys"},{"location":"victorops/getting_started/team/","text":"Create Your Team \u00b6 Navigate to the Teams tab on the main toolbar, you should find you have had a team created for you as part of the workshop setup, however if this did not happen, you may need to create a new one. Select Add Team , then enter your team name using the format described by your workshop presenter, this will typically be in the format of \"StudentID_Workshop\" and then save by clicking the Add Team button. You now need to add other users to your team. If you are running this workshop using the Splunk provided environment, the following accounts are available for testing. If you are running this lab in your own environment, you will have been provided a list of usernames you can use in place of the table below. These users are dummy accounts who will not receive notifications when they are on call. Name Username Shift Duane Chow duanechow Europe Steven Gomez gomez Europe Walter White heisenberg Europe Jim Halpert jimhalpert Asia Lydia Rodarte-Quayle lydia Asia Marie Schrader marie Asia Maximo Arciniega maximo West Coast Michael Scott michaelscott West Coast Tuco Salamanca tuco West Coast Jack Welker jackwelker 24/7 Hank Schrader hank 24/7 Pam Beesly pambeesly 24/7 Add the users to your team, using either the above list or the alternate one provided to you. The value in the Shift column can be ignored for now, but will be required for a later step. Click the Invite User button on the right hand side, then either start typing the usernames (this will filter the list), or copy and paste them into the dialogue box. Once all users are added click the Add User button. To make a team member a Team Admin, simply click the icon in the right hand column, pick any user and make them an Admin. Tip For large team management you can use the APIs to streamline this process","title":"Creating a team"},{"location":"victorops/getting_started/team/#create-your-team","text":"Navigate to the Teams tab on the main toolbar, you should find you have had a team created for you as part of the workshop setup, however if this did not happen, you may need to create a new one. Select Add Team , then enter your team name using the format described by your workshop presenter, this will typically be in the format of \"StudentID_Workshop\" and then save by clicking the Add Team button. You now need to add other users to your team. If you are running this workshop using the Splunk provided environment, the following accounts are available for testing. If you are running this lab in your own environment, you will have been provided a list of usernames you can use in place of the table below. These users are dummy accounts who will not receive notifications when they are on call. Name Username Shift Duane Chow duanechow Europe Steven Gomez gomez Europe Walter White heisenberg Europe Jim Halpert jimhalpert Asia Lydia Rodarte-Quayle lydia Asia Marie Schrader marie Asia Maximo Arciniega maximo West Coast Michael Scott michaelscott West Coast Tuco Salamanca tuco West Coast Jack Welker jackwelker 24/7 Hank Schrader hank 24/7 Pam Beesly pambeesly 24/7 Add the users to your team, using either the above list or the alternate one provided to you. The value in the Shift column can be ignored for now, but will be required for a later step. Click the Invite User button on the right hand side, then either start typing the usernames (this will filter the list), or copy and paste them into the dialogue box. Once all users are added click the Add User button. To make a team member a Team Admin, simply click the icon in the right hand column, pick any user and make them an Admin. Tip For large team management you can use the APIs to streamline this process","title":"Create Your Team"},{"location":"victorops/incident_lifecycle/","text":"Lab Summary \u00b6 UI Overview Generate Incidents Manage Incidents 1. UI Overview \u00b6 The aim of VictorOps is to \"Make On Call Suck Less\" , and it does this by getting the critical data, to the right people, at the right time. The key to making VictorOps work for you is to centralize all your alerting sources, sending them all to the VictorOps platform, then you have a single pane of glass in which to manage all of your alerting. Login to the VictorOps UI and select the Timeline tab on the main menu bar, you should have a screen similar to the following image: 2. People \u00b6 On the left we have the People section with the Teams and Users sub tabs. On the Teams tab, click on All Teams then expand [Your Teamname] . Users with the VictorOps Logo against their name are currently on call. Here you can see who is on call within a particular Team, or across all Teams via Users \u2192 On-Call . If you click into one of the currently on call users, you can see their status. It shows which Rotation they are on call for, when their current Shift ends and their next Shift starts (times are displayed in your timezone), what contact methods they have and which Teams they belong to (dummy users such as Hank do not have Contact Methods configured). 3. Timeline \u00b6 In the centre Timeline section you get a realtime view of what is happening within your environment with the newest messages at the top. Here you can quickly post update messages to make your colleagues aware of important developments etc. You can filter the view using the buttons on the top toolbar showing only update messages, GitHub integrations, or apply more advanced filters. Lets change the Filters settings to streamline your view. Click the Filters button then within the Routing Keys tab change the Show setting from all routing keys to selected routing keys . Change the My Keys value to all and the Other Keys value to selected and deselect all keys under the Other Keys section. Click anywhere outside of the dialogue box to close it. You will probably now have a much simpler view as you will not currently have Incidents created using your Routing Keys, so you are left with the other types of messages that the Timeline can display. Click on Filters again, but this time switch to the Message Types tab. Here you control the types of messages that are displayed. For example, deselect On-call Changes and Escalations , this will reduce the amount of messages displayed. 4. Incidents \u00b6 On the right we have the Incidents section. Here we get a list of all the incidents within the platform, or we view a more specific list such as incidents you are specifically assigned to, or for any of the Teams you are a member of. Select the Team Incidents tab you should find that the Triggered , Acknowledged & Resolved tabs are currently all empty as you have had no incidents logged. Let's change that by generating your first incident!","title":"Overview"},{"location":"victorops/incident_lifecycle/#lab-summary","text":"UI Overview Generate Incidents Manage Incidents","title":"Lab Summary"},{"location":"victorops/incident_lifecycle/#1-ui-overview","text":"The aim of VictorOps is to \"Make On Call Suck Less\" , and it does this by getting the critical data, to the right people, at the right time. The key to making VictorOps work for you is to centralize all your alerting sources, sending them all to the VictorOps platform, then you have a single pane of glass in which to manage all of your alerting. Login to the VictorOps UI and select the Timeline tab on the main menu bar, you should have a screen similar to the following image:","title":"1. UI Overview"},{"location":"victorops/incident_lifecycle/#2-people","text":"On the left we have the People section with the Teams and Users sub tabs. On the Teams tab, click on All Teams then expand [Your Teamname] . Users with the VictorOps Logo against their name are currently on call. Here you can see who is on call within a particular Team, or across all Teams via Users \u2192 On-Call . If you click into one of the currently on call users, you can see their status. It shows which Rotation they are on call for, when their current Shift ends and their next Shift starts (times are displayed in your timezone), what contact methods they have and which Teams they belong to (dummy users such as Hank do not have Contact Methods configured).","title":"2. People"},{"location":"victorops/incident_lifecycle/#3-timeline","text":"In the centre Timeline section you get a realtime view of what is happening within your environment with the newest messages at the top. Here you can quickly post update messages to make your colleagues aware of important developments etc. You can filter the view using the buttons on the top toolbar showing only update messages, GitHub integrations, or apply more advanced filters. Lets change the Filters settings to streamline your view. Click the Filters button then within the Routing Keys tab change the Show setting from all routing keys to selected routing keys . Change the My Keys value to all and the Other Keys value to selected and deselect all keys under the Other Keys section. Click anywhere outside of the dialogue box to close it. You will probably now have a much simpler view as you will not currently have Incidents created using your Routing Keys, so you are left with the other types of messages that the Timeline can display. Click on Filters again, but this time switch to the Message Types tab. Here you control the types of messages that are displayed. For example, deselect On-call Changes and Escalations , this will reduce the amount of messages displayed.","title":"3. Timeline"},{"location":"victorops/incident_lifecycle/#4-incidents","text":"On the right we have the Incidents section. Here we get a list of all the incidents within the platform, or we view a more specific list such as incidents you are specifically assigned to, or for any of the Teams you are a member of. Select the Team Incidents tab you should find that the Triggered , Acknowledged & Resolved tabs are currently all empty as you have had no incidents logged. Let's change that by generating your first incident!","title":"4. Incidents"},{"location":"victorops/incident_lifecycle/create_incidents/","text":"Generate Incidents \u00b6 1. On-Call \u00b6 Before generating any incidents you should assign yourself to the current Shift within your Follow the Sun Support - Business Hours Rotation and also place yourself On-Call . Click on the Schedule link within your Team in the People section on the left Or navigate to Teams \u2192 [Your Team] \u2192 Rotations Expand the Follow the Sun Support - Business Hours Rotation Click on the Manage members icon (the figures) for the current active shift depending on your timezone Use the Select a user to add... dropdown to add yourself to the shift Then click on Set Current to make yourself the current on-call user within the shift You should now get a Push Notification to your phone informing you that You Are Now On-Call 2. Trigger Alert \u00b6 Log into your first VM you created during step 2. Creating a Test Environment in VictorOps Integrations Input multipass shell ${INSTANCE}-vo1 Output \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2557 \u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u255d \u255a\u2588\u2588\u2557 \u2588\u2588\u2554\u255d\u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2588\u2588\u2551 \u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u255a\u2588\u2588\u2588\u2588\u2554\u255d \u255a\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2551 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551 \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d To run a command as administrator (user \"root\"), use \"sudo <command>\". See \"man sudo_root\" for details Waiting for cloud-init status... Your instance is ready! ubuntu@vmpe-vo1:~$ Force the CPU to spike to 100% by running the following command: Input openssl speed -multi $(grep -ci processor /proc/cpuinfo) Output Forked child 0 +DT:md4:3:16 +R:19357020:md4:3.000000 +DT:md4:3:64 +R:14706608:md4:3.010000 +DT:md4:3:256 +R:8262960:md4:3.000000 +DT:md4:3:1024 This will result in an Alert being generated by SignalFx which in turn will generate an Incident within VictorOps within a maximum of 10 seconds. This is the default polling time for the SignalFx Agent we installed (it can be reduced to 1 second if required).","title":"Create incidents"},{"location":"victorops/incident_lifecycle/create_incidents/#generate-incidents","text":"","title":"Generate Incidents"},{"location":"victorops/incident_lifecycle/create_incidents/#1-on-call","text":"Before generating any incidents you should assign yourself to the current Shift within your Follow the Sun Support - Business Hours Rotation and also place yourself On-Call . Click on the Schedule link within your Team in the People section on the left Or navigate to Teams \u2192 [Your Team] \u2192 Rotations Expand the Follow the Sun Support - Business Hours Rotation Click on the Manage members icon (the figures) for the current active shift depending on your timezone Use the Select a user to add... dropdown to add yourself to the shift Then click on Set Current to make yourself the current on-call user within the shift You should now get a Push Notification to your phone informing you that You Are Now On-Call","title":"1. On-Call"},{"location":"victorops/incident_lifecycle/create_incidents/#2-trigger-alert","text":"Log into your first VM you created during step 2. Creating a Test Environment in VictorOps Integrations Input multipass shell ${INSTANCE}-vo1 Output \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2557 \u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u255d \u255a\u2588\u2588\u2557 \u2588\u2588\u2554\u255d\u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2588\u2588\u2551 \u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u255a\u2588\u2588\u2588\u2588\u2554\u255d \u255a\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2551 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551 \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d To run a command as administrator (user \"root\"), use \"sudo <command>\". See \"man sudo_root\" for details Waiting for cloud-init status... Your instance is ready! ubuntu@vmpe-vo1:~$ Force the CPU to spike to 100% by running the following command: Input openssl speed -multi $(grep -ci processor /proc/cpuinfo) Output Forked child 0 +DT:md4:3:16 +R:19357020:md4:3.000000 +DT:md4:3:64 +R:14706608:md4:3.010000 +DT:md4:3:256 +R:8262960:md4:3.000000 +DT:md4:3:1024 This will result in an Alert being generated by SignalFx which in turn will generate an Incident within VictorOps within a maximum of 10 seconds. This is the default polling time for the SignalFx Agent we installed (it can be reduced to 1 second if required).","title":"2. Trigger Alert"},{"location":"victorops/incident_lifecycle/manage_incidents/","text":"Managing Incidents \u00b6 Use your VictorOps App on your phone to acknowledge the Incident by clicking on the push notification ... ...clicking on the alert... ...then clicking on either the single tick in the top right hand corner, or the Acknowledge link. The will then transform into a , and the status will change from TRIGGERED to ACKNOWLEDGED . Single Tick Double Tick Still on your phone, select the Alert Details tab. Then on the Web UI, navigate back to Timeline , select Team Incidents on the right, then select Acknowledged and click into the new Incident . You should now have the Details tab displayed on both your Phone and the Web UI. Notice how they both show the exact same information. Now select the Annotations tab on both the Phone and the Web UI, you should have a Graph displayed in the UI which is generated by SignalFx. On your phone click the Chart Showing Alert link... ...and you should now get the exact same image on your phone. VictorOps is a 'Mobile First' platform meaning the phone app is full functionality and you can manage an incident directly from your phone. For the remainder of this module we will focus on the Web UI however please spend some time later exploring the phone app features. Sticking with the Web UI, click the 2. Alert Details in SignalFx link. This will open a new browser tab and take you directly to the Alert within SignalFx where you could then progress your troubleshooting using the powerful tools built into the SignalFx UI. However, we are focussing on VictorOps so close this tab and return to the VictorOps UI. What if VictorOps could identify previous incidents within the system which may give you a clue to the best way to tackle this incident. The Similar Incidents tab does exactly that, surfacing previous incidents allowing you to look at them and see what actions were taken to resolve them, actions which could be easily repeated for this incident. At the top right in the UI are a number of icons that allow quick access to various actions, click on the far right one which will open this Incident in a new window. With the Incident expanded, you can see on the right we have a Time Line view where you can add messages and see the history of previous alerts and interactions. On the far left you have the option of allocating additional resources to this incident by clicking on the Add Responders link. This allows you build a virtual team specific to this incident by adding other Teams or individual Users, and also share details of a Conference Bridge where you can all get together and collaborate. Close the Add Responders dialogue by clicking Cancel . You can also snooze this incident for up to 24hrs by clicking on the alarm clock in the very top left, or re-route it to a different team who may be better placed to deal with this particular incident. Now lets fix this issue and update the Incident with what we did. Add a new message at the top right such as Discovered rogue process, terminated it . Now kill off the process we started in the VM to max out the CPU. Within no greater than 10 seconds SignalFx should detect the new CPU value, clear the alert state in SignalFx, then automatically update the Incident in VictorOps marking it as Resolved . That completes this introduction to VictorOps, but feel free to checkout the more advanced modules which will be published in the coming weeks in the Optional Modules section. These will cover topics such as: Reporting Using the API Webhooks Alert Rules Engine Maintenance Mode","title":"Manage incidents"},{"location":"victorops/incident_lifecycle/manage_incidents/#managing-incidents","text":"Use your VictorOps App on your phone to acknowledge the Incident by clicking on the push notification ... ...clicking on the alert... ...then clicking on either the single tick in the top right hand corner, or the Acknowledge link. The will then transform into a , and the status will change from TRIGGERED to ACKNOWLEDGED . Single Tick Double Tick Still on your phone, select the Alert Details tab. Then on the Web UI, navigate back to Timeline , select Team Incidents on the right, then select Acknowledged and click into the new Incident . You should now have the Details tab displayed on both your Phone and the Web UI. Notice how they both show the exact same information. Now select the Annotations tab on both the Phone and the Web UI, you should have a Graph displayed in the UI which is generated by SignalFx. On your phone click the Chart Showing Alert link... ...and you should now get the exact same image on your phone. VictorOps is a 'Mobile First' platform meaning the phone app is full functionality and you can manage an incident directly from your phone. For the remainder of this module we will focus on the Web UI however please spend some time later exploring the phone app features. Sticking with the Web UI, click the 2. Alert Details in SignalFx link. This will open a new browser tab and take you directly to the Alert within SignalFx where you could then progress your troubleshooting using the powerful tools built into the SignalFx UI. However, we are focussing on VictorOps so close this tab and return to the VictorOps UI. What if VictorOps could identify previous incidents within the system which may give you a clue to the best way to tackle this incident. The Similar Incidents tab does exactly that, surfacing previous incidents allowing you to look at them and see what actions were taken to resolve them, actions which could be easily repeated for this incident. At the top right in the UI are a number of icons that allow quick access to various actions, click on the far right one which will open this Incident in a new window. With the Incident expanded, you can see on the right we have a Time Line view where you can add messages and see the history of previous alerts and interactions. On the far left you have the option of allocating additional resources to this incident by clicking on the Add Responders link. This allows you build a virtual team specific to this incident by adding other Teams or individual Users, and also share details of a Conference Bridge where you can all get together and collaborate. Close the Add Responders dialogue by clicking Cancel . You can also snooze this incident for up to 24hrs by clicking on the alarm clock in the very top left, or re-route it to a different team who may be better placed to deal with this particular incident. Now lets fix this issue and update the Incident with what we did. Add a new message at the top right such as Discovered rogue process, terminated it . Now kill off the process we started in the VM to max out the CPU. Within no greater than 10 seconds SignalFx should detect the new CPU value, clear the alert state in SignalFx, then automatically update the Incident in VictorOps marking it as Resolved . That completes this introduction to VictorOps, but feel free to checkout the more advanced modules which will be published in the coming weeks in the Optional Modules section. These will cover topics such as: Reporting Using the API Webhooks Alert Rules Engine Maintenance Mode","title":"Managing Incidents"},{"location":"victorops/integrations/","text":"VictorOps Integrations - Lab Summary \u00b6 Configuring the Integration between VictorOps and SignalFx 1. VictorOps Service API Endpoint \u00b6 Warning The SignalFx Integration only needs to be enabled once per VictorOps instance, so you will probably find it has already been enabled, please DO NOT disable an already active integration when completing this lab. In order to integrate SignalFx with VictorOps we need to first obtain the Service API Endpoint for VictorOps. Within the VictorOps UI navigate to Integrations main tab and then use the search feature to find the SignalFx Integration. If it is not already enabled, click the Enable Integration button to activate it. You simply need to copy the Service API Endpoint, including the $routing_key into your values.txt using the Service_API_Endpoint parameter. This will be used when configuring the VictorOps Integration within the SignalFx UI. 2. Enable VictorOps Integration within SignalFx \u00b6 Login to your SignalFx account and navigate to INTEGRATIONS and use the search feature to find the VictorOps integration. Do not create a new integration! Please do not create additional VictorOps integrations if one already exists, it will not break anything but simply creates extra clean up work after the workshop has completed. The aim of this part of the lab was to show you how you would go about configuring the Integration if it was not already enabled. Assuming you are using the AppDev EMEA instance of VictorOps you will find the VictorOps Integration has already been configured so there is no need to create a new one. However the process of creating a new Integration is simply to click on Create New Integration like in the image below, or if there are existing integrations and you want to add another one you would click New Integration . Enter a descriptive Name then paste the Service_API_Endpoint value you copied in the previous step into the Post URL field, then save it. Handling multiple VictorOps integrations SignalFx can integrate with multiple VictorOps accounts so it is important when creating one to use a descriptive name and to not simply call it VictorOps. This name will be used within the SignalFx UI when selecting this integration, so ensure it is unambiguous Once saved you need to copy the ID and save it in your values.txt using the SFXVOPSID parameter for use later in the module.","title":"Enabled integration in SignalFx"},{"location":"victorops/integrations/#victorops-integrations-lab-summary","text":"Configuring the Integration between VictorOps and SignalFx","title":"VictorOps Integrations - Lab Summary"},{"location":"victorops/integrations/#1-victorops-service-api-endpoint","text":"Warning The SignalFx Integration only needs to be enabled once per VictorOps instance, so you will probably find it has already been enabled, please DO NOT disable an already active integration when completing this lab. In order to integrate SignalFx with VictorOps we need to first obtain the Service API Endpoint for VictorOps. Within the VictorOps UI navigate to Integrations main tab and then use the search feature to find the SignalFx Integration. If it is not already enabled, click the Enable Integration button to activate it. You simply need to copy the Service API Endpoint, including the $routing_key into your values.txt using the Service_API_Endpoint parameter. This will be used when configuring the VictorOps Integration within the SignalFx UI.","title":"1. VictorOps Service API Endpoint"},{"location":"victorops/integrations/#2-enable-victorops-integration-within-signalfx","text":"Login to your SignalFx account and navigate to INTEGRATIONS and use the search feature to find the VictorOps integration. Do not create a new integration! Please do not create additional VictorOps integrations if one already exists, it will not break anything but simply creates extra clean up work after the workshop has completed. The aim of this part of the lab was to show you how you would go about configuring the Integration if it was not already enabled. Assuming you are using the AppDev EMEA instance of VictorOps you will find the VictorOps Integration has already been configured so there is no need to create a new one. However the process of creating a new Integration is simply to click on Create New Integration like in the image below, or if there are existing integrations and you want to add another one you would click New Integration . Enter a descriptive Name then paste the Service_API_Endpoint value you copied in the previous step into the Post URL field, then save it. Handling multiple VictorOps integrations SignalFx can integrate with multiple VictorOps accounts so it is important when creating one to use a descriptive name and to not simply call it VictorOps. This name will be used within the SignalFx UI when selecting this integration, so ensure it is unambiguous Once saved you need to copy the ID and save it in your values.txt using the SFXVOPSID parameter for use later in the module.","title":"2. Enable VictorOps Integration within SignalFx"},{"location":"victorops/integrations/detector/","text":"Create a SignalFx Detector - Lab Summary \u00b6 Shell into Multipass instance Initialize Terraform What have we just done? 1. Shell into Multipass instance \u00b6 We now need to create a new Detector within SignalFx which will use VictorOps as the target to send alerts to. Shell into your 1st Multipass instance you created in the Getting Started module, all of the following commands will be executed within the instance: Input multipass shell ${INSTANCE} The three required variables should be stored in your values.txt if you have been populating it as you have worked through this module. Example export SFXVOPSID = xxxxxxxxxxxx export ACCESS_TOKEN = xxxxxxxxxxxxxxx export REALM = us1 Next you need to export an environment variable for your Routing Key, as this uses the hostname of the Multipass instance you simply need to run the following command to create it: Input export ROUTINGKEY = ${ HOSTNAME : 0 : 4 } _PRI 2. Initialize Terraform \u00b6 Still within the Multipass Instance, switch to the victorops folder where the Terraform config files are located Change Directory cd ~/workshop/victorops Now we can initialize Terraform Input terraform init -upgrade Output Initializing the backend... Initializing provider plugins... - Checking for available provider plugins... - Downloading plugin for provider \"signalfx\" (terraform-providers/signalfx) 4.21.0... The following providers do not have any version constraints in configuration, so the latest version was installed. To prevent automatic upgrades to new major versions that may contain breaking changes, it is recommended to add version = \"...\" constraints to the corresponding provider blocks in configuration, with the constraint strings suggested below. * provider.signalfx: version = \"~> 4.21\" Terraform has been successfully initialized! You may now begin working with Terraform. Try running \"terraform plan\" to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary. Create a new Terraform workspace 1 which will track the state for this environment. Input terraform workspace new VictorOps Output Created and switched to workspace \"VictorOps\"! You're now on a new, empty workspace. Workspaces isolate their state, so if you run \"terraform plan\" Terraform will not see any existing state for this configuration. Check the plan output for errors before typing yes to commit the apply. Input terraform apply \\ -var=\"access_token=$ACCESS_TOKEN\" \\ -var=\"realm=$REALM\" \\ -var=\"sfx_prefix=${HOSTNAME:0:4}\" \\ -var=\"sfx_vo_id=$SFXVOPSID\" \\ -var=\"routing_key=$ROUTINGKEY\" Output An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # signalfx_detector.cpu_greater_90 will be created + resource \"signalfx_detector\" \"cpu_greater_90\" { + description = \"Alerts when CPU usage is greater than 90%\" + id = (known after apply) + max_delay = 0 + name = \"vmpe CPU greater than 90%\" + program_text = <<~EOT from signalfx.detectors.against_recent import against_recent A = data('cpu.utilization', filter=filter('host', 'vmpe*')).publish(label='A') detect(when(A > threshold(90))).publish('CPU utilization is greater than 90%') EOT + show_data_markers = true + time_range = 3600 + url = (known after apply) + rule { + detect_label = \"CPU utilization is greater than 90%\" + disabled = false + notifications = [ + \"VictorOps,xxx,vmpe_pri\", ] + parameterized_body = <<~EOT {{#if anomalous}} Rule \"{{{ruleName}}}\" in detector \"{{{detectorName}}}\" triggered at {{timestamp}}. {{else}} Rule \"{{{ruleName}}}\" in detector \"{{{detectorName}}}\" cleared at {{timestamp}}. {{/if}} {{#if anomalous}} Triggering condition: {{{readableRule}}} {{/if}} {{#if anomalous}} Signal value: {{inputs.A.value}} {{else}} Current signal value: {{inputs.A.value}} {{/if}} {{#notEmpty dimensions}} Signal details: {{{dimensions}}} {{/notEmpty}} {{#if anomalous}} {{#if runbookUrl}} Runbook: {{{runbookUrl}}} {{/if}} {{#if tip}} Tip: {{{tip}}} {{/if}} {{/if}} EOT + parameterized_subject = \"{{ruleSeverity}} Alert: {{{ruleName}}} ({{{detectorName}}})\" + severity = \"Critical\" } } Plan: 1 to add, 0 to change, 0 to destroy. Do you want to perform these actions in workspace \"Workshop\"? Terraform will perform the actions described above. Only 'yes' will be accepted to approve. Enter a value: yes signalfx_detector.cpu_greater_90: Creating... signalfx_detector.cpu_greater_90: Creation complete after 2s [id=EWHU-YAAAAA] Apply complete! Resources: 1 added, 0 changed, 0 destroyed. 3. What have we just done? \u00b6 By running Terraform within the VM you have just created a new Detector within SignalFx which will send alerts to VictorOps if the CPU utilization of your specific VM goes above 90%. A filter has been used to specifically monitor your Instance using the 1st 4 characters of its name, which were randomly assigned when you created the Instance. You have now configured the Integrations between VictorOps and SignalFx! The final part of this module is to test the flow of alerts from SignalFx into VictorOps and see how you can manage the incident with both the VictorOps UI and Mobile App. Workspaces allow you to run Terraform against different environments each with their own state data stored in the workspace. \u21a9","title":"Create a detector"},{"location":"victorops/integrations/detector/#create-a-signalfx-detector-lab-summary","text":"Shell into Multipass instance Initialize Terraform What have we just done?","title":"Create a SignalFx Detector - Lab Summary"},{"location":"victorops/integrations/detector/#1-shell-into-multipass-instance","text":"We now need to create a new Detector within SignalFx which will use VictorOps as the target to send alerts to. Shell into your 1st Multipass instance you created in the Getting Started module, all of the following commands will be executed within the instance: Input multipass shell ${INSTANCE} The three required variables should be stored in your values.txt if you have been populating it as you have worked through this module. Example export SFXVOPSID = xxxxxxxxxxxx export ACCESS_TOKEN = xxxxxxxxxxxxxxx export REALM = us1 Next you need to export an environment variable for your Routing Key, as this uses the hostname of the Multipass instance you simply need to run the following command to create it: Input export ROUTINGKEY = ${ HOSTNAME : 0 : 4 } _PRI","title":"1. Shell into Multipass instance"},{"location":"victorops/integrations/detector/#2-initialize-terraform","text":"Still within the Multipass Instance, switch to the victorops folder where the Terraform config files are located Change Directory cd ~/workshop/victorops Now we can initialize Terraform Input terraform init -upgrade Output Initializing the backend... Initializing provider plugins... - Checking for available provider plugins... - Downloading plugin for provider \"signalfx\" (terraform-providers/signalfx) 4.21.0... The following providers do not have any version constraints in configuration, so the latest version was installed. To prevent automatic upgrades to new major versions that may contain breaking changes, it is recommended to add version = \"...\" constraints to the corresponding provider blocks in configuration, with the constraint strings suggested below. * provider.signalfx: version = \"~> 4.21\" Terraform has been successfully initialized! You may now begin working with Terraform. Try running \"terraform plan\" to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary. Create a new Terraform workspace 1 which will track the state for this environment. Input terraform workspace new VictorOps Output Created and switched to workspace \"VictorOps\"! You're now on a new, empty workspace. Workspaces isolate their state, so if you run \"terraform plan\" Terraform will not see any existing state for this configuration. Check the plan output for errors before typing yes to commit the apply. Input terraform apply \\ -var=\"access_token=$ACCESS_TOKEN\" \\ -var=\"realm=$REALM\" \\ -var=\"sfx_prefix=${HOSTNAME:0:4}\" \\ -var=\"sfx_vo_id=$SFXVOPSID\" \\ -var=\"routing_key=$ROUTINGKEY\" Output An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # signalfx_detector.cpu_greater_90 will be created + resource \"signalfx_detector\" \"cpu_greater_90\" { + description = \"Alerts when CPU usage is greater than 90%\" + id = (known after apply) + max_delay = 0 + name = \"vmpe CPU greater than 90%\" + program_text = <<~EOT from signalfx.detectors.against_recent import against_recent A = data('cpu.utilization', filter=filter('host', 'vmpe*')).publish(label='A') detect(when(A > threshold(90))).publish('CPU utilization is greater than 90%') EOT + show_data_markers = true + time_range = 3600 + url = (known after apply) + rule { + detect_label = \"CPU utilization is greater than 90%\" + disabled = false + notifications = [ + \"VictorOps,xxx,vmpe_pri\", ] + parameterized_body = <<~EOT {{#if anomalous}} Rule \"{{{ruleName}}}\" in detector \"{{{detectorName}}}\" triggered at {{timestamp}}. {{else}} Rule \"{{{ruleName}}}\" in detector \"{{{detectorName}}}\" cleared at {{timestamp}}. {{/if}} {{#if anomalous}} Triggering condition: {{{readableRule}}} {{/if}} {{#if anomalous}} Signal value: {{inputs.A.value}} {{else}} Current signal value: {{inputs.A.value}} {{/if}} {{#notEmpty dimensions}} Signal details: {{{dimensions}}} {{/notEmpty}} {{#if anomalous}} {{#if runbookUrl}} Runbook: {{{runbookUrl}}} {{/if}} {{#if tip}} Tip: {{{tip}}} {{/if}} {{/if}} EOT + parameterized_subject = \"{{ruleSeverity}} Alert: {{{ruleName}}} ({{{detectorName}}})\" + severity = \"Critical\" } } Plan: 1 to add, 0 to change, 0 to destroy. Do you want to perform these actions in workspace \"Workshop\"? Terraform will perform the actions described above. Only 'yes' will be accepted to approve. Enter a value: yes signalfx_detector.cpu_greater_90: Creating... signalfx_detector.cpu_greater_90: Creation complete after 2s [id=EWHU-YAAAAA] Apply complete! Resources: 1 added, 0 changed, 0 destroyed.","title":"2. Initialize Terraform"},{"location":"victorops/integrations/detector/#3-what-have-we-just-done","text":"By running Terraform within the VM you have just created a new Detector within SignalFx which will send alerts to VictorOps if the CPU utilization of your specific VM goes above 90%. A filter has been used to specifically monitor your Instance using the 1st 4 characters of its name, which were randomly assigned when you created the Instance. You have now configured the Integrations between VictorOps and SignalFx! The final part of this module is to test the flow of alerts from SignalFx into VictorOps and see how you can manage the incident with both the VictorOps UI and Mobile App. Workspaces allow you to run Terraform against different environments each with their own state data stored in the workspace. \u21a9","title":"3. What have we just done?"}]}